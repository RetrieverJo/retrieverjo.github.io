<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>Hyunje Blog &#8211; Hyunje Blog</title>

<meta name="google-site-verification" content="KstVPrbjGTMueNzKiyCurwLlZ0wNcfscVNW4KmZtXC4" />

<meta name="description" content="Blog for Hyunje">
<meta name="keywords" content="Jekyll, theme, themes, responsive, blog, modern">



<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Hyunje Blog">
<meta property="og:description" content="Blog for Hyunje">
<meta property="og:url" content="/page2/index.html">
<meta property="og:site_name" content="Hyunje Blog">





<link rel="canonical" href="/page2/">
<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Hyunje Blog Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<!-- Webfonts -->
<link href="//fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic" rel="stylesheet" type="text/css">
<link href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
<link href='//fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
<link href='//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

<meta http-equiv="cleartype" content="on">

<!-- Load Modernizr -->
<script src="/assets/js/vendor/modernizr-2.6.2.custom.min.js"></script>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="/images/apple-touch-icon-144x144-precomposed.png">




<style type="text/css">body {background-image:url(/images/white.jpg);}</style>


</head>

<body id="post-index" class="feature">

<!--[if lt IE 9]><div class="upgrade"><strong><a href="http://whatbrowser.org/">Your browser is quite old!</strong> Why not upgrade to a different browser to better enjoy this site?</a></div><![endif]-->
<nav id="dl-menu" class="dl-menuwrapper" role="navigation">
	<button class="dl-trigger">Open Menu</button>
	<ul class="dl-menu">
		<li><a href="/">Home</a></li>
		<li>
			<a href="#">About</a>
			<ul class="dl-submenu">
				<li>
					<img src="/images/avatar.jpg" alt="Hyunje Jo photo" class="author-photo">
					<h4>Hyunje Jo</h4>
					<p>Bigdata-technology based Machine Learning & Data Analysis</p>
				</li>
				<li><a href="/about/"><span class="btn btn-inverse">Learn More</span></a></li>
				<li>
					<a href="mailto:retriever89@gmail.com"><i class="fa fa-fw fa-envelope"></i> Email</a>
				</li>
				
				<li>
					<a href="https://facebook.com/RetrieverJo"><i class="fa fa-fw fa-facebook"></i> Facebook</a>
				</li>
				
				
				<li>
					<a href="https://github.com/retrieverJo"><i class="fa fa-fw fa-github"></i> GitHub</a>
				</li>
				
				
				
				
			</ul><!-- /.dl-submenu -->
		</li>
		<li>
			<a href="#">Posts</a>
			<ul class="dl-submenu">
				<li><a href="/posts/">All Posts</a></li>
				<li><a href="/categories/">All Categories</a></li>
				<li><a href="/tags/">All Tags</a></li>
			</ul>
		</li>
		<!--
		
	    
	        
	    
	    <li><a href="/theme-setup/" >Theme Setup</a></li>
	  
	    
	        
	        
	    <li><a href="http://mademistakes.com" target="_blank">External Link</a></li>
	  
	  	-->
	</ul><!-- /.dl-menu -->
</nav><!-- /.dl-menuwrapper -->


<div class="entry-header">
  <div class="image-credit">Image source: <a href="">Hyunje Jo</a></div><!-- /.image-credit -->
  
    <div class="entry-image">
      <img src="/images/bg0.jpg" alt="Hyunje Blog">
    </div><!-- /.entry-image -->
  
  <div class="header-title">
    <div class="header-title-wrap">
      <h1>Hyunje Blog</h1>
      <h2>Hyunje Blog</h2>
    </div><!-- /.header-title-wrap -->
  </div><!-- /.header-title -->
</div><!-- /.entry-header -->

<div id="main" role="main">
  
<article class="hentry">
  <header>
    
      <div class="entry-image-index">
        <a href="/data%20analysis/2015/09/09/advanced-analytics-with-spark-ch4/" title="Spark & 머신 러닝 - Predicting Forest Cover"><img src="/images/bg4.jpg" alt="Spark & 머신 러닝 - Predicting Forest Cover"></a>
      </div><!-- /.entry-image -->
    
    <div class="entry-meta">
      <span class="entry-date date published updated"><time datetime="2015-09-09T17:09:00-04:00"><a href="/data%20analysis/2015/09/09/advanced-analytics-with-spark-ch4/">September 09, 2015</a></time></span><span class="author vcard"><span class="fn"><a href="/about/" title="About Hyunje Jo">Hyunje Jo</a></span></span>
      <!--
      
      <span class="entry-reading-time">
        <i class="fa fa-clock-o"></i>
        
Reading time ~1 minute
      </span>
      -->
      <!-- /.entry-reading-time -->
      
    </div><!-- /.entry-meta -->
    
      <h1 class="entry-title"><a href="/data%20analysis/2015/09/09/advanced-analytics-with-spark-ch4/" rel="bookmark" title="Spark & 머신 러닝 - Predicting Forest Cover" itemprop="url">Spark & 머신 러닝 - Predicting Forest Cover</a></h1>
    
  </header>
  <div class="entry-content" style="overflow:hidden; height:500px;">
    <p>이 포스트는 Decision Tree를 이용해서 미국 콜로라도의 한 지역을 덮고 있는 숲의 종류를 예측하는 과정에 대한 글이다. </p>

<p>이 포스트는 <a href="http://shop.oreilly.com/product/0636920035091.do">Advanced Analytics with Spark</a>을 정리한 글이다.
<br>
<br></p>

<h2>Regression and Classification</h2>

<p>Regression은 숫자 형태의 데이터를 이용하여 또 다른 값을 예측하는 것이고, Classification은 레이블이나 카테고리등을 예측하는 것을 이야기 한다. 두 가지의 공통점은 주어진 하나 이상의 값을 이용하여 새로운 값을 예측해 낸다는 것이고 예측을 수행하기 위한 데이터와, 어떤 값을 예측할 것인지에 대한 &#39;known answers&#39;가 필요하다. 그렇기 때문에 Regression과 Classification은 Machine learning 에서 <code>supervised learning</code>에 속한다.</p>

<p>두 가지 모두 predictive analytics 에서 가장 오래되고 연구가 많이 된 방법이다. 머신러닝 관련된 라이브러리에서 대부분의 분석 알고리즘은 regression 혹은 classification 방법이다. 예를 들면 <a href="https://en.wikipedia.org/wiki/Support_vector_machine">Support Vector Machine</a>, <a href="https://en.wikipedia.org/wiki/Logistic_regression">Logistic Regression</a>, <a href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier">Naive Bayes Classifier</a>, <a href="https://en.wikipedia.org/wiki/Artificial_neural_network">Neural Network</a>, <a href="https://en.wikipedia.org/wiki/Deep_learning">Deep Learning</a> 등이 있다.</p>

<p>이 챕터(포스트)에서는 이러한 여러 알고리즘 중 가장 간단하면서도 확장성이 좋은 Decision Tree와, 그것의 확장형인 Random Decision Forest(Random Forest라고도 한다.)를 이용할 것이다. </p>

<p><br>
<br></p>

<h2>Decision Trees and Forest</h2>

<p>앞서 설명한 <strong>Decision Tree</strong>는 숫자 형태의 데이터 뿐만 아니라 categorical 한 Feature에 대해서도 사용 가능하다. 이 Decision Tree가 좀 더 일반화되어 좀 더 강력한 성능을 제공하는 것이 <strong>Random Decision Forest</strong>라고 불린다. 이 두 가지가 Spark의 MLlib에 <code>DecisionTree</code>와 <code>RandomForest</code>로 구현되어 있으며 이것을 데이터 셋에 적용하여 테스트 할 것이다.</p>

<p>Decision Tree 알고리즘은 직관적으로 이해하기 비교적 쉽다는 장점이 있다. 실제로 우리는 Decision Tree에 내재되어 있는 방식과 똑같은 방식을 실제로 사용하고 있기도 하다. 예를 들면 아침에 커피와 우유를 섞기 전에 우유가 상했는지 예측을 할 때 우리는 일련의 과정을 거친다. 먼저, 유통기한이 지났는가? 지나지 았았다면 상하지 않았을 것이고 날짜가 3일이상 지났다면 우유가 상했을 것이라 예측한다. 그렇지 않다면 우유에 냄새를 맡고 냄새가 이상하면 상했고, 그렇지 않다면 상하지 않았다고 판단할 것이다.</p>

<p><img src="https://db.tt/HxhHze1F" alt="Decision Tree Example"></p>

<p>Decision Tree에는 위 다이어그램과 같은 일련의 Yes/No 로 구성된 선택들이 내재되어 있다. 각각의 질문은 예측 결과 혹은 또 다른 결정문제를 유도한다. 이 Decision Tree의 각각의 노드는 결정문제가 되고, 각 leaf는 최종 예측 결과가 된다.</p>

<p><br>
<br></p>

<h2>Preparing the Data</h2>

<p>이 장에서 사용할 데이터셋은 Covtype이라는 데이터셋으로 <a href="https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.data.gz">이 링크</a>에서 다운로드 할 수 있다. 다운로드 후 압축을 해제하면 생성되는<strong>covtype.data</strong> 파일이 데이터파일이다.</p>

<p>데이터셋은 미국 콜로라도주의 특정 지역을 덮고 있는 숲의 종류에 대해 기록이 정리되어있다. 각 행은 해당 지역에 존재하는 여러 부분들을 여러 개의 Feature로 표현한다. 고도, 경사도, 토양의 종류 등등이 Feature에 해당된다. 이렇게 표현되는 지역들을 덮고 있는 숲은 Feature로부터 예측 가능하며 총 54 가지의 Feature가 존재한다. 그리고 약 580000개의 데이터가 존재한다. 비록 데이터가 크지 않아 빅 데이터라 할 수는 없지만 우리가 Decision Tree를 생성하고 그 결과를 확인해 보는 데에는 적당하다.</p>

<p>데이터는 다음과 같은 내용으로 구성되어 있다.</p>

<p><img src="https://db.tt/q4uI4Ua7" alt="Covtype Dataset Description"></p>

<p>고맙게도 이 데이터는 CSV형태로 되어있기 때문에 Spark MLlib을 이용하기 위해 데이터를 정제하는 과정이 거의 필요하지 않다. <strong>covtype.data</strong>파일을 HDFS에 업로드할 때, 이 포스트에서는 <code>/covtype/covtype.data</code>로 업로드 하는 것을 가정한다.</p>

<p>Spark의 Mllib은 Feature의 Vector를 <code>LabeledPoint</code> 객체로 추상화하여 사용한다. Vector 형태로 저장되어 있는 Feature 값과 구하고자 하는 target인 <code>Label</code>로 구성된 형태이다. LabeledPoint는 숫자 형태의 값만을 이용하는 것으로 제한되며 target은 Double 형태로 지정된다. 때문에 만약 Categorical한 Feature(숫자가 아닌 값들)를 사용하고자 할 때는 적절한 값으로 인코딩을 해 주어야 한다.</p>

<p>한 가지 인코딩 방법은 \(N\)개의 값은 갖는 Categorical한 Feature를 \(N\)개의 0과 1의 조합을 통해 서로 다른 값을 갖게하는 것이다. 예를 들어 날씨에 대한 Feature가 갖는 값의 종류는 <strong>cloudy</strong>, <strong>rainy</strong>, <strong>clear</strong> 일 때, cloudy는 <code>1,0,0</code>으로, rainy는 <code>0,1,0</code>과 같은 값은 갖는 형태로 인코딩을 할 수 있다. 이 포스트에서 사용하는 데이터 셋은 이 방법으로 구성되어있다. 다른 방법으로는 각각의 값에 특정 숫자(1, 2, ...)를 부여하는 방법이 있다. 이 챕터의 뒷 부분에서는 전자의 방식을 후자의 방식으로 바꿔서도 실험을 수행할 것이다.</p>

<p>HDFS에 업로드한 데이터를 MLlib에서 사용하기 위해 다음과 같이 데이터를 준비한다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.spark.mllib.linalg._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.mllib.regression._</span>

<span class="k">val</span> <span class="n">rawData</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="o">(</span><span class="s">&quot;/covtype/covtype.data&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="n">rawData</span><span class="o">.</span><span class="n">map</span> <span class="o">{</span> <span class="n">line</span> <span class="k">=&gt;</span>
    <span class="k">val</span> <span class="n">values</span> <span class="k">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&quot;,&quot;</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">toDouble</span><span class="o">)</span>
    <span class="k">val</span> <span class="n">featureVector</span> <span class="k">=</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="n">values</span><span class="o">.</span><span class="n">init</span><span class="o">)</span>
    <span class="k">val</span> <span class="n">label</span> <span class="k">=</span> <span class="n">values</span><span class="o">.</span><span class="n">last</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="nc">LabeledPoint</span><span class="o">(</span><span class="n">label</span><span class="o">,</span> <span class="n">featureVector</span><span class="o">)</span>
<span class="o">}</span>
</code></pre></div>
<p>데이터의 구성을 보면 알 수 있듯이 각 행의 마지막 값이 우리가 최종적으로 알아내고자 하는 숲의 종류임을 알 수 있다. 따라서 위 코드에서처럼 <code>featrueVector</code>를 생성할 때 init()을 이용해 <strong>가장 마지막 값은 제외한 벡터를 feature vector로</strong> 한다. 그리고 MLlib에서의 Decition Tree의 Label은 값이 0 부터 시작하므로 데이터의 가장 마지막 값은 1을 뺀다.</p>

<p>또한 다음 코드를 이용해 이전 포스트에서 수행하였던 것처럼 모든 데이터를 Decition Tree를 생성하는데 사용하지 않고, 80% 데이터를 트레이닝에 사용하고, 10%를 Cross-validation, 나머지 10%를 테스트용으로 사용할 것이다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nc">Array</span><span class="o">(</span><span class="n">trainData</span><span class="o">,</span> <span class="n">cvData</span><span class="o">,</span> <span class="n">testData</span><span class="o">)</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">randomSplit</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="mf">0.8</span><span class="o">,</span> <span class="mf">0.1</span><span class="o">,</span> <span class="mf">0.1</span><span class="o">))</span>
<span class="n">trainData</span><span class="o">.</span><span class="n">cache</span><span class="o">()</span>
<span class="n">cvData</span><span class="o">.</span><span class="n">cache</span><span class="o">()</span>
<span class="n">testData</span><span class="o">.</span><span class="n">cache</span><span class="o">()</span>
</code></pre></div>
<p><br>
<br></p>

<h2>A First Decision Tree</h2>

<p>다음 코드를 이용해 Decision Tree를 트레이닝시킨다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.spark.mllib.tree._</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="nc">DecisionTree</span><span class="o">.</span><span class="n">trainClassifier</span><span class="o">(</span><span class="n">trainData</span><span class="o">,</span> <span class="mi">7</span><span class="o">,</span> <span class="nc">Map</span><span class="o">[</span><span class="kt">Int</span>, <span class="kt">Int</span><span class="o">](),</span> <span class="s">&quot;gini&quot;</span><span class="o">,</span> <span class="mi">4</span><span class="o">,</span> <span class="mi">100</span><span class="o">)</span>
</code></pre></div>
<p>ALS를 이용한 추천 모델 생성에서도 그러하였듯이, <code>trainClassifier</code> 함수를 이용해 트레이닝을 할 때에도 몇 가지 필수 Hyperparameter가 사용된다. 첫번째 파라미터는 <strong>어떤 데이터를 이용하여 Classifer를 훈련시킬 것인지에 대한 것</strong>이고, 두 번째 파라미터는 <strong>우리가 최종적으로 예측하고자 하는 값의 종류가 몇가지 인지</strong>를 나타낸다. Covtype Dataset에서 우리가 예측하고자 하는 숲의 종류는 7가지 이므로 7이 파라미터로 이용된다. 다음 <code>Map</code>인자는 categorical feature에 대한 정보를 갖고 있는데, 이것은 나중에 <em>gini</em>파라미터의 의미와 함께 설명할 것이다. 그리고 다음 인자는 4로 <strong>Tree의 최대 깊이</strong>를 의미하며 마지막 100 파라미터는 <strong>Feature가 연속한 값을 가질 때 최대 몇 개의 bin 까지 나눌 수 있는가</strong>에 대한 것이다.</p>

<p>생성한 Decision Tree 모델이 얼마만큼의 정확도를 갖는지는 다음과 같은 코드를 이용해 <a href="https://en.wikipedia.org/wiki/Confusion_matrix">Confusion Matrix</a>를 계산함으로써 알 수 있다. 이 계산에서는 Cross-Validation 데이터를 이용하였다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.spark.mllib.evaluation._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.mllib.tree.model._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.rdd._</span>

<span class="k">def</span> <span class="n">getMetrics</span><span class="o">(</span><span class="n">model</span><span class="k">:</span> <span class="kt">DecisionTreeModel</span><span class="o">,</span> <span class="n">data</span><span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">LabeledPoint</span><span class="o">])</span><span class="k">:</span> <span class="kt">MulticlassMetrics</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">predictionsAndLabels</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="o">(</span> <span class="n">example</span> <span class="k">=&gt;</span>
        <span class="o">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="o">(</span><span class="n">example</span><span class="o">.</span><span class="n">features</span><span class="o">),</span> <span class="n">example</span><span class="o">.</span><span class="n">label</span><span class="o">)</span>
    <span class="o">)</span>
    <span class="k">new</span> <span class="nc">MulticlassMetrics</span><span class="o">(</span><span class="n">predictionsAndLabels</span><span class="o">)</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">matrics</span> <span class="k">=</span> <span class="n">getMetrics</span><span class="o">(</span><span class="n">model</span><span class="o">,</span> <span class="n">cvData</span><span class="o">)</span>
<span class="n">matrics</span><span class="o">.</span><span class="n">confusionMatrix</span>
</code></pre></div>
<p>Confusion Matrix는 다음과 같다. (랜덤성을 갖고 있기 때문에 수행 결과가 다를 수 있다.)</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">15767.0  5223.0   3.0     0.0  0.0   0.0  380.0
6761.0   21073.0  447.0   0.0  8.0   0.0  31.0
0.0      714.0    2836.0  0.0  0.0   0.0  0.0
0.0      0.0      292.0   0.0  0.0   0.0  0.0
16.0     865.0    24.0    0.0  16.0  0.0  0.0
0.0      428.0    1287.0  0.0  0.0   0.0  0.0
1134.0   20.0     0.0     0.0  0.0   0.0  914.0
</code></pre></div>
<p>우리가 예측하고자 하는 목표 값이 7가지 값을 갖기 때문에 Confusion Matrix는 7 X 7 의 행렬을 갖는다. 또한 위 행렬의 <strong>각 행은 실제 정답을 의미하고, 각 열은 Decision Tree가 예측한 값을 의미</strong>한다. 따라서 행 \(i\), 열 \(j\)의 숫자는 Decision Tree가 \(j\)로 예측하였고 실제 그 값이 \(i\)인 개수를 나타낸다. 때문에 Decision Tree가 정확히 맞춘 것은 diagonal(행과 열의 인덱스가 같은 것)에 존재하는 것들이며 그것을 제외한 나머지들은 에러이다. 위 결과에서는 category 3과 5와 같은 경우에는 제대로 맞춘 것이 하나도 없는 결과를 보인다.</p>

<p>다음 코드를 수행하면 간단히 정확도를 계산할 수 있다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="n">metrics</span><span class="o">.</span><span class="n">precision</span>

<span class="o">...</span>

<span class="nc">Double</span> <span class="k">=</span> <span class="mf">0.6972303782688576</span>
</code></pre></div>
<p>약 0.7의 값을 보이는데 이 값은 실제 <a href="https://en.wikipedia.org/wiki/Precision_and_recall#Definition_.28classification_context.29">Precision</a>라는 값을 계산한 것이다. 일반적으로 정확도라고 불리기도 하지만 <em>binary classification</em>에서 주로 사용되는 성능 측정 방법이다. <code>positive</code>와 <code>negative</code> 두 클래스로 데이터를 분류하는 문제에서 <strong>Precision은 Classifier가 Positive라고 판단한 것 중에 실제 Poistive가 차지하는 비율</strong>이다. 보통 이 Precision은 <code>Recall</code>과 함께 언급된다. <strong>Recall은 실제 Positive 값 중에 Classifier가 Positive라 판단한 것의 비율</strong>이다.</p>

<p>예를 들면 50개의 데이터 중에 20개가 Positive인 데이터셋이 있고, Classifier가 50개 중에 10개를 Positive라 판단하였는데 그 10개 중에 4개가 실제 Positive(제대로 Classify 한것을 의미) 데이터라 한다면 Precision은 \( \frac { 4 }{ 10 } = 0.4\) 이며, Recall은 \( \frac { 4 }{ 20 } = 0.2\) 이다. 이것을 Multi-class classification에 적용하여 각각의 카테고리를 Positive라 가정하고 각 수행에서 나머지 카테고리를 Negative라 하여 Precision Recall을 계산할 수 있다. 이런 계산 결과들이 위에서 생성한  <code>MulticlassMatrics</code>클래스에 들어있다. 각 카테고리별로 Recall과 Precision이 얼마나 되는지 다음 코드를 통해 확인할 수 있다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="o">(</span><span class="mi">0</span> <span class="n">until</span> <span class="mi">7</span><span class="o">).</span><span class="n">map</span><span class="o">(</span> <span class="c1">//Category 는 0부터 시작하기때문에</span>
    <span class="n">category</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">precision</span><span class="o">(</span><span class="n">category</span><span class="o">),</span> <span class="n">metrics</span><span class="o">.</span><span class="n">recall</span><span class="o">(</span><span class="n">category</span><span class="o">))</span>
<span class="o">).</span><span class="n">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>
</code></pre></div>
<p>수행 결과는 다음과 같다. (수행시마다 다를 수 있다.)</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">(0.665892389559929,0.7377064520656904)
(0.7440242912120891,0.7441031073446328)
(0.5800777255062385,0.7988732394366197)
(0.0,0.0)
(0.6666666666666666,0.01737242128121607)
(0.0,0.0)
(0.689811320754717,0.44197292069632493)
</code></pre></div>
<p>처음 계산한 정확도인 0.7은 꽤나 괜찮은 결과처럼 보이지만 0.7이라는 정확도가 얼마나 정확한 것인지 판단하기 어렵다. 따라서 그것을 구분하기 위한 기준선이 필요하다. 다음과 같은 함수를 이용하여 인자로 받는 데이터에서 Classifier가 무작위로 클래스를 선택한다고 가정후에 그 것에 대한 정확도를 계산할 수 있다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">def</span> <span class="n">classProbabilities</span><span class="o">(</span><span class="n">data</span><span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">LabeledPoint</span><span class="o">])</span> <span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">Double</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">countsByCategory</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">label</span><span class="o">).</span><span class="n">countByValue</span><span class="o">()</span>
    <span class="k">val</span> <span class="n">counts</span> <span class="k">=</span> <span class="n">countsByCategory</span><span class="o">.</span><span class="n">toArray</span><span class="o">.</span><span class="n">sortBy</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">_1</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">_2</span><span class="o">)</span>
    <span class="n">counts</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">toDouble</span> <span class="o">/</span> <span class="n">counts</span><span class="o">.</span><span class="n">sum</span><span class="o">)</span>
<span class="o">}</span>
</code></pre></div>
<p>Classifier가 무작위로 클래스를 선택하기 때문에 각 데이터에 대해서 Classifier가 정확한 클래스를 맞출 할 확률은 데이터에서 각 클래스가 차지하는 비율과 같다. 위 함수를 이용하여 다음과 같이 트레이닝 데이터와 Cross-validation 데이터에서 무작위로 클래스를 선택하는 Classifier의 정확도를 계산할 수 있다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">trainPriorProbabilities</span> <span class="k">=</span> <span class="n">classProbabilities</span><span class="o">(</span><span class="n">trainData</span><span class="o">)</span>
<span class="k">val</span> <span class="n">cvPriorProbabilities</span> <span class="k">=</span> <span class="n">classProbabilities</span><span class="o">(</span><span class="n">cvData</span><span class="o">)</span>
<span class="n">trainPriorProbabilities</span><span class="o">.</span><span class="n">zip</span><span class="o">(</span><span class="n">cvPriorProbabilities</span><span class="o">).</span><span class="n">map</span> <span class="o">{</span>
    <span class="k">case</span> <span class="o">(</span><span class="n">trainProb</span><span class="o">,</span> <span class="n">cvProb</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">trainProb</span> <span class="o">*</span> <span class="n">cvProb</span>
<span class="o">}.</span><span class="n">sum</span>

<span class="o">...</span>

<span class="nc">Double</span> <span class="k">=</span> <span class="mf">0.37742100814227625</span>
</code></pre></div>
<p>위 결과를 통해 Random Gessing 은 37%의 정확도를 가짐을 알 수 있다. 때문에 우리가 앞서 구한 70%의 정확도는 괜찮은 결과임을 알 수 있다. 하지만 이것은 <code>Tree.trainClassifier()</code>의 기본 파라미터만을 이용하여 계산한 것이기 때문에 Hyperparameter를 조절하여 더욱 성능을 끌어올릴 수 있다.</p>

<p><br>
<br></p>

<h2>Decision Tree Hyperparameters</h2>

<p>앞서 설명하였듯이 Decision Tree에는 세 가지의 Hyperparameter로 <em>최대 깊이</em>, <em>최대 bin의 수</em>, <em>impurity measure</em>가 존재한다.</p>

<p>Decision Tree의 최대 깊이는 Tree의 높이를 이야기한다. Tree의 깊이가 깊다는 것은 데이터를 분류하는데 까지의 과정이 세밀함을 의미하며, 깊이가 깊을 때는 좀 더 정확하게 분류를 할 수 있지만 <a href="http://sanghyukchun.github.io/59/">Overfitting</a>의 위험성이 있다.</p>

<p>Decision Tree는 각각의 질의 단계에서 각 단계에 맞는 decision을 내려야 한다. 이때 결정을 내리기 위한 질문들은 숫자 형태의 Feature인 경우에는 <code>feature &gt;= value</code>와 같은 형태이며, Categorical한 Feature인 경우에는 <code>feature in (value1, value2, ...)</code>형태를 갖는다. 이러한 decision rule의 셋이 각 단계에서 decision을 내리는 데에 사용된다. 이것들을 Spark MLlib에서는 <code>bin</code>이라 부른다. 사용되는 bin의 수가 클수록 계산 시간은 길어지지만 좀 더 최적화된 결과를 낼 수 있다.</p>

<p>Decision Tree를 형성하는데에 있어 좋은 Decision Rule이라 함은 데이터를 명확하게 구분짓는 Rule 일것이다. 예를 들면 어떤 Rule이 Covtype Dataset을 정확히 클래스 1~3과 4~7로 나눈다면 그 Rule은 매우 좋은 Rule이라 할 수 있다. 결론적으로 좋은 Rule을 고른다는 것은 <strong>데이터를 두 개의 서브셋으로 나눌 때, 그 사이의 불순물이 적도록 선택하는 것</strong>이다. 때문에 어떤 방식으로 불순물이 많은지 판단할지가 매우 중요한데, 일반적으로 많이 사용하는 방식은 <code>Gini</code>방식과 <code>Entropy</code>방식이다.</p>

<p>Gini 방식은 앞서 설명하였던 무작위로 클래스의 레이블을 선택하는 과정과 비슷하다. Gini impurity(불순도) 측정 방식은 어떤 한 클래스를 골라서 무작위로 라벨을 추정하였을 때, 그 추정이 틀릴 확률을 이용하여 계산된다. 만약 이 불순도가 0이 된다면 현재 데이터는 완벽히 한 클래스만 존재하여 정확히 분류가 된 것을 의미한다. 그리고 데이터의 모든 클래스가 같은 비율로 존재할 때 불순도가 제일 높다. 이러한 Gini 불순도 \(I_G\) 는 \( i = 1, 2, ..., N \) 클래스와, 각 클래스가 데이터 중에서 차지하는 비중인 \(p_i\)를 이용해 다음과 같이 표현 가능하다.</p>

<p>\( I_G(p) = \sum _{ i=1 }^{ N }{ { p }_{ i }(1-{ p }_{ i }) }  = 1 - \sum _{ i=1 }^{ N }{ { { p }_{ i } }^{ 2 } } \) </p>

<p>Entropy 방식은 Information Theory에서 나온 방법이다. 식이 유도되는 방식을 이야기 하기에는 어렵지만 <strong>목표하는 클래스의 서브셋이 얼마만큼의 불확실성을 갖는가에 대한 것</strong>이며, 다음과 같이 정의된다.</p>

<p>\( { I }_{ E }(p)=\sum _{ i=1 }^{ N }{ { p }_{ i }\log { \frac { 1 }{ p }  }  } = -\sum _{ i=1 }^{ N }{ { p }_{ i }log({ p }_{ i }) } \)</p>

<p>데이터셋에 따라 어느 측정 방식이 좋은지는 다르며, Spark의 MLlib 에서는 <code>Gini</code>방식이 기본값이다. 몇몇의 Decision Tree는 <code>Minimum Information Gain</code>이라는 방식을 이용하는데 아직 이 방식은 MLlib에 구현되어 있지 않다.</p>

<p><br>
<br></p>

<h2>Tuning Decision Trees</h2>

<p>위에서 설명한 파라미터를 조절하여 처음 생성한 Decision Tree 모델보다 성능을 개선시킬 것이다. 영화 추천 모델에서와 마찬가지로 다음 코드와 같이 간단한 형태의 파라미터 조절 실험이 가능하다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">evaluations</span> <span class="k">=</span> 
    <span class="k">for</span><span class="o">(</span><span class="n">impurity</span> <span class="k">&lt;-</span> <span class="nc">Array</span><span class="o">(</span><span class="s">&quot;gini&quot;</span><span class="o">,</span> <span class="s">&quot;entropy&quot;</span><span class="o">);</span>
        <span class="n">depth</span> <span class="k">&lt;-</span> <span class="nc">Array</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">20</span><span class="o">,</span> <span class="mi">30</span><span class="o">);</span>
        <span class="n">bins</span> <span class="k">&lt;-</span> <span class="nc">Array</span><span class="o">(</span><span class="mi">10</span><span class="o">,</span> <span class="mi">300</span><span class="o">))</span>
    <span class="k">yield</span> <span class="o">{</span>
        <span class="k">val</span> <span class="n">model</span> <span class="k">=</span>
            <span class="nc">DecisionTree</span><span class="o">.</span><span class="n">trainClassifier</span><span class="o">(</span><span class="n">trainData</span><span class="o">,</span> <span class="mi">7</span><span class="o">,</span> <span class="nc">Map</span><span class="o">[</span><span class="kt">Int</span>, <span class="kt">Int</span><span class="o">](),</span> <span class="n">impurity</span><span class="o">,</span> <span class="n">depth</span><span class="o">,</span> <span class="n">bins</span><span class="o">)</span>
        <span class="k">val</span> <span class="n">predictionsAndLabels</span> <span class="k">=</span> <span class="n">cvData</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">example</span> <span class="k">=&gt;</span>
            <span class="o">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="o">(</span><span class="n">example</span><span class="o">.</span><span class="n">features</span><span class="o">),</span> <span class="n">example</span><span class="o">.</span><span class="n">label</span><span class="o">)</span>
        <span class="o">)</span>
        <span class="k">val</span> <span class="n">accuracy</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MulticlassMetrics</span><span class="o">(</span><span class="n">predictionsAndLabels</span><span class="o">).</span><span class="n">precision</span>
        <span class="o">((</span><span class="n">impurity</span><span class="o">,</span> <span class="n">depth</span><span class="o">,</span> <span class="n">bins</span><span class="o">),</span> <span class="n">accuracy</span><span class="o">)</span>
    <span class="o">}</span>

<span class="n">evaluations</span><span class="o">.</span><span class="n">sortBy</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">_2</span><span class="o">).</span><span class="n">reverse</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>
</code></pre></div>
<p>위 코드의 수행 결과는 다음과 같다. 물론 세부적인 수치는 다를 수 있다.</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">((entropy,30,300),0.938073512955152)
((gini,30,300),0.9331152621158647)
((entropy,30,10),0.9135060686924334)
((gini,30,10),0.9122320736851166)
((entropy,20,300),0.9077386588620125)
((gini,20,300),0.9051734526986314)
((entropy,20,10),0.895394680210037)
((gini,20,10),0.8903675647757596)
((gini,1,300),0.6380304725832832)
((gini,1,10),0.6375484204183525)
((entropy,1,300),0.48788843935611603)
((entropy,1,10),0.48788843935611603)
</code></pre></div>
<p>이 결과로부터 Decision Tree의 깊이를 1로 하는 것은 결과를 생성하는데 부족하다는 것을 알 수 있다. 또한, bin의 수는 높을 수록 좋은 정확도를 보이는 경향을 보였다. 그리고 불순도를 판단하는 방법은 Entropy 방식이 조금 더 좋은 결과를 보였다. 결론적으로 <strong>Entropy방법</strong>, <strong>최대 깊이 30</strong>, <strong>300개의 bin</strong>을 이용하여 Decition Tree를 생성하였을 때 가장 높은 성능인 <strong>93.8%</strong>의 성능을 보였다.</p>

<p>여기서 우리는 찾아낸 파라미터들이 Overfitting 된 것이 아닌지 판단을 해 보아야 한다. 이것은 다음과 같이 위에서 구한 파라미터를 이용하여 트레이닝 데이터와 Cross-Validation 데이터를 이용하여 Decision Tree를 생성하였을 때의 성능을 확인함으로써 판단 가능하다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="nc">DecisionTree</span><span class="o">.</span><span class="n">trainClassifier</span><span class="o">(</span>
    <span class="n">trainData</span><span class="o">.</span><span class="n">union</span><span class="o">(</span><span class="n">cvData</span><span class="o">),</span> <span class="mi">7</span><span class="o">,</span> <span class="nc">Map</span><span class="o">[</span><span class="kt">Int</span>, <span class="kt">Int</span><span class="o">](),</span> <span class="s">&quot;entropy&quot;</span><span class="o">,</span> <span class="mi">30</span><span class="o">,</span> <span class="mi">300</span><span class="o">)</span>
<span class="k">val</span> <span class="n">accuracy</span> <span class="k">=</span> <span class="n">getMetrics</span><span class="o">(</span><span class="n">model</span><span class="o">,</span> <span class="n">testData</span><span class="o">).</span><span class="n">precision</span>

<span class="o">...</span>

<span class="n">accuracy</span><span class="k">:</span> <span class="kt">Double</span> <span class="o">=</span> <span class="mf">0.9427713442521098</span>
</code></pre></div>
<p>위 코드의 수행 결과는 94.2%의 정확도를 보인다. 만약 앞서 얻은 파라미터가 Overfitting된 파라미터였다면 Cross-Validation데이터를 union한 데이터에 대한 Decision Tree의 정확도는 더 떨어졌을 것이다. 하지만 앞서 수행하였던 결과보다 데이터를 추가하여 Decision Tree 트레이닝 하였고, 성능이 증가하였다. 따라서 앞에서 얻은 파라미터가 트레이닝 데이터에 Overfitting되지 않은 파라미터임을 알 수 있다.</p>

<p><br>
<br></p>

<h2>Categorical Features Revisited</h2>

<p>지금까지 작성한 예제 코드에서는 <code>Map[Int, Int]()</code> 파라미터에 대한 설명을 거의 하지 않고 진행하였다. 이 파라미터는 7과 같이 각각의 Categorical한 Feature의 값의 가지 수에 대한 것이다. Map의 key는 <strong>입력 벡터의 인덱스</strong>를 나타내며, value들은 <strong>벡터의 각 인덱스에 존재하는 Categorcal한 값의 가지 수</strong>를 나타낸다. 때문에 비어있는 <code>Map()</code>이 파라미터로 전달되었을 때는 <strong>Categorical한 값이 없음을 나타내며, 모든 값이 숫자 형태의 데이터임</strong>을 의미한다.</p>

<p>다행히도 지금까지 이용한 covtype 데이터셋은 Categorical Feature를 여러 개의 Numeric Feature를 이용하여 표현하고 있다. 이때, 0과 1을 이용한 binary 형태의 값 표현이기 때문에 Decision Tree를 구성할 때 큰 문제가 생기지는 않는다. 하지만 당연히도, 이러한 형태의 Categorical Feature에 대한 표현은 Decision Tree를 구성할 때 하나의 Categorical Feature를 구분하기 위해 그 Feature를 표현하는데 사용되는 모든 Numeric Feature를 고려하여 Decision Rule을 구성하게된다. 이때, 메모리 사용량도 증가할 것이며 속도 역시 감소할 것이다.</p>

<p>이러한 것을 피하는 방법은 다음과 같이 여러 개의 Numeric Feature로 구성되어 있는 하나의 Categorical Feature를 통합하여 재구성하는 것이다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="n">rawData</span><span class="o">.</span><span class="n">map</span> <span class="o">{</span> <span class="n">line</span> <span class="k">=&gt;</span>
    <span class="k">val</span> <span class="n">values</span> <span class="k">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="sc">&#39;,&#39;</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">toDouble</span><span class="o">)</span>
    <span class="k">val</span> <span class="n">wilderness</span> <span class="k">=</span> <span class="n">values</span><span class="o">.</span><span class="n">slice</span><span class="o">(</span><span class="mi">10</span><span class="o">,</span> <span class="mi">14</span><span class="o">).</span><span class="n">indexOf</span><span class="o">(</span><span class="mf">1.0</span><span class="o">).</span><span class="n">toDouble</span>
    <span class="k">val</span> <span class="n">soil</span> <span class="k">=</span> <span class="n">values</span><span class="o">.</span><span class="n">slice</span><span class="o">(</span><span class="mi">14</span><span class="o">,</span> <span class="mi">54</span><span class="o">).</span><span class="n">indexOf</span><span class="o">(</span><span class="mf">1.0</span><span class="o">).</span><span class="n">toDouble</span>
    <span class="k">val</span> <span class="n">featureVector</span> <span class="k">=</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="n">values</span><span class="o">.</span><span class="n">slice</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">10</span><span class="o">)</span> <span class="o">:+</span> <span class="n">wilderness</span> <span class="o">:+</span> <span class="n">soil</span><span class="o">)</span>
    <span class="k">val</span> <span class="n">label</span> <span class="k">=</span> <span class="n">values</span><span class="o">.</span><span class="n">last</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="nc">LabeledPoint</span><span class="o">(</span><span class="n">label</span><span class="o">,</span> <span class="n">featureVector</span><span class="o">)</span>
<span class="o">}</span>
</code></pre></div>
<p>위처럼 기존에 Categorical Feature를 여러 개의 Numeric Feature로 표현하던 것을 하나의 Feature로 변경한다. 그리고 다음의 코드에서처럼 DecisionTree를 생성할 때 Map()에 해당 Feature의 인덱스와 그 값의 가지 수를 함께 전달하여 Categorical Feature를 그대로 활용하도록 한다. 다만, bin의 수는 반드시 Categorical Feature의 가지 수 보다 커야 하기 때문에 bind르 40이상으로 설정하여 수행한다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nc">Array</span><span class="o">(</span><span class="n">trainData</span><span class="o">,</span> <span class="n">cvData</span><span class="o">,</span> <span class="n">testData</span><span class="o">)</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">randomSplit</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="mf">0.8</span><span class="o">,</span> <span class="mf">0.1</span><span class="o">,</span> <span class="mf">0.1</span><span class="o">))</span>
<span class="n">trainData</span><span class="o">.</span><span class="n">cache</span><span class="o">()</span>
<span class="n">cvData</span><span class="o">.</span><span class="n">cache</span><span class="o">()</span>
<span class="n">testData</span><span class="o">.</span><span class="n">cache</span><span class="o">()</span>

<span class="k">val</span> <span class="n">evaluations</span> <span class="k">=</span> 
    <span class="k">for</span><span class="o">(</span><span class="n">impurity</span> <span class="k">&lt;-</span> <span class="nc">Array</span><span class="o">(</span><span class="s">&quot;gini&quot;</span><span class="o">,</span> <span class="s">&quot;entropy&quot;</span><span class="o">);</span>
        <span class="n">depth</span> <span class="k">&lt;-</span> <span class="nc">Array</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">20</span><span class="o">,</span> <span class="mi">30</span><span class="o">);</span>
        <span class="n">bins</span> <span class="k">&lt;-</span> <span class="nc">Array</span><span class="o">(</span><span class="mi">40</span><span class="o">,</span> <span class="mi">300</span><span class="o">))</span>
    <span class="k">yield</span> <span class="o">{</span>
        <span class="n">println</span><span class="o">((</span><span class="n">impurity</span><span class="o">,</span> <span class="n">depth</span><span class="o">,</span> <span class="n">bins</span><span class="o">))</span>
        <span class="k">val</span> <span class="n">model</span> <span class="k">=</span>
            <span class="nc">DecisionTree</span><span class="o">.</span><span class="n">trainClassifier</span><span class="o">(</span><span class="n">trainData</span><span class="o">,</span> <span class="mi">7</span><span class="o">,</span> <span class="nc">Map</span><span class="o">(</span><span class="mi">10</span> <span class="o">-&gt;</span> <span class="mi">4</span><span class="o">,</span> <span class="mi">11</span> <span class="o">-&gt;</span> <span class="mi">40</span><span class="o">),</span> <span class="n">impurity</span><span class="o">,</span> <span class="n">depth</span><span class="o">,</span> <span class="n">bins</span><span class="o">)</span>
        <span class="k">val</span> <span class="n">predictionsAndLabels</span> <span class="k">=</span> <span class="n">cvData</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">example</span> <span class="k">=&gt;</span>
            <span class="o">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="o">(</span><span class="n">example</span><span class="o">.</span><span class="n">features</span><span class="o">),</span> <span class="n">example</span><span class="o">.</span><span class="n">label</span><span class="o">)</span>
        <span class="o">)</span>
        <span class="k">val</span> <span class="n">trainAccuracy</span> <span class="k">=</span> <span class="n">getMetrics</span><span class="o">(</span><span class="n">model</span><span class="o">,</span> <span class="n">trainData</span><span class="o">).</span><span class="n">precision</span>
        <span class="k">val</span> <span class="n">cvAccuracy</span> <span class="k">=</span> <span class="n">getMetrics</span><span class="o">(</span><span class="n">model</span><span class="o">,</span> <span class="n">cvData</span><span class="o">).</span><span class="n">precision</span>
        <span class="o">((</span><span class="n">impurity</span><span class="o">,</span> <span class="n">depth</span><span class="o">,</span> <span class="n">bins</span><span class="o">),</span> <span class="o">(</span><span class="n">trainAccuracy</span><span class="o">,</span> <span class="n">cvAccuracy</span><span class="o">))</span>
    <span class="o">}</span>

<span class="n">evaluations</span><span class="o">.</span><span class="n">sortBy</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">_2</span><span class="o">.</span><span class="n">_2</span><span class="o">).</span><span class="n">reverse</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>
</code></pre></div>
<p>위 예제의 수행 결과는 다음과 같다.</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">((entropy,30,300),(0.9997400744976563,0.9424945022597011))
((entropy,30,40),(0.9995381489007944,0.9389967273293969))
((gini,30,300),(0.9997142967618867,0.9377153642361171))
((gini,30,40),(0.9996197783973981,0.9343734307631036))
((entropy,20,300),(0.9675436825214062,0.9258194663295873))
((gini,20,40),(0.9666049433104628,0.9238974216896677))
((gini,20,300),(0.9692987166983876,0.9238627902547142))
((entropy,20,40),(0.966656498782002,0.9227892157711555))
((gini,1,300),(0.6335093379847826,0.6374261917542553))
((gini,1,40),(0.6328541538673048,0.6369413516649063))
((entropy,1,300),(0.4876546127110015,0.4874201312531385))
((entropy,1,40),(0.4876546127110015,0.4874201312531385))
</code></pre></div>
<p>위 결과는 트레이닝 셋에 대한 수행 결과는 Overfitting 된 결과를 보이지만 Cross-Validation 데이터를 이용해 정확도를 판별하였을 때에는 데이터를 변환하지 않았을 때의 성능과 비슷한 성능을 보였다. 또한 다음과 같이 트레이닝 셋에 Cross-Validation 데이터를 포함한 것을 이용해 Decision Tree를 훈련시켜 그 결과도 확인하였다. 그 결과 역시 변경 전의 결과와 비슷한 성능을 보였다. 하지만 두 경우 모두 약간의 성능 증가는 존재하였다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="nc">DecisionTree</span><span class="o">.</span><span class="n">trainClassifier</span><span class="o">(</span><span class="n">trainData</span><span class="o">.</span><span class="n">union</span><span class="o">(</span><span class="n">cvData</span><span class="o">),</span> <span class="mi">7</span><span class="o">,</span> <span class="nc">Map</span><span class="o">(</span><span class="mi">10</span> <span class="o">-&gt;</span> <span class="mi">4</span><span class="o">,</span> <span class="mi">11</span> <span class="o">-&gt;</span> <span class="mi">40</span><span class="o">),</span> <span class="s">&quot;entropy&quot;</span><span class="o">,</span> <span class="mi">30</span><span class="o">,</span> <span class="mi">300</span><span class="o">)</span>
<span class="k">val</span> <span class="n">accuracy</span> <span class="k">=</span> <span class="n">getMetrics</span><span class="o">(</span><span class="n">model</span><span class="o">,</span> <span class="n">testData</span><span class="o">).</span><span class="n">precision</span>
<span class="o">...</span>

<span class="n">accuracy</span><span class="k">:</span> <span class="kt">Double</span> <span class="o">=</span> <span class="mf">0.9450667034844589</span>
</code></pre></div>
<p><em>(실제 책에서는 3% 차이로 더 큰 차이가 발생하였으나, 이 글 작성시 수행한 실험에서는 큰 차이가 나지 않았다.)</em></p>

<p><br>
<br></p>

<h2>Random Decision Forests</h2>

<p>만약 위 코드를 그대로 따라왔다면, 직접 수행한 결과와 이 포스트에 있는 수행 결과가 약간 다를 것이다. 그 이유는 Decision Tree가 가지고 있는 랜덤성 때문이다. Decision Tree 알고리즘이 각 단계에서 가능한 모든 경우의 수를 고려하게되면 수많은 시간이 필요하기 때문에 그렇게 할 수 없다. 만약 하나의 Categorical Feature가 \(N\)가지의 경우를 갖는다면 \({ 2 }^{ N } - 2\)의 Decision Rule이 존재한다. 따라서 \(N\)이 커진다면 가능한 Decision Rule의 수 역시 기하급수적으로 증가하게 될 것이다.</p>

<p>그래서 모든 경우의 수를 확인하는 방법 대신에, 몇몇 휴리스틱한 방법을 이용하여 성능을 증가시킨다. 그 중 하나는 <code>배깅(Bagging)</code>이라는 방식인데, <strong>한 개의 Decision Tree가 아닌 여러 독립적인 Decision Tree를 이용하여 각 Tree가 특정 결과를 생성하고, 그 각 결과의 평균치 등을 이용하여 예측치를 결정하는 것</strong>이다. 단순히 이야기 하면 Voting 방식이다. 이러한 방식은 단순히 하나의 Decision Tree만으로 결과를 내는 것보다 정확한 결과를 낼 확률이 높으며, 이때 여러 독립적인 Decision Tree를 생성하는 과정에서 랜덤성(Randomness)이 활용되고, 이것이 <code>Random Decision Tree</code>의 주요 아이디어가 된다.</p>

<p>다음과 같이 Spark MLlib의 <code>RandomForest</code>를 이용하여 쉽게 Random Decision Forest를 생성할 수 있다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">forest</span> <span class="k">=</span> <span class="nc">RandomForest</span><span class="o">.</span><span class="n">trainClassifier</span><span class="o">(</span>
    <span class="n">trainData</span><span class="o">,</span> <span class="mi">7</span><span class="o">,</span> <span class="nc">Map</span><span class="o">(</span><span class="mi">10</span> <span class="o">-&gt;</span> <span class="mi">4</span><span class="o">,</span> <span class="mi">11</span> <span class="o">-&gt;</span> <span class="mi">40</span><span class="o">),</span> <span class="mi">20</span><span class="o">,</span> <span class="s">&quot;auto&quot;</span><span class="o">,</span> <span class="s">&quot;entropy&quot;</span><span class="o">,</span> <span class="mi">30</span><span class="o">,</span> <span class="mi">300</span><span class="o">)</span>
</code></pre></div>
<p>Random Decision Forest는 새로운 두 개의 파라미터가 등장한다. 첫 번째 파라미터는 몇 개의 Decision Tree를 생성할 것인지에 대한 파라미터이며, 본 예시에서는 20으로 정하였다. 한 개의 Decision Tree를 생성하는 것이 아니라 20개의 Tree를 생성하기 때문에 지금까지 수행하였던 예시들보다 수행 시간이 오래 걸린다. 두 번째 파라미터는 트리의 각 레벨에서 어떤 feature를 선택할지에 대해 평가를 하는 방식인데, 여기서는 &quot;auto&quot;를 이용하였다. Random Decision Forest에서는 모든 feature를 전부 고려하지 않고 전체 중 일부만 선택하여 활용하는데, 어떤 방식으로 일부를 선택할 것인지에 대한 것이다. 예측 과정은 단순히 Decision Tree들의 가중평균으로 계산된다. Categorcal Feature는 결과 중 가장 많이 나온 값으로 선택하는 방식을 따른다.</p>

<p>다음과 같이 생성한 Random Decision Forest의 성능을 평가할수 있다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">def</span> <span class="n">getForestMetrics</span><span class="o">(</span><span class="n">model</span><span class="k">:</span> <span class="kt">RandomForestModel</span><span class="o">,</span> <span class="n">data</span><span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">LabeledPoint</span><span class="o">])</span><span class="k">:</span> <span class="kt">MulticlassMetrics</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">predictionsAndLabels</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span> <span class="o">{</span>
        <span class="n">example</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="o">(</span><span class="n">example</span><span class="o">.</span><span class="n">features</span><span class="o">),</span> <span class="n">example</span><span class="o">.</span><span class="n">label</span><span class="o">)</span>
    <span class="o">}</span>
    <span class="k">new</span> <span class="nc">MulticlassMetrics</span><span class="o">(</span><span class="n">predictionsAndLabels</span><span class="o">)</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">accuracy</span> <span class="k">=</span> <span class="n">getForestMetrics</span><span class="o">(</span><span class="n">forest</span><span class="o">,</span> <span class="n">testData</span><span class="o">).</span><span class="n">precision</span>

<span class="o">...</span>

<span class="n">accuracy</span><span class="k">:</span> <span class="kt">Double</span> <span class="o">=</span> <span class="mf">0.9632742522824155</span>
</code></pre></div>
<p>트레이닝 데이터로만 생성한 Random Decision Forest의 정확성은 96.3%로 지금까지 생성하였던 단일 Decision Tree보다 성능이 높음을 알 수 있다.</p>

<p>Random Decision Forest는 Spark와 MapReduce와 같은 빅 데이터의 데이터 처리 방식과도 연관성이 있다. Random Decision Forest를 생성할 때는 각각의 Tree를 독립적으로 생성하는데, 이것은 언급한 빅데이터 기술들은 데이터를 독립적으로 처리하는 매커니즘을 포함하고 있기 때문이다.</p>

<p><br>
<br></p>

<h2>Making Predictions</h2>

<p>Decision Tree와 Random Decision Forest를 생성하는 과정이 흥미로웠지만, 이것은 완전한 목표가 아니다. 최종 목표는 주어진 벡터를 생성한 Model을 이용해 결과를 예측하는 것이다. 근데, 지금까지의 과정을 제대로 따라왔다면 정말로 쉽다. 이미 앞선 과정에서 <code>getMetrics</code> 함수와 <code>getForestMetrics</code> 함수 안에서 해당 과정을 수행하고 있기 때문이다.</p>

<p>DecisionTree와 RandomForest의 훈련 결과는 각각 DecisionTreeModel과 RandomForestModel 객체인데, 두 객체는 모두 <code>predict()</code>함수를 포함하고 있다. 이 함수는 벡터를 인자로 받아 해당 데이터에 맞는 예측 결과를 반환하는 함수이다. 따라서 다음과 같이 특정 벡터에 대해 그 결과를 예측할 수 있다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input</span> <span class="k">=</span> <span class="s">&quot;2709,125,28,67,23,3224,253,207,61,6094,0,29&quot;</span>
<span class="k">val</span> <span class="n">vector</span> <span class="k">=</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="n">input</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="sc">&#39;,&#39;</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">toDouble</span><span class="o">))</span>
<span class="n">forest</span><span class="o">.</span><span class="n">predict</span><span class="o">(</span><span class="n">vector</span><span class="o">)</span>

<span class="o">...</span>

<span class="nc">Double</span> <span class="k">=</span> <span class="mf">4.0</span>
</code></pre></div>
<p>이 결과는 4가 나와야 하는데, 이것은 위 벡터 <strong>&quot;2709,125,28,67,23,3224,253,207,61,6094,0,29&quot;</strong>의 예측 결과가 숲의 종류 <code>5</code>임을 뜻한다(원래의 데이터는 클래스가 1 부터 시작하고, 트레이닝에서 활용한 데이터는 0부터 시작하는 것으로 변경하였으므로). 이것은 Covtype 데이터 셋에서 &quot;Aspen&quot; 임을 뜻한다.</p>

<p>위 예시에서는 단순히 하나의 벡터에 대해서만 수행했지만, RDD로 구성된 여러 개의 벡터를 한번에 예측할 수도 있다.</p>

  </div><!-- /.entry-content -->
  
  <center><div><a href="/data%20analysis/2015/09/09/advanced-analytics-with-spark-ch4/" class="btn">Read More...</a></div></center>
  
</article><!-- /.hentry -->

<article class="hentry">
  <header>
    
      <div class="entry-image-index">
        <a href="/data%20analysis/2015/07/27/advanced-analytics-with-spark-ch3-2/" title="Spark & 머신 러닝 - Recommending Music - 2/2"><img src="/images/bg3.jpg" alt="Spark & 머신 러닝 - Recommending Music - 2/2"></a>
      </div><!-- /.entry-image -->
    
    <div class="entry-meta">
      <span class="entry-date date published updated"><time datetime="2015-07-27T17:09:00-04:00"><a href="/data%20analysis/2015/07/27/advanced-analytics-with-spark-ch3-2/">July 27, 2015</a></time></span><span class="author vcard"><span class="fn"><a href="/about/" title="About Hyunje Jo">Hyunje Jo</a></span></span>
      <!--
      
      <span class="entry-reading-time">
        <i class="fa fa-clock-o"></i>
        
Reading time ~1 minute
      </span>
      -->
      <!-- /.entry-reading-time -->
      
    </div><!-- /.entry-meta -->
    
      <h1 class="entry-title"><a href="/data%20analysis/2015/07/27/advanced-analytics-with-spark-ch3-2/" rel="bookmark" title="Spark & 머신 러닝 - Recommending Music - 2/2" itemprop="url">Spark & 머신 러닝 - Recommending Music - 2/2</a></h1>
    
  </header>
  <div class="entry-content" style="overflow:hidden; height:500px;">
    <p><a href="http://hyunje.com/data%20analysis/2015/07/13/advanced-analytics-with-spark-ch3-1/">지난 포스트</a>에 이어 ALS를 이용한 추천 알고리즘의 성능을 평가하는 과정에 대한 글이다.</p>

<p>이 포스트는 <a href="http://shop.oreilly.com/product/0636920035091.do">Advanced Analytics with Spark</a>을 정리한 글이다.
<br>
<br></p>

<h2>Evaluating Recommendation Quality</h2>

<p>추천의 수행 결과를 평가하는 것으로 가장 정확한 방법은, 각 사용자가 추천 결과를 보고 그것에 대해 평가를 내리는 것이 가장 정확한 방식이다. 하지만 이러한 과정은 몇몇의 사용자를 샘플링 하여 진행한다고 하더라도 실제적으로 불가능에 가까운 방식이다. 때문에 사용자들이 들었던 아티스트들은 끌리는 아티스트들이고, 사용자들이 듣지 않은 아티스트들은 그렇지 않은 아티스트라고 가정하여 평가를 수행하는 것이 납득할만한 방법이다. 이러한 가정은 문제를 위한 가정이긴 하지만, 다른 데이터를 추가적으로 사용하지 않고 적용시킬 수 있다는 장점이 있다.</p>

<p>이 방법을 이용하여 추천 모델을 평가하기 위해서는 데이터를 분리하여 분리된 데이터는 ALS 모델을 생성하는 과정에서 제외시키는 과정이 필요하다. 그러면 이 분리된 데이터는 사용자들에 대한 좋은 추천 결과들을 가지고 있는 것으로 해석될 수 있다. 결과적으로 추천 시스템은 분리된 데이터를 제외하고 추천 모델을 생성시킨 후에 추천을 수행할 것이고, 추천이 이상적이라면 추천 시스템이 생성한 추천 결과의 상위권에 이 분리된 데이터들이 존재해야 할 것이다.</p>

<p>추천 결과를 분리한 아티스트의 리스트와 비교하여 0.0에서 1.0의 범위를 갖는 값(높을 수록 좋은 추천 결과를 나타냄)으로 수치화시킬 수 있다. (모든 아티스트의 쌍과 비교할 수 있지만, 그렇게 되면 너무 많은 쌍이 발생할 수 있기 때문에 일부 샘플된 쌍만 비교하는 것으로 한다.) 그리고 여기서 0.5는 무작위로 추천을 수행하였을 때의 기대값이라 한다.</p>

<p>이 방식은 <a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic">ROC Curve</a>와 직접적인 연관성을 갖는다. 앞서 얘기한 방식은 <a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_curve">AUC, Area Under the Curve</a>을 나타내는데, 이것은 무작위로 생성된 추천 결과에 비해 좋은 추천 결과들이 얼마만큼의 좋은 추천을 수행했는가 판단하는데에 이용된다.</p>

<p>AUC는 일반적인 Binary Classifier 와 같은 일반적인 Classifier 에서도 평가 방법으로 많이 이용된다. Spark의 MLlib에서는 BinaryClassificationMetrics에 이것이 구현되어있다. 이 글에서는 <strong>각 사용자별 AUC</strong>를 계산하고, 그것을 <strong>평균</strong>낼 것이다.</p>

<p><br>
<br></p>

<h2>Computing AUC</h2>

<p>이 절에서 수행되는 코드는 <a href="http://hyunje.com/data%20analysis/2015/07/13/advanced-analytics-with-spark-ch3-1/">지난 포스트</a>의 코드까지 수행된 것을 가정한다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">allData</span> <span class="k">=</span> <span class="n">rawUserArtistData</span><span class="o">.</span><span class="n">map</span><span class="o">{</span> <span class="n">line</span> <span class="k">=&gt;</span> 
    <span class="k">val</span> <span class="nc">Array</span><span class="o">(</span><span class="n">userId</span><span class="o">,</span> <span class="n">artistId</span><span class="o">,</span> <span class="n">count</span><span class="o">)</span> <span class="k">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="sc">&#39; &#39;</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">toInt</span><span class="o">)</span>
    <span class="k">val</span> <span class="n">finalArtistId</span> <span class="k">=</span> <span class="n">bArtistAlias</span><span class="o">.</span><span class="n">value</span><span class="o">.</span><span class="n">getOrElse</span><span class="o">(</span><span class="n">artistId</span><span class="o">,</span> <span class="n">artistId</span><span class="o">)</span>
    <span class="nc">Rating</span><span class="o">(</span><span class="n">userId</span><span class="o">,</span> <span class="n">finalArtistId</span><span class="o">,</span> <span class="n">count</span><span class="o">)</span>
<span class="o">}.</span><span class="n">cache</span><span class="o">()</span>

<span class="k">val</span> <span class="nc">Array</span><span class="o">(</span><span class="n">trainData</span><span class="o">,</span> <span class="n">cvData</span><span class="o">)</span> <span class="k">=</span> <span class="n">allData</span><span class="o">.</span><span class="n">randomSplit</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="mf">0.9</span><span class="o">,</span> <span class="mf">0.1</span><span class="o">))</span>
<span class="n">trainData</span><span class="o">.</span><span class="n">cache</span><span class="o">()</span>
<span class="n">cvData</span><span class="o">.</span><span class="n">cache</span><span class="o">()</span>

<span class="k">val</span> <span class="n">allItemIDs</span> <span class="k">=</span> <span class="n">allData</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">product</span><span class="o">).</span><span class="n">distinct</span><span class="o">().</span><span class="n">collect</span><span class="o">()</span>
<span class="k">val</span> <span class="n">bAllItemIDs</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">broadcast</span><span class="o">(</span><span class="n">allItemIDs</span><span class="o">)</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="nc">ALS</span><span class="o">.</span><span class="n">trainImplicit</span><span class="o">(</span><span class="n">trainData</span><span class="o">,</span> <span class="mi">20</span><span class="o">,</span> <span class="mi">5</span><span class="o">,</span> <span class="mf">0.01</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">)</span>
</code></pre></div>
<p>위 코드는 데이터셋을 9:1의 비율로 나누어 90%의 데이터를 트레이닝 데이터로, 나머지 10%의 데이터를 Cross-Validation 데이터로 사용하여 추천 모델을 훈련시키는 과정을 나타낸다.</p>

<p>그리고 다음 코드는, 생성된 추천 모델의 <code>predict</code> 함수를 이용하여 AUC를 계산하는 것에 대한 함수이다. 이 함수를 그대로 shell 에 입력하거나, 따로 파일에 작성하여 이전 포스트 에서 수행하였던 방식처럼 불러와도 된다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.spark.rdd.RDD</span>
<span class="k">import</span> <span class="nn">org.apache.spark.broadcast.Broadcast</span>
<span class="k">import</span> <span class="nn">scala.collection.mutable.ArrayBuffer</span>
<span class="k">import</span> <span class="nn">scala.util.Random</span>

<span class="c1">// 각 사용자별로 AUC를 계산하고, 평균 AUC를 반환하는 함수.</span>
<span class="k">def</span> <span class="n">areaUnderCurve</span><span class="o">(</span>
      <span class="n">positiveData</span><span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">Rating</span><span class="o">],</span>
      <span class="n">bAllItemIDs</span><span class="k">:</span> <span class="kt">Broadcast</span><span class="o">[</span><span class="kt">Array</span><span class="o">[</span><span class="kt">Int</span><span class="o">]],</span>
      <span class="n">predictFunction</span><span class="k">:</span> <span class="o">(</span><span class="kt">RDD</span><span class="o">[(</span><span class="kt">Int</span>,<span class="kt">Int</span><span class="o">)]</span> <span class="o">=&gt;</span> <span class="nc">RDD</span><span class="o">[</span><span class="kt">Rating</span><span class="o">]))</span> <span class="k">=</span> <span class="o">{</span>

    <span class="c1">// Positive로 판단되는 결과들, 즉 전체 데이터에서 Cross-validation을 하기 위해 남겨둔</span>
    <span class="c1">// 10%의 데이터를 이용하여 Positive한 데이터로 저장한다.</span>
    <span class="k">val</span> <span class="n">positiveUserProducts</span> <span class="k">=</span> <span class="n">positiveData</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">r</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">r</span><span class="o">.</span><span class="n">user</span><span class="o">,</span> <span class="n">r</span><span class="o">.</span><span class="n">product</span><span class="o">))</span>
    <span class="c1">// Positive 데이터에서 (사용자, 아티스트ID)별로 각각의 쌍에 대한 예측치를 계산하고,</span>
    <span class="c1">// 그 결과를 사용자별로 그룹화한다.</span>
    <span class="k">val</span> <span class="n">positivePredictions</span> <span class="k">=</span> <span class="n">predictFunction</span><span class="o">(</span><span class="n">positiveUserProducts</span><span class="o">).</span><span class="n">groupBy</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">user</span><span class="o">)</span>

    <span class="c1">// 각 사용자에 대한 Negative 데이터(전체 데이터셋 - Positive 데이터)를 생성한다.</span>
    <span class="c1">// 전체 데이터 셋에서 Positive 데이터를 제외한 아이템 중 무작위로 선택한다.</span>
    <span class="k">val</span> <span class="n">negativeUserProducts</span> <span class="k">=</span> <span class="n">positiveUserProducts</span><span class="o">.</span><span class="n">groupByKey</span><span class="o">().</span><span class="n">mapPartitions</span> <span class="o">{</span>
      <span class="c1">// 각 파티션에 대해서 수행한다.</span>
      <span class="n">userIDAndPosItemIDs</span> <span class="k">=&gt;</span> <span class="o">{</span>
        <span class="c1">// 각 파티션 별로 난수 생성기를 초기화</span>
        <span class="k">val</span> <span class="n">random</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Random</span><span class="o">()</span>
        <span class="k">val</span> <span class="n">allItemIDs</span> <span class="k">=</span> <span class="n">bAllItemIDs</span><span class="o">.</span><span class="n">value</span>

        <span class="n">userIDAndPosItemIDs</span><span class="o">.</span><span class="n">map</span> <span class="o">{</span> <span class="k">case</span> <span class="o">(</span><span class="n">userID</span><span class="o">,</span> <span class="n">posItemIDs</span><span class="o">)</span> <span class="k">=&gt;</span>
          <span class="k">val</span> <span class="n">posItemIDSet</span> <span class="k">=</span> <span class="n">posItemIDs</span><span class="o">.</span><span class="n">toSet</span>
          <span class="k">val</span> <span class="n">negative</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ArrayBuffer</span><span class="o">[</span><span class="kt">Int</span><span class="o">]()</span>
          <span class="k">var</span> <span class="n">i</span> <span class="k">=</span> <span class="mi">0</span>
          <span class="c1">// Positive 아이템의 갯수를 벗어나지 않도록하는 범위 내에서</span>
          <span class="c1">// 모든 아이템 중 무작위로 아이템을 선택하여</span>
          <span class="c1">// Positive 아이템이 아니라면 Negative 아이템으로 간주한다.</span>
          <span class="k">while</span> <span class="o">(</span><span class="n">i</span> <span class="o">&lt;</span> <span class="n">allItemIDs</span><span class="o">.</span><span class="n">size</span> <span class="o">&amp;&amp;</span> <span class="n">negative</span><span class="o">.</span><span class="n">size</span> <span class="o">&lt;</span> <span class="n">posItemIDSet</span><span class="o">.</span><span class="n">size</span><span class="o">)</span> <span class="o">{</span>
            <span class="k">val</span> <span class="n">itemID</span> <span class="k">=</span> <span class="n">allItemIDs</span><span class="o">(</span><span class="n">random</span><span class="o">.</span><span class="n">nextInt</span><span class="o">(</span><span class="n">allItemIDs</span><span class="o">.</span><span class="n">size</span><span class="o">))</span>
            <span class="k">if</span> <span class="o">(!</span><span class="n">posItemIDSet</span><span class="o">.</span><span class="n">contains</span><span class="o">(</span><span class="n">itemID</span><span class="o">))</span> <span class="o">{</span>
              <span class="n">negative</span> <span class="o">+=</span> <span class="n">itemID</span>
            <span class="o">}</span>
            <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
          <span class="o">}</span>
          <span class="c1">// (사용자 아이디, Negative 아이템 아이디)의 쌍을 반환한다.</span>
          <span class="n">negative</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">itemID</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">userID</span><span class="o">,</span> <span class="n">itemID</span><span class="o">))</span>
        <span class="o">}</span>
      <span class="o">}</span>
    <span class="o">}.</span><span class="n">flatMap</span><span class="o">(</span><span class="n">t</span> <span class="k">=&gt;</span> <span class="n">t</span><span class="o">)</span>
    <span class="c1">// flatMap을 이용하여 묶여져 있는 셋을 하나의 큰 RDD로 쪼갠다.</span>

    <span class="c1">// Negative 아이템(아티스트)에 대한 예측치를 계산한다.</span>
    <span class="k">val</span> <span class="n">negativePredictions</span> <span class="k">=</span> <span class="n">predictFunction</span><span class="o">(</span><span class="n">negativeUserProducts</span><span class="o">).</span><span class="n">groupBy</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">user</span><span class="o">)</span>

    <span class="c1">// 각 사용자별로 Positive 아이템과 Negative 아이템을 Join 한다.</span>
    <span class="n">positivePredictions</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">negativePredictions</span><span class="o">).</span><span class="n">values</span><span class="o">.</span><span class="n">map</span> <span class="o">{</span>
      <span class="k">case</span> <span class="o">(</span><span class="n">positiveRatings</span><span class="o">,</span> <span class="n">negativeRatings</span><span class="o">)</span> <span class="k">=&gt;</span>
        <span class="c1">// AUC는 무작위로 선별된(처음에 10%를 무작위로 분리하였으므로) Positive 아이템의 Score가</span>
        <span class="c1">// 무작위로 선별된(negativeUserProducts 를 구할 때 무작위로 선택하였으므로) Negative 아이템의 Score보다</span>
        <span class="c1">// 높을 확률을 나타낸다. 이때, 모든 Postive 아이템과 Negative 아이템의 쌍을 비교하여 그 비율을 계산한다.</span>

        <span class="k">var</span> <span class="n">correct</span> <span class="k">=</span> <span class="mi">0L</span>
        <span class="k">var</span> <span class="n">total</span> <span class="k">=</span> <span class="mi">0L</span>
        <span class="c1">// 모든 Positive 아이템과 Negative 아이템의 쌍에 대해</span>
        <span class="k">for</span> <span class="o">(</span><span class="n">positive</span> <span class="k">&lt;-</span> <span class="n">positiveRatings</span><span class="o">;</span> <span class="n">negative</span> <span class="k">&lt;-</span> <span class="n">negativeRatings</span><span class="o">)</span> <span class="o">{</span>
          <span class="c1">// Positive 아이템의 예측치가 Negative 아이템의 예측치보다 높다면 옳은 추천 결과</span>
          <span class="k">if</span> <span class="o">(</span><span class="n">positive</span><span class="o">.</span><span class="n">rating</span> <span class="o">&gt;</span> <span class="n">negative</span><span class="o">.</span><span class="n">rating</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="mi">1</span>
          <span class="o">}</span>
          <span class="n">total</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="o">}</span>
        <span class="c1">// 전체 쌍에서 옳은 추천 결과의 비율을 이용한 각 사용자별 AUC 계산</span>
        <span class="n">correct</span><span class="o">.</span><span class="n">toDouble</span> <span class="o">/</span> <span class="n">total</span>
    <span class="o">}.</span><span class="n">mean</span><span class="o">()</span> <span class="c1">// 전체 사용자의 AUC 평균을 계산하고 리턴한다.</span>
  <span class="o">}</span>
</code></pre></div>
<p>위 함수를 이용하여 다음과 같이 AUC를 계산할 수 있다. 함수의 동작 과정에 대한 설명은 코드에 포함되어 있는 주석으로 대신한다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">auc</span> <span class="k">=</span> <span class="n">areaUnderCurve</span><span class="o">(</span><span class="n">cvData</span><span class="o">,</span> <span class="n">bAllItemIDs</span><span class="o">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="o">)</span>
<span class="o">...</span>
<span class="n">auc</span><span class="k">:</span> <span class="kt">Double</span> <span class="o">=</span> <span class="mf">0.9623184489901165</span>
</code></pre></div>
<p>수행 결과는 조금 다를 수 있겠지만 거의 0.96에 가까운 수치가 나올 것이다. 이 수치는 무작위로 추천을 수행했을 때의 기대값인 0.5 보다 많이 높은 값이며, 최대값인 1.0에 매우 가까운 수치이다. 따라서 괜찮은 추천을 수행해 주었다고 할 수 있다.</p>

<p>이 과정을 전체 데이터 셋을 90%의 트레이닝 데이터와 나머지 10% 데이터로 구분하는 것부터 다시 수행함으로써 좀 더 최적화된 평가 수치를 얻을 수 있다. 실제로 전체 데이터 셋을 \(k\)개의 서브셋으로 분리하고, \(k-1\)개의 서브셋을 트레이닝 데이터로, 나머지 한 개의 서브셋을 평가용으로 사용하여 \(k\)번 반복하는 방식이 존재한다. 이것이 일반적으로 불리는 <a href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)#k-fold_cross-validation">K-fold Cross-validation</a> 방식이다.</p>

<p>앞서 계산한 결과가 어느정도의 결과를 갖는지 간단한 벤치마크 값을 계산하여 비교해 볼 수도 있다. 모든 사용자에게 가장 많이 플레이 된 아티스트를 똑같이 추천해 주는 것이다. 이런 추천은 개인화된 추천이 아니지만 간단하고, 빠른 방법이다. 이 경우의 AUC를 계산하여 앞서 계산한 결과와 어느정도 차이가 있는지 확인해 볼 수 있다.</p>

<p>다음과 같이 함수 <code>predictMostListened</code>함수를 정의하여 사용한다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.spark.SparkContext</span>

<span class="k">def</span> <span class="n">predictMostListened</span><span class="o">(</span><span class="n">sc</span><span class="k">:</span> <span class="kt">SparkContext</span><span class="o">,</span> <span class="n">train</span><span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">Rating</span><span class="o">])(</span><span class="n">allData</span><span class="k">:</span> <span class="kt">RDD</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">Int</span><span class="o">)])</span> <span class="k">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">bListenCount</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">broadcast</span><span class="o">(</span>
        <span class="n">train</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">r</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">r</span><span class="o">.</span><span class="n">product</span><span class="o">,</span> <span class="n">r</span><span class="o">.</span><span class="n">rating</span><span class="o">)).</span><span class="n">reduceByKey</span><span class="o">(</span><span class="k">_</span> <span class="o">+</span> <span class="k">_</span><span class="o">).</span><span class="n">collectAsMap</span><span class="o">()</span>
    <span class="o">)</span>
    <span class="n">allData</span><span class="o">.</span><span class="n">map</span> <span class="o">{</span> <span class="k">case</span> <span class="o">(</span><span class="n">user</span><span class="o">,</span> <span class="n">product</span><span class="o">)</span> <span class="k">=&gt;</span>
        <span class="nc">Rating</span><span class="o">(</span><span class="n">user</span><span class="o">,</span> <span class="n">product</span><span class="o">,</span> <span class="n">bListenCount</span><span class="o">.</span><span class="n">value</span><span class="o">.</span><span class="n">getOrElse</span><span class="o">(</span><span class="n">product</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">))</span>
    <span class="o">}</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">auc</span> <span class="k">=</span> <span class="n">areaUnderCurve</span><span class="o">(</span><span class="n">cvData</span><span class="o">,</span> <span class="n">bAllItemIDs</span><span class="o">,</span> <span class="n">predictMostListened</span><span class="o">(</span><span class="n">sc</span><span class="o">,</span> <span class="n">trainData</span><span class="o">))</span>
</code></pre></div>
<p>이 결과는 0.93 정도가 나온다. 앞서 우리가 추천 모델을 이용하여 수행한 추천의 결과가 더 높은 것을 알 수 있다. 하지만 좀 더 결과를 좋게 만들 수 없을까?
<br>
<br></p>

<h2>Hyperparameter Selection</h2>

<p>한 가지 간단한 방법은 추천 모델 형성에 사용된 몇 개의 <a href="https://en.wikipedia.org/wiki/Hyperparameter">Hyperparameter</a>를 조절해보는 것이다. 지금까지의 추천 모델 형성 과정에서는 이 값에 대해 언급이 없었지만, 사용되었던 파라미터와 그 기본값은 다음과 같다.</p>

<h4>rank = 10</h4>

<p><em>rank</em> 파라미터는 <em>user-feature</em> 행렬과 <em>product-feature</em> 행렬을 구성할 때 column \(k\)의 크기를 의미한다.</p>

<h4>iterations = 5</h4>

<p><em>iterations</em>는 Matrix Factorization 과정을 몇번 반복할 것인가에 대한 것이다. 횟수가 많아질 수록 추천의 성능은 좋아지지만, 수행 시간이 늘어난다.</p>

<h4>lambda = 0.01</h4>

<p><em>Overfitting</em>을 막아주는 파라미터이다. 값이 높을수록 Overfitting 을 막아주지만, 너무 높다면 추천의 정확도를 저하시킨다.</p>

<h4>alpha = 1.0</h4>

<p><em>Alpha</em>는 Implicit Feedback 방식에서 사용되는 파라미터로, user-product의 baseline confidence(값이 존재하는 데이터와 그렇지 않은 데이터 중 어떤것에 초점을 둘 것인지)를 조절하는 파라미터이다.</p>

<p>이 파라미터들을 조절하여 추천 모델의 성능을 증가시킬 수 있다. 파라미터를 조절하여 최적의 값을 찾는 방식에는 다양한 방법이 있지만, 여기선 간단하게만 변화를 주어 테스트를 할 것이다. 다음 코드와 같이 각 <em>rank</em>, <em>lambda</em>, <em>alpha</em> 에 두 개의 값으로 변화를 주어 그 결과로 계산되는 AUC를 비교할 것이다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">evaluations</span> <span class="k">=</span>
    <span class="k">for</span><span class="o">(</span><span class="n">rank</span>    <span class="k">&lt;-</span> <span class="nc">Array</span><span class="o">(</span><span class="mi">10</span><span class="o">,</span> <span class="mi">50</span><span class="o">);</span>
        <span class="n">lambda</span>  <span class="k">&lt;-</span> <span class="nc">Array</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">0.0001</span><span class="o">);</span>
        <span class="n">alpha</span>   <span class="k">&lt;-</span> <span class="nc">Array</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">40.0</span><span class="o">))</span>
        <span class="k">yield</span> <span class="o">{</span>
         <span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="nc">ALS</span><span class="o">.</span><span class="n">trainImplicit</span><span class="o">(</span><span class="n">trainData</span><span class="o">,</span> <span class="n">rank</span><span class="o">,</span> <span class="mi">10</span><span class="o">,</span> <span class="n">lambda</span><span class="o">,</span> <span class="n">alpha</span><span class="o">)</span>
         <span class="k">val</span> <span class="n">auc</span> <span class="k">=</span> <span class="n">areaUnderCurve</span><span class="o">(</span><span class="n">cvData</span><span class="o">,</span> <span class="n">bAllItemIDs</span><span class="o">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="o">)</span>
         <span class="o">((</span><span class="n">rank</span><span class="o">,</span> <span class="n">lambda</span><span class="o">,</span> <span class="n">alpha</span><span class="o">),</span> <span class="n">auc</span><span class="o">)</span>
    <span class="o">}</span>

<span class="n">evaluations</span><span class="o">.</span><span class="n">sortBy</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">_2</span><span class="o">).</span><span class="n">reverse</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>
</code></pre></div>
<p>수행 결과는 다음과 같다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="o">((</span><span class="mi">10</span><span class="o">,</span><span class="mf">1.0</span><span class="o">,</span><span class="mf">40.0</span><span class="o">),</span><span class="mf">0.9775933769125035</span><span class="o">)</span>
<span class="o">((</span><span class="mi">50</span><span class="o">,</span><span class="mf">1.0</span><span class="o">,</span><span class="mf">40.0</span><span class="o">),</span><span class="mf">0.9775096131405069</span><span class="o">)</span>
<span class="o">((</span><span class="mi">10</span><span class="o">,</span><span class="mf">1.0E-4</span><span class="o">,</span><span class="mf">40.0</span><span class="o">),</span><span class="mf">0.9767512207167729</span><span class="o">)</span>
<span class="o">((</span><span class="mi">50</span><span class="o">,</span><span class="mf">1.0E-4</span><span class="o">,</span><span class="mf">40.0</span><span class="o">),</span><span class="mf">0.9761886422104153</span><span class="o">)</span>
<span class="o">((</span><span class="mi">10</span><span class="o">,</span><span class="mf">1.0</span><span class="o">,</span><span class="mf">1.0</span><span class="o">),</span><span class="mf">0.9691674538720272</span><span class="o">)</span>
<span class="o">((</span><span class="mi">50</span><span class="o">,</span><span class="mf">1.0</span><span class="o">,</span><span class="mf">1.0</span><span class="o">),</span><span class="mf">0.9670028532287775</span><span class="o">)</span>
<span class="o">((</span><span class="mi">10</span><span class="o">,</span><span class="mf">1.0E-4</span><span class="o">,</span><span class="mf">1.0</span><span class="o">),</span><span class="mf">0.9648010615992904</span><span class="o">)</span>
<span class="o">((</span><span class="mi">50</span><span class="o">,</span><span class="mf">1.0E-4</span><span class="o">,</span><span class="mf">1.0</span><span class="o">),</span><span class="mf">0.9545102924987607</span><span class="o">)</span>
</code></pre></div>
<p>위 결과로 보아 rank는 10, lambda는 1.0, alpha를 40으로 하였을 때가 기본 설정으로 하였을 때보다 추천 성능이 좋음을 알 수 있다. 이런 방식으로 추천 모델을 최적화할 수 있다.</p>

<p>여기서 각 파라미터가 추천 결과에 어떤 영향을 미치는지 분석할 수 있다. <em>Alpha</em> 파라미터는 1일 때보다 40일때 추천의 성능이 증가되었다. 흥미로운 점은 이 40이라는 값이 지난 포스트에서 언급한 논문이 제안한 기본값이라는 것이다. 그리고 낮은 값인 1 보다 큰 값인 40일 때 성능이 좋은 것으로 보아 사용자가 특정 아티스트를 들었다는 정보가 듣지 않았다는 정보보다 추천 모델을 형성하는데에 있어 더욱 효과적이라는 것을 나타낸다.</p>

<p><em>lambda</em>는 매우 적은 차이를 이끌어낸다. 하지만 높은 Lambda를 사용하였을 때 추천 성능이 더욱 좋은 것으로 보아 Overfitting을 효과적으로 방지하였음을 알 수 있다. Overfitting에 대해서는 다음 장에서 자세하게 살펴 볼 것이다.</p>

<p>column의 크기 \(k\)는 rank 파라미터의 값으로 보아 크게 중요하지 않음을 알 수 있다. 오히려 값이 50으로 클 때가 성능이 더 좋지 않았다. 따라서 너무 큰 \(k\)를 설정하게 되면 오히려 추천 성능이 감소함을 유추할 수 있다.</p>

<p>파라미터를 설정할 때 모든 파라미터에 대해 완벽하게 이해하고 있을 필요까지는 없다. 하지만 적어도 파라미터들이 어느 범위의 값을 갖는지 정도를 안다면, 여러 모델을 최적화하는데 많은 도움이 된다.</p>

  </div><!-- /.entry-content -->
  
  <center><div><a href="/data%20analysis/2015/07/27/advanced-analytics-with-spark-ch3-2/" class="btn">Read More...</a></div></center>
  
</article><!-- /.hentry -->

<article class="hentry">
  <header>
    
      <div class="entry-image-index">
        <a href="/data%20analysis/2015/07/13/advanced-analytics-with-spark-ch3-1/" title="Spark & 머신 러닝 - Recommending Music - 1/2"><img src="/images/bg2.jpg" alt="Spark & 머신 러닝 - Recommending Music - 1/2"></a>
      </div><!-- /.entry-image -->
    
    <div class="entry-meta">
      <span class="entry-date date published updated"><time datetime="2015-07-13T19:09:00-04:00"><a href="/data%20analysis/2015/07/13/advanced-analytics-with-spark-ch3-1/">July 13, 2015</a></time></span><span class="author vcard"><span class="fn"><a href="/about/" title="About Hyunje Jo">Hyunje Jo</a></span></span>
      <!--
      
      <span class="entry-reading-time">
        <i class="fa fa-clock-o"></i>
        
Reading time ~1 minute
      </span>
      -->
      <!-- /.entry-reading-time -->
      
    </div><!-- /.entry-meta -->
    
      <h1 class="entry-title"><a href="/data%20analysis/2015/07/13/advanced-analytics-with-spark-ch3-1/" rel="bookmark" title="Spark & 머신 러닝 - Recommending Music - 1/2" itemprop="url">Spark & 머신 러닝 - Recommending Music - 1/2</a></h1>
    
  </header>
  <div class="entry-content" style="overflow:hidden; height:500px;">
    <p>이 글에서는 Spark를 이용하여 추천을 수행하는 과정에 대해 설명한다. <a href="http://www-etud.iro.umontreal.ca/%7Ebergstrj/audioscrobbler_data.html">Audioscrobbler Dataset</a> 를 이용하여 사용자가 좋아할 만한 음악을 추천해 주는 작업을 할 것이다.</p>

<p>이 포스트는 <a href="http://shop.oreilly.com/product/0636920035091.do">Advanced Analytics with Spark</a>을 정리한 글이다.</p>

<p>Chapter 3를 두 개의 글로 나누었다. 첫 번째 글은 추천을 수행하고, 간단히 추천 수행 결과를 확인해 보는 정도로 마무리 하고, 두 번째 글은 생성한 추천 모델이 얼마나 효과적으로 추천을 수행해주는지 분석하는 과정이다.</p>

<p><br>
<br></p>

<h2>Introduction</h2>

<p>추천 엔진은 사람들이 가장 쉽게 접할 수 있는 머신 러닝의 한 예라고 할 수 있다. Amazon, Youtube과 같은 사이트는 물론 대부분의 서비스는 자체적으로 추천 기능을 제공한다. 추천 시스템의 결과물은 현재 시스템을 사용하고 있는 사람이 좋아할만한 아이템이기 때문에, 다른 머신 러닝 알고리즘에 비해 좀 더 직관적으로 이해할 수 있다. 그만큼 추천 시스템은 많은 사람들에게 이미 널리 알려져 있고, 익숙한 머신 러닝 알고리즘이다.</p>

<p>이 챕터에서는 Spark에 정의되어 있는 핵심 머신 러닝 알고리즘 중 추천 시스템과 연관이 있는 것들에 대해 알아볼 것이고, 그것을 이용해 사용자에게 음악을 추천 해 줄 것이다. 이러한 과정들은 Spark와 MLlib의 실제 예시가 될것이며, 이어지는 다른 챕터들에서 사용하게 될 머신 러닝과 관련된 아이디어들에도 도움을 주게 될 것이다.</p>

<p><br>
<br></p>

<h2>Data Set</h2>

<p>이 챕터에서 수행할 예시 데이터는 <a href="http://www-etud.iro.umontreal.ca/%7Ebergstrj/audioscrobbler_data.html">Audtioscrobbler에서 제공하는 데이터셋</a>이다. Audioscrobbler 는 Last.fm 에서 처음으로 활용한 음악 추천 시스템이다. Audioscrobbler는 사용자들이 듣는 음악 정보를 자동으로 서버로 전송하여 기록하는 API 를 제공하였는데, 이러한 API의 사용은 많은 사용자의 정보를 기록하는 것으로 이어졌고, Last.fm 에서는 이 정보를 강력한 음악 추천 엔진을 구성하는데 사용하였다.</p>

<p>그 당시의 대부분의 추천 엔진에 대한 연구는 평가기반(사용자 x가 아이템 a에 평점 5를 남겼다)의 데이터에 대한 것들이었다. 하지만 흥미롭게도 Audioscrobbler 데이터는 사용자들이 어떠한 음악을 플레이했다에 대한 정보(사용자 x는 음악 a를 플레이했다.)밖에 제공되지 않는다. 이러한 데이터는 기존 데이터에 비해 난이도가 있는데, 그 이유는 사용자가 음악을 재생했다는 정보가 그 음악을 좋아한다고는 볼 수 없기 때문이다. 이러한 형태의 데이터 셋을 <strong>Implicit Feedback Dataset</strong>이라 한다.</p>

<p>위 링크에서 데이터셋을 다운로드 받아 압축을 해제하면 몇 개의 파일이 나온다. 그 중 가장 핵심이 되는 데이터 파일은 <code>user_artist_data.txt</code> 파일이다. 이 파일은 141,000명의 사용자와 160만명의 아티스트에 대한 정보가 들어있으며 사용자의 아티스트에 대한 플레이 정보는 약 2400만 정도의 기록이 저장되어있다. <code>artist_data.txt</code>파일은 모든 아티스트에 대한 정보가 들어있지만, 이 데이터 안에는 같은 아티스트를 가리키지만 서로 다른 이름으로 저장되어 있는 경우가 있다. 때문에 이를 위해 같은 아티스트를 가리키고 있는 ID의 Map인 <code>artist_alias.txt</code> 파일이 존재한다.</p>

<p><br>
<br></p>

<h2>The Alternating Least Squares Recommender Algorithm</h2>

<p>추천을 수행하기에 앞서, 설명한 데이터 셋의 형태에 맞는 추천 알고리즘을 선택해야 한다. 우리가 가지고 있는 데이터 셋은 Implicit feedback 형태이며, 사용자에 대한 정보(성별, 나이 등)라던가 아티스트에 대한 정보 역시 존재하지 않는다. 따라서 활용할 수 있는 정보는 <strong>어떠한 사용자가 어떤 아티스트의 노래를 들었다</strong> 라는 정보 뿐이고, 이러한 기록만 이용해서 추천을 수행해야 한다.</p>

<p>이러한 조건에 알맞는 추천 알고리즘은 <a href="https://en.wikipedia.org/wiki/Collaborative_filtering">Collaborative Filtering, CF</a><a href="https://ko.wikipedia.org/wiki/%ED%98%91%EC%97%85_%ED%95%84%ED%84%B0%EB%A7%81">(협업 필터링)</a>이다. CF는 아이템이나 사용자의 속성을 사용하지 않고 단순히 둘 사이의 관계정보(이 데이터 셋에서는 음악 플레이 여부)만 이용하여 추천을 수행하는 알고리즘이다.</p>

<p>CF에는 여러 알고리즘들이 존재하는데, 여기선 Matrix Factorization 모델을 이용한 추천 알고리즘을 이용하여 추천을 수행한다. Matrix Factorization 계열의 추천 알고리즘은 \( i \times j\) 크기의 행렬을 생성하고, 사용자 \(i\)가 아티스트 \(j\)의 음악을 플레이 했다는 정보를 행렬의 데이터로 이용한다. 이 행렬을 \(A\)라 할때, 전체 데이터에 비해서 사용자-아티스트의 조합이 매우 적기 때문에 행렬 \(A\)의 데이터는 듬성듬성 존재한다(Sparse 하다고 한다).</p>

<p>Matrix Factorization 방식에서는 이 행렬 \(A\)를 두 개의 작은 행렬 \(X\)와 \(Y\)로 쪼갠다. 이 때 각 행렬의 크기는 \(i \times k\), \(j \times k\)로, 원래 행렬의 행과 열의 크기가 매우 크기 때문에 두 행렬의 행 역시 매우 크다. 그리고 \(k\)는 Latent factor로써, 사용자와 아티스트 사이의 연관을 표현하는데에 이용된다.</p>

<p><img src="https://dl.dropboxusercontent.com/u/97648427/blog-img/ch3-1.png" alt="Matrix Factorization"></p>

<p>위 그림 3-1[1]과 같이 행렬 \(X, Y\)를 계산한 후에, 사용자 \(i\)의 아티스트 \(j\)에 대한 평점을 계산하기 위해서는 행렬 \(X\)의 \(i\)번째 행과, 행렬 \(Y^T\)의 \(j\)번째 열을 곱하여 계산한다.</p>

<p>이러한 방법을 기반으로 한 추천 알고리즘이 많이 존재 하는데, 이 챕터에서 사용되는 알고리즘은 Alternating Least Squares 알고리즘이다. 이 알고리즘은 Netflix Prize 에서 우승한 논문인 &quot;Collaborative Filtering for the Implicit Feedback Datasets&quot;과, &quot;Large-scale Parallel Collaborative Filtering for the Netflix Prize&quot;에서 주로 사용된 방식이다. 또한 Spark의 MLlib 에는 이 두 논문의 구현체가 구현되어 있다. 이 것을 이용해 이번 챕터를 진행 할 것이다.</p>

<p><br>
<br></p>

<h2>Preparing the Data</h2>

<p>다운로드 받은 <a href="http://www-etud.iro.umontreal.ca/%7Ebergstrj/audioscrobbler_data.html">Audtioscrobbler에서 제공하는 데이터셋</a>을 압축 해제하고, HDFS에 업로드한다. 다음과 같이 <code>/audio</code> 경로에 업로드하는것을 가정한다.</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">-rw-r--r--   1 hyunje supergroup    2932731 2015-07-12 04:19 /audio/artist_alias.txt
-rw-r--r--   1 hyunje supergroup   55963575 2015-07-12 04:19 /audio/artist_data.txt
-rw-r--r--   1 hyunje supergroup  426761761 2015-07-12 04:19 /audio/user_artist_data.txt
</code></pre></div>
<p>또한, 데이터의 크기가 크고, 계산량이 많기 때문에 Spark Shell 을 수행시킬 때 다음과 같이 드라이버의 메모리 용량을 <strong>6GB</strong>이상을 확보시켜야 한다.</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash">spark-shell --driver-memory 6g --master <span class="nb">local</span><span class="o">[</span>2<span class="o">]</span>
</code></pre></div>
<p>Spark의 MLlib 에 한 가지 제한이 있는데, 사용자와 아이템 아이디의 크기가 <code>Integer.MAX_VALUE</code> 보다 크면 안된다는 것이다. 즉 <code>2147483647</code>을 초과할 수 없다. 이를 다음과 같이 확인해 볼 수 있다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">rawUserArtistData</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="o">(</span><span class="s">&quot;/audio/user_artist_data.txt&quot;</span><span class="o">)</span>
<span class="n">rawUserArtistData</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="sc">&#39; &#39;</span><span class="o">)(</span><span class="mi">0</span><span class="o">).</span><span class="n">toDouble</span><span class="o">).</span><span class="n">stats</span><span class="o">()</span>
<span class="n">rawUserArtistData</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="sc">&#39; &#39;</span><span class="o">)(</span><span class="mi">1</span><span class="o">).</span><span class="n">toDouble</span><span class="o">).</span><span class="n">stats</span><span class="o">()</span>
</code></pre></div>
<p>위 명령어의 수행 결과는 다음과 같으며, 이는 데이터를 다른 변환 없이 그대로 사용해도 무방함을 나타낸다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="nc">StatCounter</span> <span class="k">=</span> <span class="o">(</span><span class="n">count</span><span class="k">:</span> <span class="err">24296858</span><span class="o">,</span> <span class="n">mean</span><span class="k">:</span> <span class="err">1947573</span><span class="kt">.</span><span class="err">265353</span><span class="o">,</span> <span class="n">stdev</span><span class="k">:</span> <span class="err">496000</span><span class="kt">.</span><span class="err">544975</span><span class="o">,</span> <span class="n">max</span><span class="k">:</span> <span class="err">2443548</span><span class="kt">.</span><span class="err">000000</span><span class="o">,</span> <span class="n">min</span><span class="k">:</span> <span class="err">90</span><span class="kt">.</span><span class="err">000000</span><span class="o">)</span>
<span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="nc">StatCounter</span> <span class="k">=</span> <span class="o">(</span><span class="n">count</span><span class="k">:</span> <span class="err">24296858</span><span class="o">,</span> <span class="n">mean</span><span class="k">:</span> <span class="err">1718704</span><span class="kt">.</span><span class="err">093757</span><span class="o">,</span> <span class="n">stdev</span><span class="k">:</span> <span class="err">2539389</span><span class="kt">.</span><span class="err">040171</span><span class="o">,</span> <span class="n">max</span><span class="k">:</span> <span class="err">10794401</span><span class="kt">.</span><span class="err">000000</span><span class="o">,</span> <span class="n">min</span><span class="k">:</span> <span class="err">1</span><span class="kt">.</span><span class="err">000000</span><span class="o">)</span>
</code></pre></div>
<p>그리고 추천을 수행하기 위해 아티스트의 데이터를 읽어 이를 기억해야 할 필요가 있다. 다음과 코드를 이용해 아티스트 데이터를 불러올 수 있다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">rawArtistData</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="o">(</span><span class="s">&quot;/audio/artist_data.txt&quot;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">artistById</span> <span class="k">=</span> <span class="n">rawArtistData</span><span class="o">.</span><span class="n">flatMap</span><span class="o">(</span> <span class="n">line</span> <span class="k">=&gt;</span> <span class="o">{</span>
    <span class="k">val</span> <span class="o">(</span><span class="n">id</span><span class="o">,</span> <span class="n">name</span><span class="o">)</span> <span class="k">=</span> <span class="n">line</span><span class="o">.</span><span class="n">span</span><span class="o">(</span><span class="k">_</span> <span class="o">!=</span> <span class="sc">&#39;\t&#39;</span><span class="o">)</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">name</span><span class="o">.</span><span class="n">isEmpty</span><span class="o">)</span> <span class="o">{</span>
        <span class="nc">None</span>
    <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
        <span class="k">try</span> <span class="o">{</span>
            <span class="nc">Some</span><span class="o">((</span><span class="n">id</span><span class="o">.</span><span class="n">toInt</span><span class="o">,</span> <span class="n">name</span><span class="o">.</span><span class="n">trim</span><span class="o">))</span>
        <span class="o">}</span> <span class="k">catch</span> <span class="o">{</span>
            <span class="k">case</span> <span class="n">e</span><span class="k">:</span> <span class="kt">NumberFormatException</span> <span class="o">=&gt;</span> <span class="nc">None</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">})</span>
</code></pre></div>
<p>또한, 앞서 설명하였듯이 각 아티스트가 오타 등의 이유로 다른 텍스트로 표현될 수 있기 때문에 이를 하나로 통합시켜야 한다. <code>artist_alias.txt</code> 파일의 각 행은 두 개의 열 <code>badID \t good ID</code>로 이루어져 있으며, 해당 파일을 읽어 드라이버 에서 Map 형태로 기억하고 있는다. 이 작업은 다음 코드를 수행함으로써 이뤄진다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">rawArtistAlias</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="o">(</span><span class="s">&quot;/audio/artist_alias.txt&quot;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">artistAlias</span> <span class="k">=</span> <span class="n">rawArtistAlias</span><span class="o">.</span><span class="n">flatMap</span><span class="o">(</span> <span class="n">line</span> <span class="k">=&gt;</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">tokens</span> <span class="k">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="sc">&#39;\t&#39;</span><span class="o">)</span>
    <span class="k">if</span><span class="o">(</span><span class="n">tokens</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="n">isEmpty</span><span class="o">)</span> <span class="o">{</span>
        <span class="nc">None</span>
    <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
        <span class="nc">Some</span><span class="o">((</span><span class="n">tokens</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="n">toInt</span><span class="o">,</span> <span class="n">tokens</span><span class="o">(</span><span class="mi">1</span><span class="o">).</span><span class="n">toInt</span><span class="o">))</span>
    <span class="o">}</span>
<span class="o">}).</span><span class="n">collectAsMap</span><span class="o">()</span>
</code></pre></div>
<p><code>artistAlias.get(6803336)</code>의 결과는 아이디 <strong>1000010</strong>이기 때문에, 다음과 같은 예시를 통해 정상적으로 데이터가 불러와졌는지 확인할 수 있다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="n">artistById</span><span class="o">.</span><span class="n">lookup</span><span class="o">(</span><span class="mi">6803336</span><span class="o">)</span>
<span class="n">artistById</span><span class="o">.</span><span class="n">lookup</span><span class="o">(</span><span class="mi">1000010</span><span class="o">)</span>
</code></pre></div>
<p>위 코드의 수행 결과는 각각 <code>Aerosmith (unplugged)</code>와 <code>Aerosmith</code>를 나타내며, 이는 정상적인 결과를 의미한다.</p>

<h2>Building a First Model</h2>

<p>Spark 의 MLlib에 구현되어 있는 ALS를 사용하기 위해선 두 가지의 변환 과정이 필요하다. 첫번째는 기존에 구한 아티스트의 ID를 앞서 생성한 Map 을 이용하여 같은 ID끼리 묶어야 하며, 데이터를 MLlib의 ALS에서 사용하는 입력 형태인 <strong>Rating</strong> 객체로 변환해야 한다. <strong>Rating</strong>객체는 <code>사용자ID-ProductID-Value</code>형태를 갖는 객체인데, 이름은 Rating 이지만 Implicit 형태의 데이터에서도 사용 가능하다. 이 챕터에서는 Value를 ProductID 를 아티스트의 ID, Value를 사용자가 해당 아티스트의 노래를 재생한 횟수로 사용할 것이다. 다음과 같은 코드를 이용하여 추천을 수행하기 위한 데이터를 준비한다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.spark.mllib.recommendation._</span>

<span class="k">val</span> <span class="n">bArtistAlias</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">broadcast</span><span class="o">(</span><span class="n">artistAlias</span><span class="o">)</span>
<span class="k">val</span> <span class="n">trainData</span> <span class="k">=</span> <span class="n">rawUserArtistData</span><span class="o">.</span><span class="n">map</span><span class="o">(</span> <span class="n">line</span> <span class="k">=&gt;</span> <span class="o">{</span>
    <span class="k">val</span> <span class="nc">Array</span><span class="o">(</span><span class="n">userId</span><span class="o">,</span> <span class="n">artistId</span><span class="o">,</span> <span class="n">count</span><span class="o">)</span> <span class="k">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="sc">&#39; &#39;</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">toInt</span><span class="o">)</span>
    <span class="k">val</span> <span class="n">finalArtistId</span> <span class="k">=</span> <span class="n">bArtistAlias</span><span class="o">.</span><span class="n">value</span><span class="o">.</span><span class="n">getOrElse</span><span class="o">(</span><span class="n">artistId</span><span class="o">,</span> <span class="n">artistId</span><span class="o">)</span>
    <span class="nc">Rating</span><span class="o">(</span><span class="n">userId</span><span class="o">,</span> <span class="n">finalArtistId</span><span class="o">,</span> <span class="n">count</span><span class="o">)</span>
<span class="o">}).</span><span class="n">cache</span><span class="o">()</span>
</code></pre></div>
<p>위 코드에서 중요한 부분은 기존에 생성하였던 <code>artistAlias</code> Map 을 <strong>broadcast</strong>하는 과정이다. Broadcast를 하지 않는다면 artistAlias 를 Spark가 생성하는 모든 Task 마다 복사하여 사용하게 된다. 하지만 이러한 작업은 큰 비용을 소비한다. 각각의 과정은 최소 몇 메가 바이트 에서 몇십 메가 바이트(크기에 따라 다르며, 이 예시에서의 크기임)를 소비하기 때문에, JVM에서 생성하는 모든 Task 에 이 데이터를 복사한다는 것은 매우 비효율적이다.</p>

<p>따라서 생성한 Map을 Broadcasting 함으로써 Spark Cluster의 각 Executer 가 단 하나의 Map만 유지할 수 있도록 한다. 때문에 Cluster에서 여러 Executer 가 수많은 Task 를 생성할 때 메모리를 효율적으로 관리할 수 있도록 해준다.</p>

<p>그리고 지금까지 계산한 결과를 <strong>cache()</strong>를 통해 메모리에 임시 저장함으로써, <code>trainData</code> 변수를 접근할 때마다 map 을 다시 수행하는 것을 막는다.</p>

<p>생성한 변수들을 이용해 다음과 같이 추천 모델을 생성할 수 있다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="nc">ALS</span><span class="o">.</span><span class="n">trainImplicit</span><span class="o">(</span><span class="n">trainData</span><span class="o">,</span> <span class="mi">10</span><span class="o">,</span> <span class="mi">5</span><span class="o">,</span> <span class="mf">0.01</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">)</span>
</code></pre></div>
<p>위 과정은 앞에서 설명한 MatrixFactoriation 방식을 이용해 추천 모델을 생성하는 과정이다. 이때 클러스터의 상태에 따라 수행시간은 몇 분 정도 수행될 수 있다. 그리고 다음 코드를 수행함으로써 내부 Feature 들이 정상적으로 계산되었는지 확인한다(정확한 값인지는 모르지만).</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="n">model</span><span class="o">.</span><span class="n">userFeatures</span><span class="o">.</span><span class="n">mapValues</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">mkString</span><span class="o">(</span><span class="s">&quot;, &quot;</span><span class="o">)).</span><span class="n">first</span><span class="o">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">productFeatures</span><span class="o">.</span><span class="n">mapValues</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">mkString</span><span class="o">(</span><span class="s">&quot;, &quot;</span><span class="o">)).</span><span class="n">first</span><span class="o">()</span>

<span class="o">...</span>

<span class="o">(</span><span class="nc">Int</span><span class="o">,</span> <span class="nc">String</span><span class="o">)</span> <span class="k">=</span> <span class="o">(</span><span class="mi">90</span><span class="o">,-</span><span class="mf">0.8930547833442688</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.7431690096855164</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.6351532936096191</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.28394362330436707</span><span class="o">,</span> <span class="mf">0.14852239191532135</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.37798216938972473</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.923484742641449</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.12640361487865448</span><span class="o">,</span> <span class="mf">0.5575262308120728</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.35868826508522034</span><span class="o">)</span>
<span class="o">(</span><span class="nc">Int</span><span class="o">,</span> <span class="nc">String</span><span class="o">)</span> <span class="k">=</span> <span class="o">(</span><span class="mi">2</span><span class="o">,-</span><span class="mf">0.08458994328975677</span><span class="o">,</span> <span class="mf">0.027468876913189888</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.16536176204681396</span><span class="o">,</span> <span class="mf">0.08694511651992798</span><span class="o">,</span> <span class="mf">0.019154658541083336</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.12874850630760193</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.04696394130587578</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.0629991888999939</span><span class="o">,</span> <span class="mf">0.15156564116477966</span><span class="o">,</span> <span class="mf">0.0011008649598807096</span><span class="o">)</span>
</code></pre></div>
<p>알고리즘이 랜덤성을 갖고 있기 때문에 수행 결과는 위와 다를 수 있다.</p>

<p><br>
<br></p>

<h2>Spot Checking Recommendations</h2>

<p>이제 실제로 사용자들에게 추천을 잘 수행해 주었는가를 확인해 봐야 한다. 2093760 사용자에 대해 과연 추천을 잘 수행했는지 확인해 볼 것이다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">rawArtistsForUser</span> <span class="k">=</span> <span class="n">rawUserArtistData</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="sc">&#39; &#39;</span><span class="o">)).</span><span class="n">filter</span><span class="o">({</span>
    <span class="k">case</span> <span class="nc">Array</span><span class="o">(</span><span class="n">user</span><span class="o">,</span><span class="k">_</span><span class="o">,</span><span class="k">_</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">user</span><span class="o">.</span><span class="n">toInt</span> <span class="o">==</span> <span class="mi">2093760</span>
<span class="o">})</span>

<span class="k">val</span> <span class="n">existingProducts</span> <span class="k">=</span> <span class="n">rawArtistsForUser</span><span class="o">.</span><span class="n">map</span><span class="o">({</span>
    <span class="k">case</span> <span class="nc">Array</span><span class="o">(</span><span class="k">_</span><span class="o">,</span><span class="n">artist</span><span class="o">,</span><span class="k">_</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">artist</span><span class="o">.</span><span class="n">toInt</span>
<span class="o">}).</span><span class="n">collect</span><span class="o">.</span><span class="n">toSet</span>

<span class="n">artistById</span><span class="o">.</span><span class="n">filter</span><span class="o">({</span>
    <span class="k">case</span> <span class="o">(</span><span class="n">id</span><span class="o">,</span> <span class="n">name</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">existingProducts</span><span class="o">.</span><span class="n">contains</span><span class="o">(</span><span class="n">id</span><span class="o">)</span>
<span class="o">}).</span><span class="n">values</span><span class="o">.</span><span class="n">collect</span><span class="o">().</span><span class="n">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>
</code></pre></div>
<p>위 코드의 수행 결과는 다음과 같은 결과를 보이는데,</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">David Gray
Blackalicious
Jurassic 5
The Saw Doctors
Xzibit
</code></pre></div>
<p>이 결과는 2093760 사용자가 플레이한 아티스트의 목록이다. 플레이했던 아티스트로 보아, 주로 pop과 hip-hop 음악을 플레이했음을 알 수 있다. (물론 나를 포함한 이 글을 읽는 사람들은 한국인이기 때문에 잘 모를 것이다... 책에서 그렇다고 하니 일단 믿어 보자.) 이러한 정보를 갖고 있는 사용자에게는 어떤 아이템들을 추천 해 주었는가는 다음 코드를 이용해 확인할 수 있다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">recommendations</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">recommendProducts</span><span class="o">(</span><span class="mi">2093760</span><span class="o">,</span> <span class="mi">5</span><span class="o">)</span>
<span class="n">recommendations</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>
</code></pre></div>
<p>위 결과는 다음과 같이 상위 5개의 아이템을 추천해 준 결과를 출력한다.</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">Rating(2093760,1300642,0.027983077231064094)
Rating(2093760,2814,0.027609241365462805)
Rating(2093760,1001819,0.027584770801984716)
Rating(2093760,1037970,0.027400202899883735)
Rating(2093760,829,0.027248976510692982)
</code></pre></div>
<p>추천의 수행 결과는 앞서 생성하였던 <code>Rating</code> 객체를 이용하여 표현된다. Rating 객체에는 (사용자 ID, 아티스트 ID, 값) 형태의 데이터가 존재한다. 이름은 Rating 이지만 세번째 필드의 값이 그대로 평점 값을 나타내는 것은 아님을 주의해야한다. ALS 알고리즘에서는 이 값은 0 과 1 사이의 값을 가지며 값이 높을 수록 좋은 추천을 이야기한다.</p>

<p>다음 코드를 이용해 추천된 결과에서 각각의 아티스트 ID 가 어떤 아티스트인지 이름을 확인해 볼 수 있다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">recommendedProductIDs</span> <span class="k">=</span> <span class="n">recommendations</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">product</span><span class="o">).</span><span class="n">toSet</span>

<span class="n">artistById</span><span class="o">.</span><span class="n">filter</span><span class="o">({</span>
    <span class="k">case</span> <span class="o">(</span><span class="n">id</span><span class="o">,</span> <span class="n">name</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">recommendedProductIDs</span><span class="o">.</span><span class="n">contains</span><span class="o">(</span><span class="n">id</span><span class="o">)</span>
<span class="o">}).</span><span class="n">values</span><span class="o">.</span><span class="n">collect</span><span class="o">().</span><span class="n">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>
</code></pre></div>
<p>수행 결과는 다음과 같다. 이 결과는 수행시마다 다를 수 있다.</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">50 Cent
Nas
Kanye West
2Pac
The Game
</code></pre></div>
<p>위 목록의 아티스트는 모두 hip-hop 관련 아티스트이다. 얼핏 보기엔 괜찮아 보이지만 너무 대중적인 가수들이며 사용자의 개인적인 성향을 파악하지는 못한 것 같은 결과를 보인다.</p>

<p><br>
<br></p>

<h2>Next Post</h2>

<p>지금까지는 사용자들의 음악 플레이 기록을 이용하여, 아티스트를 추천해주는 과정을 수행하였다. 다음 포스트에서는 수행한 추천이 얼마나 잘 수행되었는지 평가하는 과정을 진행할 것이다.</p>

<p><br>
<br></p>

<h2>References</h2>

<p>[1] : <a href="http://shop.oreilly.com/product/0636920035091.do">Advanced Analytics with Spark</a></p>

  </div><!-- /.entry-content -->
  
  <center><div><a href="/data%20analysis/2015/07/13/advanced-analytics-with-spark-ch3-1/" class="btn">Read More...</a></div></center>
  
</article><!-- /.hentry -->



<div class="pagination">
  <ul class="inline-list">
    
    
      
        <li><a href="" class="btn">Previous</a></li>
      
    

    
    
      <li><a href="">1</a></li>
    

    
    

    
    
    

    
      
        <li><strong class="current-page">2</strong></li>
      
    
      
        
        
        
          
          
        
        <li><a href="/page3/">3</a></li>
      
    
      
        
        
        
          
          
        
        <li><a href="/page4/">4</a></li>
      
    

    
    

    
      <li><a href="/page5/">5</a></li>
    

    
    
      <li><a href="/page3/" class="btn">Next</a></li>
    
  </ul>
</div>

</div><!-- /#main -->

<div class="footer-wrapper">
  <footer role="contentinfo">
    <span>&copy; 2016 Hyunje Jo.</span>
  </footer>
</div><!-- /.footer-wrapper -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="/assets/js/scripts.min.js"></script>

<!-- Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-62281776-2', 'auto');
  ga('send', 'pageview');

</script>


<!-- Mathjax -->
<script type="text/javascript"
    src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


          

</body>
</html>