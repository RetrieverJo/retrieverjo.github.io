<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>Spark RDD의 함수 동작 방식 &#8211; Hyunje Blog</title>
<meta name="description" content="Blog for Hyunje">
<meta name="keywords" content="Spark, Spark RDD">



<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark RDD의 함수 동작 방식">
<meta property="og:description" content="Blog for Hyunje">
<meta property="og:url" content="/data%20analysis/2014/11/06/spark-rdd-functions/">
<meta property="og:site_name" content="Hyunje Blog">





<link rel="canonical" href="/data%20analysis/2014/11/06/spark-rdd-functions/">
<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Hyunje Blog Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<!-- Webfonts -->
<link href="//fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic" rel="stylesheet" type="text/css">
<link href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
<link href='//fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
<link href='//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

<meta http-equiv="cleartype" content="on">

<!-- Load Modernizr -->
<script src="/assets/js/vendor/modernizr-2.6.2.custom.min.js"></script>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="/images/apple-touch-icon-144x144-precomposed.png">




<style type="text/css">body {background-image:url(/images/white.jpg);}</style>


</head>

<body id="post" class="feature">

<!--[if lt IE 9]><div class="upgrade"><strong><a href="http://whatbrowser.org/">Your browser is quite old!</strong> Why not upgrade to a different browser to better enjoy this site?</a></div><![endif]-->
<nav id="dl-menu" class="dl-menuwrapper" role="navigation">
	<button class="dl-trigger">Open Menu</button>
	<ul class="dl-menu">
		<li><a href="/">Home</a></li>
		<li>
			<a href="#">About</a>
			<ul class="dl-submenu">
				<li>
					<img src="/images/avatar.jpg" alt="Hyunje Jo photo" class="author-photo">
					<h4>Hyunje Jo</h4>
					<p>Bigdata-technology based Machine Learning & Data Analysis</p>
				</li>
				<li><a href="/about/"><span class="btn btn-inverse">Learn More</span></a></li>
				<li>
					<a href="mailto:retriever89@gmail.com"><i class="fa fa-fw fa-envelope"></i> Email</a>
				</li>
				
				<li>
					<a href="https://facebook.com/RetrieverJo"><i class="fa fa-fw fa-facebook"></i> Facebook</a>
				</li>
				
				
				<li>
					<a href="https://github.com/retrieverJo"><i class="fa fa-fw fa-github"></i> GitHub</a>
				</li>
				
				
				
				
			</ul><!-- /.dl-submenu -->
		</li>
		<li>
			<a href="#">Posts</a>
			<ul class="dl-submenu">
				<li><a href="/posts/">All Posts</a></li>
				<li><a href="/categories/">All Categories</a></li>
				<li><a href="/tags/">All Tags</a></li>
			</ul>
		</li>
		<!--
		
	    
	        
	    
	    <li><a href="/theme-setup/" >Theme Setup</a></li>
	  
	    
	        
	        
	    <li><a href="http://mademistakes.com" target="_blank">External Link</a></li>
	  
	  	-->
	</ul><!-- /.dl-menu -->
</nav><!-- /.dl-menuwrapper -->



<div class="entry-header">
  <div class="image-credit">Image source: Hyunje Jo</div><!-- /.image-credit -->
  <div class="entry-image">
    <img src="/images/bg2.jpg" alt="Spark RDD의 함수 동작 방식">
  </div><!-- /.entry-image -->
</div><!-- /.entry-header -->


<div id="main" role="main">
  <article class="hentry">
    <header class="header-title">
      <div class="header-title-wrap">
        
          <h1 class="entry-title"><a href="/data%20analysis/2014/11/06/spark-rdd-functions/" rel="bookmark" title="Spark RDD의 함수 동작 방식">Spark RDD의 함수 동작 방식</a></h1>
        
        <h2><span class="entry-date date published"><time datetime="2014-11-06T09:09:00-05:00">November 06, 2014</time></span></h2>
        
        <p class="entry-reading-time">
          <i class="fa fa-clock-o"></i>
          
Reading time ~7 minutes
        </p><!-- /.entry-reading-time -->
        
      </div><!-- /.header-title-wrap -->
    </header>
    <div class="entry-content">
      <p>이 글은 Spark의 RDD에 존재하는 함수들이 어떤 방식으로 동작되는지에 대한 글입니다. <br>
<a href="http://spark.apache.org/docs/latest/programming-guide.html#resilient-distributed-datasets-rdds">Spark 의 공식 Documentation</a>을 일부 번역하였습니다.<br>
또한, Java 기준으로 설명 할 것이며, Scala 로 된 버전은 추후에 추가 작성할 계획입니다.<br>
번역하기에 적절치 않은 용어들은 영문 단어 그대로 남겨놓았습니다.
<hr>
<br></p>

<h3>WARNING</h3>

<p>이 글은 최신버전을 기준으로 설명된 글이 아닙니다. 최신 버전을 대상으로 하였을 때와 설치 과정 혹은 출력 결과가 다를 수 있습니다.</p>

<p><br></p>

<h3>Spark의 RDD</h3>

<p>Spark는 Resilient Distributed Dataset, RDD 로 구성되어 있습니다. 이 RDD는 분산 형태로 처리 가능한 fault-tolerant collection 입니다. Spark에서 RDD를 생성하는 방법은 두 가지가 있습니다. 첫 번째로는 Driver 프로그램에서 이미 존재하는 colleciton을 <em>parallelizing</em> 시키는 방법이 있고, 다른 방법으로는 HDFS나 HBase혹은 Hadoop InputFormat 으로 수행 가능한 어떠한 데이터 소스를 <em>referencing</em>하는 방법이 있습니다.</p>

<p><br></p>

<h5>Parallelized Collections</h5>

<p>Java에서 Parallelized Collection을 생성하기 위해서는 <code>JavaSparkContext</code>클래스에 존재하는 <code>parallelize</code> 함수에 Driver 프로그램에서 사용한 Collection을 파라미터로 넘겨주면 됩니다. Collection에 존재하는 엘리먼트들은 Distributed Dataset으로 복사되고, 분산 형태로 연산됩니다. 1 에서 5 까지 값을 갖는 리스트를 parallelized collection으로 생성하는 방법은 다음 예와 같습니다.</p>
<div class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">List</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">4</span><span class="o">,</span> <span class="mi">5</span><span class="o">);</span>
<span class="n">JavaRDD</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">&gt;</span> <span class="n">distData</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="na">parallelize</span><span class="o">(</span><span class="n">data</span><span class="o">);</span>
</code></pre></div>
<p>한번 생성된 distributed dataset(<code>distData</code>)는 분산 형태로 연산될 수 있습니다. 예를들면, 다음과 같은 코드를 이용하여 리스트에 존재하는 모든 값을 더할 수 있습니다.</p>
<div class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">distData</span><span class="o">.</span><span class="na">reduce</span><span class="o">((</span><span class="n">a</span><span class="o">,</span> <span class="n">b</span><span class="o">)</span> <span class="o">-&gt;</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="o">);</span>
</code></pre></div>
<p>이러한 분산 형태의 연산에 대해서는 아래 Section 에서 설명할 것입니다.</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">이 Documentation에서는 Java 8 에서 제공하는 Lamda 문법을 사용하고 있습니다. Java 8을 사용할 수 없는 상황이어서 lambda 표현식을 사용하지 못할 때는, org.apache.spark.api.java.function 패키지를 구현하여 사용할 수 있습니다. 이에 대해서는 아래 Section에서 설명할 것입니다.
</code></pre></div>
<p>parallel collection에서 중요한 파라메터중 하나는 데이터셋을 몇 개의 <code>slices</code>로 나눌 것인지에 대한 것입니다. Spark는 각 cluster의 조각마다 하나의 태스크를 수행 하게 됩니다. 일반적으로 클러스터에서 각각의 CPU 마다 2 ~ 4 개의 slice를 합니다. Spark는 클러스터를 기반으로 slice의 수를 자동적으로 생성을 시도하지만, <code>parallelize</code>를 수행할 때 그 개수를 수동으로 지정해 줄 수 있습니다. (e.g. <code>sc.parallelize(data, 10)</code>)</p>

<p><br></p>

<h4>External Datasets</h4>

<p>Spark에서는 Hadoop과 연관되는 모든 데이터 소스(Local File System, HDFS, Cassandra, HBase, Amazon S3, etc.)를 이용하여 distributed dataset을 생성할 수 있습니다. Spark는 텍스트파일, <a href="http://hadoop.apache.org/common/docs/current/api/org/apache/hadoop/mapred/SequenceFileInputFormat.html">Sequence File</a>과 모든 Hadoop <a href="http://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapred/InputFormat.html">InputFormat</a>을 지원합니다.</p>

<p>텍스트 파일의 RDD는 <code>SparkContext</code>의 <code>textFile</code> 함수를 사용하여 생성될 수 있으며, 이 함수는 파일의 URI를 이용하여 파일에 접근합니다. 그리고 텍스트 파일의 한 라인의 collection으로 읽고, 다음과 같은 형태로 파일을 불러옵니다.</p>
<div class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">JavaRDD</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">distFile</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="na">textFile</span><span class="o">(</span><span class="s">&quot;data.txt&quot;</span><span class="o">);</span>
</code></pre></div>
<p>한번 생성이 되면, <code>distFile</code>은 dataset 연산들을 수행할 수 있게 됩니다. 예를들면 <code>map</code>과 <code>reduce</code>를 이용하여 모든 라인의 길이를 더한 갚을 구할때는 다음과 같이 명령어를 수행하면 됩니다.</p>
<div class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">distFile</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="n">s</span> <span class="o">-&gt;</span> <span class="n">s</span><span class="o">.</span><span class="na">length</span><span class="o">()).</span><span class="na">reduce</span><span class="o">(</span><span class="n">a</span><span class="o">,</span> <span class="n">b</span><span class="o">)</span> <span class="o">-&gt;</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="o">)</span>
</code></pre></div>
<p>Spark를 이용하여 파일을 읽을 때, 다음 사항들을 참고할 수 있습니다.</p>

<ul>
<li>Local File System 에 있는 파일에 접근할 때, 반드시 Worker node에서 접근 가능한 경로에 파일이 있어야 한다. 모든 Worker에게 파일을 복사하거나, network-mounted 로 공유된 파일 시스템을 사용해야 합니다.<br><br></li>
<li>Spark의 file-based 입력 함수는 폴더, 압축파일과 와일드카드 표현을 포함하여 사용될 수 있습니다. 예를 들면 <code>textFile(&quot;/my/directory&quot;)</code>, <code>textFile(&quot;/my/directory/*.txt&quot;)</code>, <code>textFile(&quot;/my/directory/*/gz&quot;)</code>가 모두 가능합니다.<br><br></li>
</ul>

<p>Spark는 텍스트 파일 이외에도 많은 데이터 포맷을 제공합니다.</p>

<ul>
<li><code>JavaSaprkContext.wholeTextFiles</code>는 하나의 폴더 안에 존재하는 텍스트 파일을 읽습니다. 그리고 그것을 &lt;파일이름, 내용&gt; 형태의 쌍으로 리턴합니다. 이것은 한 파일을 읽어 각각의 줄에 대해 처리하는 <code>textFile</code>과는 다른 형태입니다.<br><br></li>
<li><a href="http://hadoop.apache.org/common/docs/current/api/org/apache/hadoop/mapred/SequenceFileInputFormat.html">SequenceFiles</a>를 읽기 위해서는 SparkContext의 <code>sequenceFile[K,V]</code> 함수를 사용해야합니다. K 와 V는 해당 파일에서 사용하고 있는 Key와 Value의 타입입니다. 이것들은 Hadoop의 IntWritable 과 Text 클래스와 같이 <a href="http://hadoop.apache.org/common/docs/current/api/org/apache/hadoop/io/Writable.html">Writable</a>클래스의 subclass여야 합니다. Spark에서는 이러한 과정을 돕기 위해 몇 개의 일반적인 Writable 타입에 대해 native type을 제공합니다. 예를들어 <code>sequenceFile[Int,String]</code>을 사용하면, 이것은 <code>IntWritable</code>과 <code>Text</code>로 인식됩니다.<br><br></li>
<li>다른 Hadoop InputFormat을 사용하기 위해서는 <code>JavaSparkContext.HadoopRDD</code>함수를 사용해야 합니다. 이 함수는 임의의 JobConf와 InputFormat 클래스, Key 클래스, Value 클래스를 받습니다. Hadoop 에서 입력 소스를 지정하는 과정과 같은 방식으로 지정을 해야 합니다. 또한 새 맵리듀스 API(org.apache.hadoop.mapreduce 패키지에 존재하는 API)를 사용하기 위해서는<code>JavaSparkContext.newHadoopRDD</code>를 사용해야합니다.<br><br></li>
<li><code>JavaRDD.saveAsObjectFile</code>과 <code>JavaSparkContext.objectFile</code>은 Serialized된 자바 객체 형태로 출력하는 것을 지원합니다. 이것은 Avro와 같이 특수화 된 형태보다는 효율적이지 않지만 간단한 형태로 어떠한 RDD도 저장 가능합니다.</li>
</ul>

<p><br></p>

<h4>RDD Operations</h4>

<p>추후 번역</p>

      <footer class="entry-meta">
        <span class="entry-tags"><a href="/tags/#Spark" title="Pages tagged Spark" class="tag"><span class="term">Spark</span></a><a href="/tags/#Spark RDD" title="Pages tagged Spark RDD" class="tag"><span class="term">Spark RDD</span></a></span>
        
        <div class="social-share">
  <ul class="socialcount socialcount-small inline-list">
    <li class="facebook"><a href="https://www.facebook.com/sharer/sharer.php?u=/data%20analysis/2014/11/06/spark-rdd-functions/" title="Share on Facebook"><span class="count"><i class="fa fa-facebook-square"></i> Like</span></a></li>
    <li class="twitter"><a href="https://twitter.com/intent/tweet?text=/data%20analysis/2014/11/06/spark-rdd-functions/" title="Share on Twitter"><span class="count"><i class="fa fa-twitter-square"></i> Tweet</span></a></li>
    <li class="googleplus"><a href="https://plus.google.com/share?url=/data%20analysis/2014/11/06/spark-rdd-functions/" title="Share on Google Plus"><span class="count"><i class="fa fa-google-plus-square"></i> +1</span></a></li>
  </ul>
</div><!-- /.social-share -->
      </footer>
    </div><!-- /.entry-content -->
    <section id="disqus_thread"></section><!-- /#disqus_thread -->
    <div class="read-more">
  
    <div class="read-more-header">
      <a href="/data%20analysis/2014/11/05/recommendation-with-spark/" class="read-more-btn">Read More</a>
    </div><!-- /.read-more-header -->
    <div class="read-more-content">
      <h3><a href="/data%20analysis/2015/10/24/advanced-analytics-with-spark-ch5/" title="Spark & 머신 러닝 - Anomaly Detection">Spark & 머신 러닝 - Anomaly Detection</a></h3>
      <p>이 포스트는 K-means Clustering을 이용하여 네트워크 트래픽에서의 비정상 트래픽을 감지해 내는 과정에 대한 내용을 담고 있다. 이 장에서 수행한 결과는 수행시마다 바뀌기 때문에, 수행 결과가 이 문서에서 제시하는 결과와 완벽히 일치하...&hellip; <a href="/data%20analysis/2015/10/24/advanced-analytics-with-spark-ch5/">Continue reading</a></p>
    </div><!-- /.read-more-content -->
  
  <div class="read-more-list">
    
      <div class="list-item">
        <h4><a href="/data%20analysis/2015/09/09/advanced-analytics-with-spark-ch4/" title="Spark & 머신 러닝 - Predicting Forest Cover">Spark & 머신 러닝 - Predicting Forest Cover</a></h4>
        <span>Published on September 09, 2015</span>
      </div><!-- /.list-item -->
    
      <div class="list-item">
        <h4><a href="/data%20analysis/2015/07/27/advanced-analytics-with-spark-ch3-2/" title="Spark & 머신 러닝 - Recommending Music - 2/2">Spark & 머신 러닝 - Recommending Music - 2/2</a></h4>
        <span>Published on July 27, 2015</span>
      </div><!-- /.list-item -->
    
  </div><!-- /.read-more-list -->
</div><!-- /.read-more -->
  </article>
</div><!-- /#main -->

<div class="footer-wrapper">
  <footer role="contentinfo">
    <span>&copy; 2015 Hyunje Jo.</span>
  </footer>
</div><!-- /.footer-wrapper -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="/assets/js/scripts.min.js"></script>

<!-- Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-62281776-1', 'auto');
  ga('send', 'pageview');
</script>

<!-- Mathjax -->
<script type="text/javascript"
    src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'hyunjeblog'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function () {
            var s = document.createElement('script'); s.async = true;
            s.type = 'text/javascript';
            s.src = '//' + disqus_shortname + '.disqus.com/count.js';
            (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
        }());
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
	        

</body>
</html>
