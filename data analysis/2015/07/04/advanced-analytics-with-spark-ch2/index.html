<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>Spark & 머신 러닝 - Introduction to Spark &#8211; Hyunje Blog</title>

<meta name="google-site-verification" content="KstVPrbjGTMueNzKiyCurwLlZ0wNcfscVNW4KmZtXC4" />

<meta name="description" content="Blog for Hyunje">
<meta name="keywords" content="Spark, Machine Learning">



<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark & 머신 러닝 - Introduction to Spark">
<meta property="og:description" content="Blog for Hyunje">
<meta property="og:url" content="/data%20analysis/2015/07/04/advanced-analytics-with-spark-ch2/">
<meta property="og:site_name" content="Hyunje Blog">





<link rel="canonical" href="/data%20analysis/2015/07/04/advanced-analytics-with-spark-ch2/">
<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Hyunje Blog Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<!-- Webfonts -->
<link href="//fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic" rel="stylesheet" type="text/css">
<link href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
<link href='//fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
<link href='//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

<meta http-equiv="cleartype" content="on">

<!-- Load Modernizr -->
<script src="/assets/js/vendor/modernizr-2.6.2.custom.min.js"></script>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="/images/apple-touch-icon-144x144-precomposed.png">




<style type="text/css">body {background-image:url(/images/white.jpg);}</style>


</head>

<body id="post" class="feature">

<!--[if lt IE 9]><div class="upgrade"><strong><a href="http://whatbrowser.org/">Your browser is quite old!</strong> Why not upgrade to a different browser to better enjoy this site?</a></div><![endif]-->
<nav id="dl-menu" class="dl-menuwrapper" role="navigation">
	<button class="dl-trigger">Open Menu</button>
	<ul class="dl-menu">
		<li><a href="/">Home</a></li>
		<li>
			<a href="#">About</a>
			<ul class="dl-submenu">
				<li>
					<img src="/images/avatar.jpg" alt="Hyunje Jo photo" class="author-photo">
					<h4>Hyunje Jo</h4>
					<p>Bigdata-technology based Machine Learning & Data Analysis</p>
				</li>
				<li><a href="/about/"><span class="btn btn-inverse">Learn More</span></a></li>
				<li>
					<a href="mailto:retriever89@gmail.com"><i class="fa fa-fw fa-envelope"></i> Email</a>
				</li>
				
				<li>
					<a href="https://facebook.com/RetrieverJo"><i class="fa fa-fw fa-facebook"></i> Facebook</a>
				</li>
				
				
				<li>
					<a href="https://github.com/retrieverJo"><i class="fa fa-fw fa-github"></i> GitHub</a>
				</li>
				
				
				
				
			</ul><!-- /.dl-submenu -->
		</li>
		<li>
			<a href="#">Posts</a>
			<ul class="dl-submenu">
				<li><a href="/posts/">All Posts</a></li>
				<li><a href="/categories/">All Categories</a></li>
				<li><a href="/tags/">All Tags</a></li>
			</ul>
		</li>
		<!--
		
	    
	        
	    
	    <li><a href="/theme-setup/" >Theme Setup</a></li>
	  
	    
	        
	        
	    <li><a href="http://mademistakes.com" target="_blank">External Link</a></li>
	  
	  	-->
	</ul><!-- /.dl-menu -->
</nav><!-- /.dl-menuwrapper -->



<div class="entry-header">
  <div class="image-credit">Image source: Hyunje Jo</div><!-- /.image-credit -->
  <div class="entry-image">
    <img src="/images/bg1.jpg" alt="Spark & 머신 러닝 - Introduction to Spark">
  </div><!-- /.entry-image -->
</div><!-- /.entry-header -->


<div id="main" role="main">
  <article class="hentry">
    <header class="header-title">
      <div class="header-title-wrap">
        
          <h1 class="entry-title"><a href="/data%20analysis/2015/07/04/advanced-analytics-with-spark-ch2/" rel="bookmark" title="Spark & 머신 러닝 - Introduction to Spark">Spark & 머신 러닝 - Introduction to Spark</a></h1>
        
        <h2><span class="entry-date date published"><time datetime="2015-07-04T11:09:00-04:00">July 04, 2015</time></span></h2>
        
        <p class="entry-reading-time">
          <i class="fa fa-clock-o"></i>
          
Reading time ~27 minutes
        </p><!-- /.entry-reading-time -->
        
      </div><!-- /.header-title-wrap -->
    </header>
    <div class="entry-content">
      <p>이 글에서는 Spark가 어떤 형태로 동작하는지 설명하고 간단한 예시를 통해 Spark에 적응하는 과정을 설명한다.</p>

<p>이 포스트는 <a href="http://shop.oreilly.com/product/0636920035091.do">Advanced Analytics with Spark</a>을 정리한 글이다.</p>

<p>이 글에서 다루고자 하는 내용은 Chapter 2이다. Chapter 1은 빅데이터에 대한 개략적인 얘기와, 왜 Spark가 뜨고 있는지, Spark 가 데이터 분석에서 어떠한 역할을 하고 있는지에 대한 설명이 있었다. 그 내용들은 다른 자료들에 많이 있으므로 따로 정리는 하지 않았다.</p>

<p><br>
<br></p>

<h2>Record Linkage</h2>

<p>chapter 2에서는 Record Linkage와 비슷한 작업(ex : <a href="https://en.wikipedia.org/wiki/Extract,_transform,_load">ETL</a>)들을 Spark 로 어떻게 수행하는지에 대해 설명하고, Follow-up 할 수 있도록 하고있다.</p>

<p>실제 데이터를 이용해 분석을 수행할 때 대부분은 수집한 데이터를 그대로 이용하지 않는다. 수집한 데이터를 그대로 이용한다면 잘못된 데이터(값이 비어있거나, 필요없는 데이터가 섞여있거나, 같은 데이터가 중복되어 들어있거나 등등)들이 분석에 그대로 활용되기 때문에 이들을 잘 필터링 해야 한다.</p>

<p>이 책에서 Recoed Linkage는 위의 문제 중 같은 데이터가 다른 형태로 들어있을 때, 그것을 하나의 데이터로 간주하도록 하는 것이라 얘기하고 있다.</p>

<p>이러한 내용들을 수행하기 위해 Record Linkage Comparison Patterns Dataset을 이용한다.</p>

<p><br>
<br></p>

<h2>The Spark Shell and SparkContext</h2>

<p>Spark를 이용하는 방법은 크게 두 가지가 있다. 하나는 Spark Shell 을 통해서 REPL(read-eval-print loop) 형태로 Spark를 이용하는 방법이고, 나머지 방법은 Spark Application 을 IDE를 이용해 작성한 후, 그것을 패키징 하여 Spark Cluster로 Submit하여 수행하는 방법이다.</p>

<p>REPL을 이용하려면 다음과 같은 명령어를 이용해야한다.</p>

<p>(여기서, 개인적인 공부이기 때문에 로컬 클러스터에서 수행함을 가정한다. 또한, Shell은 Scala를 기반으로 작성해야 하기 때문에 Scala 에 대한 이해가 필요하다.)</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>spark-shell --master <span class="nb">local</span><span class="o">[</span>2<span class="o">]</span>
</code></pre></div>
<p>만약 Spark 를 YARN을 이용해 수행시키고 싶다면 다음과 같이 입력한다.</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>spark-shell --master yarn-client
</code></pre></div>
<p><br></p>

<p>이 챕터에서는 <a href="http://bit.ly/1Aoywaq">http://bit.ly/1Aoywaq</a> 링크의 데이터를 이용하고 있다.
이 데이터를 HDFS로 업로드해야 하기 때문에, 다음 과정을 이용해 데이터를 HDFS로 업로드 한다.</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>wget http://bit.ly/1Aoywaq -O donation.zip
<span class="nv">$ </span>unzip donation.zip
<span class="nv">$ </span>unzip <span class="s1">&#39;block_*.zip&#39;</span>
<span class="nv">$ </span>hdfs dfs -mkdir /linkage
<span class="nv">$ </span>hdfs dfs -put block_*.csv /linkage
</code></pre></div>
<p>책에서는 (아직은) Spark-shell을 기준으로 설명하고 있다. 본 글 역시 다른 언급이 있지 않는 이상 Spark-shell 을 기준으로 설명할 것이다.</p>

<p>우선, 다음 명령어를 이용해 데이터가 HDFS에 정상적으로 업로드 되고, 그것을 잘 읽어 오는지 확인한다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">rawblocks</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="o">(</span><span class="s">&quot;/linkage&quot;</span><span class="o">)</span>
<span class="o">...</span>
<span class="n">rawblocks</span><span class="k">:</span> <span class="kt">org.apache.spark.rdd.RDD</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="nc">MapPartitionsRDD</span><span class="o">[</span><span class="err">1</span><span class="o">]</span> <span class="n">at</span> <span class="n">textFile</span> <span class="n">at</span> <span class="o">&lt;</span><span class="n">console</span><span class="k">&gt;:</span><span class="mi">21</span>
</code></pre></div>
<p>Spark Shell 에서는 기본적인 SparkContext 객체에 대한 인스턴스를 하나 제공한다. 그 인스턴스에 대한 접근은 <code>sc</code>로 할 수 있으며, <strong>textFile</strong> 함수를 이용해 HDFS에 저장되어 있는 파일을 읽어올 수 있다.</p>

<p>다음 명령어를 이용해 데이터의 상위 10 줄에 어떤 데이터가 들어있는지 확인한다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">head</span> <span class="k">=</span> <span class="n">rawblocks</span><span class="o">.</span><span class="n">take</span><span class="o">(</span><span class="mi">10</span><span class="o">)</span>
<span class="n">head</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>
</code></pre></div>
<p>그러면 다음과 같은 값이 들어있음을 알 수 있다.</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">&quot;id_1&quot;,&quot;id_2&quot;,&quot;cmp_fname_c1&quot;,&quot;cmp_fname_c2&quot;,&quot;cmp_lname_c1&quot;,&quot;cmp_lname_c2&quot;,&quot;cmp_sex&quot;,&quot;cmp_bd&quot;,&quot;cmp_bm&quot;,&quot;cmp_by&quot;,&quot;cmp_plz&quot;,&quot;is_match&quot;
37291,53113,0.833333333333333,?,1,?,1,1,1,1,0,TRUE
39086,47614,1,?,1,?,1,1,1,1,1,TRUE
70031,70237,1,?,1,?,1,1,1,1,1,TRUE
84795,97439,1,?,1,?,1,1,1,1,1,TRUE
36950,42116,1,?,1,1,1,1,1,1,1,TRUE
42413,48491,1,?,1,?,1,1,1,1,1,TRUE
25965,64753,1,?,1,?,1,1,1,1,1,TRUE
49451,90407,1,?,1,?,1,1,1,1,0,TRUE
39932,40902,1,?,1,?,1,1,1,1,1,TRUE
</code></pre></div>
<p>이 결과를 보면, csv 데이터의 제일 첫 줄에 각 컬럼이 나타내는 값이 어떤 것인지에 대한 정보가 있다. 이것을 다음과 같은 함수와 명령어를 이용하여 필터링한다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">def</span> <span class="n">isHeader</span><span class="o">(</span><span class="n">line</span><span class="k">:</span><span class="kt">String</span><span class="o">)</span> <span class="k">:</span> <span class="kt">Boolean</span> <span class="o">=</span> <span class="o">{</span>
    <span class="n">line</span><span class="o">.</span><span class="n">contains</span><span class="o">(</span><span class="s">&quot;id_1&quot;</span><span class="o">)</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">noheader</span> <span class="k">=</span> <span class="n">rawblocks</span><span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="o">!</span><span class="n">isHeader</span><span class="o">(</span><span class="n">x</span><span class="o">))</span>
</code></pre></div>
<p>그 결과로, 다음과 같이 컬럼명이 제외된 데이터 10개를 볼 수 있다.</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">37291,53113,0.833333333333333,?,1,?,1,1,1,1,0,TRUE
39086,47614,1,?,1,?,1,1,1,1,1,TRUE
70031,70237,1,?,1,?,1,1,1,1,1,TRUE
84795,97439,1,?,1,?,1,1,1,1,1,TRUE
36950,42116,1,?,1,1,1,1,1,1,1,TRUE
42413,48491,1,?,1,?,1,1,1,1,1,TRUE
25965,64753,1,?,1,?,1,1,1,1,1,TRUE
49451,90407,1,?,1,?,1,1,1,1,0,TRUE
39932,40902,1,?,1,?,1,1,1,1,1,TRUE
46626,47940,1,?,1,?,1,1,1,1,1,TRUE
</code></pre></div>
<p><br>
<br></p>

<h2>Structuring Data with Tuples and Case Classes</h2>

<p>지금까지 읽은 데이터를 그대로 읽어서 분석에 활용할 수 있지만, 데이터를 파싱하여 활용하면 더욱 쉽게 활용할 수 있다.</p>

<p>데이터는 다음과 같은 형태를 띄고 있다.</p>

<ul>
<li>처음 2개의 Integer 값 : 레코드에서 매칭되는 환자의 ID</li>
<li>9개의 Double 값 : 9가지의 필드에 대한 매칭 스코어(없을 수 있음)</li>
<li>Boolean 값 : 매치 되는지 여부에 대한 판별결과</li>
</ul>

<p>이를 파싱하기 위해 다음과 같은 <a href="http://docs.scala-lang.org/ko/tutorials/tour/case-classes.html">Case Class</a>를 정의하고 필요한 서브 함수를 작성하여 활용한다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">case</span> <span class="k">class</span> <span class="nc">MatchData</span><span class="o">(</span><span class="n">id1</span><span class="k">:</span> <span class="kt">Int</span><span class="o">,</span> <span class="n">id2</span><span class="k">:</span> <span class="kt">Int</span><span class="o">,</span> <span class="n">scores</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">Double</span><span class="o">],</span> <span class="n">matched</span><span class="k">:</span> <span class="kt">Boolean</span><span class="o">)</span>

<span class="k">def</span> <span class="n">toDouble</span><span class="o">(</span><span class="n">s</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span>
    <span class="k">if</span><span class="o">(</span><span class="s">&quot;?&quot;</span><span class="o">.</span><span class="n">equals</span><span class="o">(</span><span class="n">s</span><span class="o">))</span> <span class="nc">Double</span><span class="o">.</span><span class="nc">NaN</span> <span class="k">else</span> <span class="n">s</span><span class="o">.</span><span class="n">toDouble</span>
<span class="o">}</span>

<span class="k">def</span> <span class="n">parse</span><span class="o">(</span><span class="n">line</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">pieces</span> <span class="k">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="sc">&#39;,&#39;</span><span class="o">);</span>
    <span class="k">val</span> <span class="n">id1</span> <span class="k">=</span> <span class="n">pieces</span><span class="o">.</span><span class="n">apply</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="n">toInt</span>
    <span class="k">val</span> <span class="n">id2</span> <span class="k">=</span> <span class="n">pieces</span><span class="o">.</span><span class="n">apply</span><span class="o">(</span><span class="mi">1</span><span class="o">).</span><span class="n">toInt</span>
    <span class="k">val</span> <span class="n">scores</span> <span class="k">=</span> <span class="n">pieces</span><span class="o">.</span><span class="n">slice</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mi">11</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="n">toDouble</span><span class="o">)</span>
    <span class="k">val</span> <span class="n">matched</span> <span class="k">=</span> <span class="n">pieces</span><span class="o">.</span><span class="n">apply</span><span class="o">(</span><span class="mi">11</span><span class="o">).</span><span class="n">toBoolean</span>
    <span class="nc">MatchData</span><span class="o">(</span><span class="n">id1</span><span class="o">,</span> <span class="n">id2</span><span class="o">,</span> <span class="n">scores</span><span class="o">,</span> <span class="n">matched</span><span class="o">)</span>
<span class="o">}</span>
</code></pre></div>
<p>다음 명령어를 통해 데이터를 파싱하고, 그 결과를 확인한다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">parsed</span> <span class="k">=</span> <span class="n">noheader</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">line</span> <span class="k">=&gt;</span> <span class="n">parse</span><span class="o">(</span><span class="n">line</span><span class="o">))</span>

<span class="n">parsed</span><span class="o">.</span><span class="n">take</span><span class="o">(</span><span class="mi">10</span><span class="o">).</span><span class="n">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>
</code></pre></div>
<p>그리고, 지금까지 파싱한 결과를 메모리에 cache()시켜놓는다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="n">parsed</span><span class="o">.</span><span class="n">cache</span><span class="o">()</span>
</code></pre></div>
<p><br>
<br></p>

<h2>Creating Histograms</h2>

<p><a href="https://en.wikipedia.org/wiki/Histogram">Histogram</a> 은 간단히 말하면, 항목별로 개수를 센 결과를 나타낸다고 할 수 있다. 이 절에서는 지금까지 파싱한 데이터가 <code>matched</code> 필드 값의 종류(true, false)별로 얼마나 존재하는지에 대한 히스토그램을 생성할 것이다. 다행히도 Spark의 RDD에서 기본적으로 제공하는 <strong>countByValue</strong>를 이용하면 쉽게 해결할 수 있다.</p>

<p>다음 명령어를 통해 각 값 별로 얼마만큼의 레코드가 존재하는지 쉽게 카운팅 할 수 있다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">matchCounts</span> <span class="k">=</span> <span class="n">parsed</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">md</span> <span class="k">=&gt;</span> <span class="n">md</span><span class="o">.</span><span class="n">matched</span><span class="o">).</span><span class="n">countByValue</span><span class="o">()</span>
</code></pre></div>
<p>다음과 같은 수행 결과로, 손쉽게 <code>matched</code> 필드의 각 값 별 히스토그램을 생성할 수 있다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="n">matchCounts</span><span class="k">:</span> <span class="kt">scala.collection.Map</span><span class="o">[</span><span class="kt">Boolean</span>,<span class="kt">Long</span><span class="o">]</span> <span class="k">=</span> <span class="nc">Map</span><span class="o">(</span><span class="kc">true</span> <span class="o">-&gt;</span> <span class="mi">20931</span><span class="o">,</span> <span class="kc">false</span> <span class="o">-&gt;</span> <span class="mi">5728201</span><span class="o">)</span>
</code></pre></div>
<p><br>
<br></p>

<h2>Summary Statistics for Continuous Variables</h2>

<p>앞서 설명된 <strong>countByValue</strong>는 값의 종류에 따라 Histogram 을 생성하는 좋은 방법 중 하나이다. 하지만 Boolean 형태의 값처럼 적은 범위를 갖는 값이 아니라 Continuous Variable, 즉 연속변수와 같은 경우에 사용하기에는 적절하지 않다.</p>

<p>연속변수들에 대해서는 모든 값의 Histogram 을 구하는 것보다 분포에 대한 확률적인 통계 수치(평균, 표준편차, 최대 or 최솟값 등)를 보는 것이 좀 더 간결하게 데이터를 파악할 수 있다.</p>

<p>Spark에서는 이를 위해 <strong>stats</strong>라는 함수를 제공한다. 이 함수를 이용함으로써 손쉽게 특정 변수에 대한 통계적 수치를 출력할 수 있다. 파싱한 값중에 NaN이 들어가 있을 수 있기 때문에, 해당 레코드는 필터링을 수행한 후에 수행시키도록 한다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">java.lang.Double.isNaN</span>
<span class="n">parsed</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">md</span> <span class="k">=&gt;</span> <span class="n">md</span><span class="o">.</span><span class="n">scores</span><span class="o">(</span><span class="mi">0</span><span class="o">)).</span><span class="n">filter</span><span class="o">(!</span><span class="n">isNaN</span><span class="o">(</span><span class="k">_</span><span class="o">)).</span><span class="n">stats</span><span class="o">()</span>
</code></pre></div>
<p>위 코드의 수행 결과로 다음과 같은 결과를 볼 수 있다.</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">org.apache.spark.util.StatCounter = (count: 5748125, mean: 0.712902, stdev: 0.388758, max: 1.000000, min: 0.000000)
</code></pre></div>
<p>또한 Scala의 <strong>Range</strong>를 이용하여 scores 배열에 들어있는 모든 변수에 대한 수치값들에 대한 통계치를 구할 수 있다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">stats</span> <span class="k">=</span> <span class="o">(</span><span class="mi">0</span> <span class="n">until</span> <span class="mi">9</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="n">i</span> <span class="k">=&gt;</span> <span class="o">{</span>
    <span class="n">parsed</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">md</span> <span class="k">=&gt;</span> <span class="n">md</span><span class="o">.</span><span class="n">scores</span><span class="o">(</span><span class="n">i</span><span class="o">)).</span><span class="n">filter</span><span class="o">(!</span><span class="n">isNaN</span><span class="o">(</span><span class="k">_</span><span class="o">)).</span><span class="n">stats</span><span class="o">()</span>
<span class="o">})</span>
<span class="n">stats</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>
</code></pre></div>
<p>그 결과는 다음과 같다.</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">(count: 5748125, mean: 0.712902, stdev: 0.388758, max: 1.000000, min: 0.000000)
(count: 103698, mean: 0.900018, stdev: 0.271316, max: 1.000000, min: 0.000000)
(count: 5749132, mean: 0.315628, stdev: 0.334234, max: 1.000000, min: 0.000000)
(count: 2464, mean: 0.318413, stdev: 0.368492, max: 1.000000, min: 0.000000)
(count: 5749132, mean: 0.955001, stdev: 0.207301, max: 1.000000, min: 0.000000)
(count: 5748337, mean: 0.224465, stdev: 0.417230, max: 1.000000, min: 0.000000)
(count: 5748337, mean: 0.488855, stdev: 0.499876, max: 1.000000, min: 0.000000)
(count: 5748337, mean: 0.222749, stdev: 0.416091, max: 1.000000, min: 0.000000)
(count: 5736289, mean: 0.005529, stdev: 0.074149, max: 1.000000, min: 0.000000)
</code></pre></div>
<p><br>
<br></p>

<h2>Creating Reusable Code for Computing Summary Statistics</h2>

<p>하지만, 위와 같은 작업은 매우 비효율적이다. scores 배열에 존재하는 값에 대한 각각의 통계치를 계산하기 위해서 <code>parsed RDD</code>를 매번 다시 계산해야 한다. 물론 앞선 과정에서 <code>parsed RDD</code> 를 <strong>cache</strong> 해 놓긴 하였지만, 데이터가 많아지면 많아질 수록 이 작업의 소요시간은 급속도로 증가할 것이다.</p>

<p>이러한 경우에, 어떠한 <code>RDD[Array[Double]]</code>를 인자로 받아, 값이 정상적으로 들어있는 레코드들에 대한 각 인덱스별 <code>StatCounter</code> 를 갖는 클래스 혹은 함수를 작성하는 것을 생각해 볼 수 있다.</p>

<p>또한, 이러한 작업이 분석 과정에서 반복될 때, 매번 해당 코드를 새롭게 작성하는 것보다 다른 파일에 작성하여 그것을 재사용하는 것이 적절한 방식이다. 때문에 다른 파일에 스칼라 코드를 작성하고, Spark에서 그 파일을 불러와 사용하도록 할 것이다. 다음 소스코드를 다른 파일 <code>StatsWithMissing.scala</code>파일에 저장한 후 사용할 것이며, 멤버변수와 함수에 대해서는 코드의 뒷 부분에서 설명할 것이다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.spark.util.StatCounter</span>

<span class="k">class</span> <span class="nc">NAStatCounter</span> <span class="k">extends</span> <span class="nc">Serializable</span><span class="o">{</span>
    <span class="k">val</span> <span class="n">stats</span><span class="k">:</span> <span class="kt">StatCounter</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">StatCounter</span><span class="o">()</span>
    <span class="k">var</span> <span class="n">missing</span><span class="k">:</span> <span class="kt">Long</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="n">add</span><span class="o">(</span><span class="n">x</span><span class="k">:</span> <span class="kt">Double</span><span class="o">)</span><span class="k">:</span> <span class="kt">NAStatCounter</span> <span class="o">=</span> <span class="o">{</span>
        <span class="k">if</span><span class="o">(</span><span class="n">java</span><span class="o">.</span><span class="n">lang</span><span class="o">.</span><span class="nc">Double</span><span class="o">.</span><span class="n">isNaN</span><span class="o">(</span><span class="n">x</span><span class="o">))</span> <span class="o">{</span>
            <span class="n">missing</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
            <span class="n">stats</span><span class="o">.</span><span class="n">merge</span><span class="o">(</span><span class="n">x</span><span class="o">)</span>
        <span class="o">}</span>
        <span class="k">this</span>
    <span class="o">}</span>

    <span class="k">def</span> <span class="n">merge</span><span class="o">(</span><span class="n">other</span><span class="k">:</span> <span class="kt">NAStatCounter</span><span class="o">)</span><span class="k">:</span> <span class="kt">NAStatCounter</span> <span class="o">=</span> <span class="o">{</span>
        <span class="n">stats</span><span class="o">.</span><span class="n">merge</span><span class="o">(</span><span class="n">other</span><span class="o">.</span><span class="n">stats</span><span class="o">)</span>
        <span class="n">missing</span> <span class="o">+=</span> <span class="n">other</span><span class="o">.</span><span class="n">missing</span>
        <span class="k">this</span>
    <span class="o">}</span>

    <span class="k">override</span> <span class="k">def</span> <span class="n">toString</span> <span class="k">=</span> <span class="o">{</span>
        <span class="s">&quot;stats: &quot;</span> <span class="o">+</span> <span class="n">stats</span><span class="o">.</span><span class="n">toString</span> <span class="o">+</span> <span class="s">&quot; NaN: &quot;</span> <span class="o">+</span> <span class="n">missing</span>
    <span class="o">}</span>
<span class="o">}</span>

<span class="k">object</span> <span class="nc">NAStatCounter</span> <span class="k">extends</span> <span class="nc">Serializable</span> <span class="o">{</span>
    <span class="k">def</span> <span class="n">apply</span><span class="o">(</span><span class="n">x</span><span class="k">:</span> <span class="kt">Double</span><span class="o">)</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NAStatCounter</span><span class="o">().</span><span class="n">add</span><span class="o">(</span><span class="n">x</span><span class="o">)</span>
<span class="o">}</span>
</code></pre></div>
<p>앞서 정의한 <code>NAStatCounter</code> 클래스는 두 개의 멤버 변수를 갖고 있다. <code>stats</code>로 정의된 <code>StatCounter</code> 인스턴스는 immutable이고, <code>missing</code>으로 정의된 <code>Long</code> 변수는 mutable 변수이다. 이 클래스를 <code>Serializable</code> 객체를 상속시킨 이유는, Spark 의 RDD에서 이 객체를 사용하기 위해선 반드시 상속을 시켜주어야 한다. 만약 이 상속을 하지 않으면 RDD에서 에러가 발생한다.</p>

<p>클래스의 첫 번째 함수 <code>add</code>는 새로운 Double 형태의 값을 받아 <code>stats</code>변수가 값을 계속 관측할 수 있도록 한다. 만약 인자로 받은 값이 NaN이면, missing 값을 1 증가시키고, NaN이 아니라면 StatCounter 객체에 기록한다. 두 번째 함수 <code>merge</code>는 다른 NAStatCounter 인스턴스를 매개변수로 받아 지금의 인스턴스와 병합시키는 역할을 한다. 세 번째 함수 toString은 쉽게 NAStatCounter 클래스를 출력하기 위해서 오버라이딩 한 것이다. 스칼라에서는 부모 객체의 함수를 오버라이딩 하기 위해선 반드시 함수 앞에 <code>override</code> 키워드를 추가해야 한다.</p>

<p>그리고 class 정의와 함께 NAStatCounter 객체에 대한 <code>companion object</code>를 함께 정의한다. 스칼라에서 object 키워드는 자바에서의 static method 와 같이 어떤 클래스에 대한 helper method를 제공하는 싱글톤 객체를 선언하는데에 이용된다. 이 경우에서처럼 class 이름과 같은 object를 선언하는 것을 <code>companion object</code>를 선언한다고 하며, 여기서의 <code>apply</code> 함수는 <code>NAStatCounter</code> 클래스에 대한 새 인스턴스를 생성하고, 그 인스턴스를 반환하기 전에 Double 값을 더한다.</p>

<p>정상적으로 로드가 되었다면 다음과 같은 메시지가 출력된다.</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">import org.apache.spark.util.StatCounter
defined class NAStatCounter
defined module NAStatCounter
warning: previously defined class NAStatCounter is not a companion to object NAStatCounter.
Companions must be defined together; you may wish to use :paste mode for this.
</code></pre></div>
<p>경고가 출력되어 문제가 생긴것이 아닌가 할 수 있지만, 무시할 수 있는 경고이다.
다음과 같은 예시로 정상적으로 로드되었는지 확인해 볼 수 있다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">nas1</span> <span class="k">=</span> <span class="nc">NAStatCounter</span><span class="o">(</span><span class="mf">10.0</span><span class="o">)</span>
<span class="n">nas1</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="mf">2.1</span><span class="o">)</span>
<span class="k">val</span> <span class="n">nas2</span> <span class="k">=</span> <span class="nc">NAStatCounter</span><span class="o">(</span><span class="nc">Double</span><span class="o">.</span><span class="nc">NaN</span><span class="o">)</span>
<span class="n">nas1</span><span class="o">.</span><span class="n">merge</span><span class="o">(</span><span class="n">nas2</span><span class="o">)</span>
</code></pre></div>
<p>이제 작성한 <code>NAStatCounter</code>클래스를 이용하여 <code>parsed RDD</code>에 들어있는 MatchData 레코드를 처리하자. 각각의 MatchData 인스턴스는 Array[Double] 형태의 매칭 스코어를 포함하고 있다. 배열에 있는 각각의 엔트리마다 <code>NAStatCounter</code> 객체를 생성시켜, 모든 값을 추적하려 한다. 그렇게 하기 위해선 다음과 같은 방식으로 RDD 안에 존재하는 모든 레코드는 Array[Double]을 갖고 있기 때문이 이것을 Array[NAStatCounter]를 갖는 RDD로 변경하면 된다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">nasRDD</span> <span class="k">=</span> <span class="n">parsed</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">md</span> <span class="k">=&gt;</span> <span class="o">{</span>
    <span class="n">md</span><span class="o">.</span><span class="n">scores</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">d</span> <span class="k">=&gt;</span> <span class="nc">NAStatCounter</span><span class="o">(</span><span class="n">d</span><span class="o">))</span>
<span class="o">})</span>
</code></pre></div>
<p>이제, 여러개의 Array[NAStatCounter] 를 하나의 배열로 합치면서 각 인덱스별로 존재하는 NAStatCounter를 병합하면 된다. 이를 위해 다음과 같은 코드를 이용한다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">reduced</span> <span class="k">=</span> <span class="n">nasRDD</span><span class="o">.</span><span class="n">reduce</span><span class="o">((</span><span class="n">n1</span><span class="o">,</span> <span class="n">n2</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="o">{</span>
    <span class="n">n1</span><span class="o">.</span><span class="n">zip</span><span class="o">(</span><span class="n">n2</span><span class="o">).</span><span class="n">map</span> <span class="o">{</span> <span class="k">case</span> <span class="o">(</span><span class="n">a</span><span class="o">,</span> <span class="n">b</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">merge</span><span class="o">(</span><span class="n">b</span><span class="o">)</span> <span class="o">}</span>
<span class="o">})</span>
<span class="n">reduced</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>
</code></pre></div>
<p>그 결과로 다음과 같이 모든 매칭 스코어에 대한 인덱스별 통계 수치를 구할 수 있다.</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">stats: (count: 5748125, mean: 0.712902, stdev: 0.388758, max: 1.000000, min: 0.000000) NaN: 1007
stats: (count: 103698, mean: 0.900018, stdev: 0.271316, max: 1.000000, min: 0.000000) NaN: 5645434
stats: (count: 5749132, mean: 0.315628, stdev: 0.334234, max: 1.000000, min: 0.000000) NaN: 0
stats: (count: 2464, mean: 0.318413, stdev: 0.368492, max: 1.000000, min: 0.000000) NaN: 5746668
stats: (count: 5749132, mean: 0.955001, stdev: 0.207301, max: 1.000000, min: 0.000000) NaN: 0
stats: (count: 5748337, mean: 0.224465, stdev: 0.417230, max: 1.000000, min: 0.000000) NaN: 795
stats: (count: 5748337, mean: 0.488855, stdev: 0.499876, max: 1.000000, min: 0.000000) NaN: 795
stats: (count: 5748337, mean: 0.222749, stdev: 0.416091, max: 1.000000, min: 0.000000) NaN: 795
stats: (count: 5736289, mean: 0.005529, stdev: 0.074149, max: 1.000000, min: 0.000000) NaN: 12843
</code></pre></div>
<p>또한 다음과 같이 <code>statsWithMissing</code>함수를 정의하고 이를 사용함으로써 좀 더 고급지게(?) 처리할 수 있다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">def</span> <span class="n">statsWithMissing</span><span class="o">(</span><span class="n">rdd</span><span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">Array</span><span class="o">[</span><span class="kt">Double</span><span class="o">]])</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">NAStatCounter</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">nastats</span> <span class="k">=</span> <span class="n">rdd</span><span class="o">.</span><span class="n">mapPartitions</span><span class="o">((</span><span class="n">iter</span><span class="k">:</span> <span class="kt">Iterator</span><span class="o">[</span><span class="kt">Array</span><span class="o">[</span><span class="kt">Double</span><span class="o">]])</span> <span class="k">=&gt;</span> <span class="o">{</span>
        <span class="k">val</span> <span class="n">nas</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">NAStatCounter</span><span class="o">]</span> <span class="k">=</span> <span class="n">iter</span><span class="o">.</span><span class="n">next</span><span class="o">().</span><span class="n">map</span><span class="o">(</span><span class="n">d</span> <span class="k">=&gt;</span> <span class="nc">NAStatCounter</span><span class="o">(</span><span class="n">d</span><span class="o">))</span>
        <span class="n">iter</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="n">arr</span> <span class="k">=&gt;</span> <span class="o">{</span>
            <span class="n">nas</span><span class="o">.</span><span class="n">zip</span><span class="o">(</span><span class="n">arr</span><span class="o">).</span><span class="n">foreach</span> <span class="o">{</span> <span class="k">case</span> <span class="o">(</span><span class="n">n</span><span class="o">,</span> <span class="n">d</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">n</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="n">d</span><span class="o">)}</span>
        <span class="o">})</span>
        <span class="nc">Iterator</span><span class="o">(</span><span class="n">nas</span><span class="o">)</span>
    <span class="o">})</span>
    <span class="n">nastats</span><span class="o">.</span><span class="n">reduce</span><span class="o">((</span><span class="n">n1</span><span class="o">,</span> <span class="n">n2</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="o">{</span>
        <span class="n">n1</span><span class="o">.</span><span class="n">zip</span><span class="o">(</span><span class="n">n2</span><span class="o">).</span><span class="n">map</span> <span class="o">{</span> <span class="k">case</span> <span class="o">(</span><span class="n">a</span><span class="o">,</span> <span class="n">b</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">merge</span><span class="o">(</span><span class="n">b</span><span class="o">)}</span>
    <span class="o">})</span>
<span class="o">}</span>
</code></pre></div>
<p><br>
<br></p>

<h2>Simple Variable Selection and Scoring</h2>

<p>앞서 작성한 <code>statsWithMissing</code> 함수를 이용해 다음과 같이 parsedRDD 로부터 각 데이터가 매치되는지 여부에 따라 scores의 분포가 어떻게 되는지 구할 수 있다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">statsm</span> <span class="k">=</span> <span class="n">statsWithMissing</span><span class="o">(</span><span class="n">parsed</span><span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">matched</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">scores</span><span class="o">))</span>
<span class="k">val</span> <span class="n">statsn</span> <span class="k">=</span> <span class="n">statsWithMissing</span><span class="o">(</span><span class="n">parsed</span><span class="o">.</span><span class="n">filter</span><span class="o">(!</span><span class="k">_</span><span class="o">.</span><span class="n">matched</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">scores</span><span class="o">))</span>
</code></pre></div>
<p>두 변수 <code>statsm</code>과 <code>statsn</code>은 전체 데이터를 매치되는지 여부에 따라 두 개의 서브셋으로 나누어 scores의 확률적 분포에 대한 정보를 갖고 있다. 여기서 두 개의 각 서브셋에 존재하는 scores 배열의 각 칼럼 별 정보를 비교함으로써, 두 서브셋 차이에 각 feature 별로 어떤 차이를 갖고 있는지를 비교할 수 있다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="n">statsm</span><span class="o">.</span><span class="n">zip</span><span class="o">(</span><span class="n">statsn</span><span class="o">).</span><span class="n">map</span> <span class="o">{</span> <span class="k">case</span><span class="o">(</span><span class="n">m</span><span class="o">,</span> <span class="n">n</span><span class="o">)</span> <span class="k">=&gt;</span>
    <span class="o">(</span><span class="n">m</span><span class="o">.</span><span class="n">missing</span> <span class="o">+</span> <span class="n">n</span><span class="o">.</span><span class="n">missing</span><span class="o">,</span> <span class="n">m</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">mean</span> <span class="o">-</span> <span class="n">n</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">mean</span><span class="o">)</span>
<span class="o">}.</span><span class="n">zipWithIndex</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>
</code></pre></div>
<p>위 코드의 수행 결과로 다음과 같은 결과가 나온다.</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">((1007,0.285452905746686),0)
((5645434,0.09104268062279874),1)
((0,0.6838772482597568),2)
((5746668,0.8064147192926266),3)
((0,0.03240818525033473),4)
((795,0.7754423117834044),5)
((795,0.5109496938298719),6)
((795,0.7762059675300523),7)
((12843,0.9563812499852178),8)
</code></pre></div>
<p>좋은 feature 는 두 가지의 속성이 있다. 하나는 그 feature에 따른 크기가 큰 차이가 존재하는 것이고, 모든 데이터 쌍(두 서브셋 사이의)에 대해서도 균일하게 발생한다는 것이다. 이러한 이론에 따라 인덱스 1의 feature 는 좋은 feature라고 할 수 없다. 값이 존재하지 않아 missing이 카운트 된 횟수가 매우 많으며, 두 서브셋의 평균값의 차이가 0.09로 매우 적다(값의 범위가 0 에서 1인 것임을 감안했을 때). Feature 4 또한 적절치 않다. Feature 4는 모든 값이 존재하지만 평균 값의 차이가 0.03이므로 두 데이터 그룹 사이에 별 차이가 없기 때문이다.</p>

<p>반면, feature 5와 7은 훌륭한 feature 이다. 대부분의 데이터에 대해 값이 존재하며, 두 그룹의 평균 차이가 매우 크기 때문이다. 그리고 feature 2, 6, 8 역시 괜찮은 feature 라 할 수 있다. Feature 0과 3은 좀 애매하다고 할 수 있다. Feature 0은 대부분의 데이터에서 관측 가능하지만 두 셋의 평균 차이가 크지 않고, 반대로 Feature 3은 두 셋의 평균 차이가 크지만 많은 데이터에서 관측하기가 어렵다. 이 정보들은 두 데이터 셋을 명확하게 표현하기가 어렵다.</p>

<p>앞서 설명한 내용을 바탕으로하여 쓸만한 feature(2, 5, 6, 7, 8)를 이용해 각 데이터에 대한 scoring model을 만들 것이다. 이 모델에서는 NaN 값은 0으로 처리하여 계산할 것이다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">def</span> <span class="n">naz</span><span class="o">(</span><span class="n">d</span><span class="k">:</span> <span class="kt">Double</span><span class="o">)</span> <span class="k">=</span> <span class="k">if</span> <span class="o">(</span><span class="nc">Double</span><span class="o">.</span><span class="nc">NaN</span><span class="o">.</span><span class="n">equals</span><span class="o">(</span><span class="n">d</span><span class="o">))</span> <span class="mf">0.0</span> <span class="k">else</span> <span class="n">d</span>
<span class="k">case</span> <span class="k">class</span> <span class="nc">Scored</span><span class="o">(</span><span class="n">md</span><span class="k">:</span> <span class="kt">MatchData</span><span class="o">,</span> <span class="n">score</span><span class="k">:</span> <span class="kt">Double</span><span class="o">)</span>
<span class="k">val</span> <span class="n">ct</span> <span class="k">=</span> <span class="n">parsed</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">md</span> <span class="k">=&gt;</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">score</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mi">5</span><span class="o">,</span> <span class="mi">6</span><span class="o">,</span> <span class="mi">7</span><span class="o">,</span> <span class="mi">8</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="n">i</span> <span class="k">=&gt;</span> <span class="n">naz</span><span class="o">(</span><span class="n">md</span><span class="o">.</span><span class="n">scores</span><span class="o">(</span><span class="n">i</span><span class="o">))).</span><span class="n">sum</span>
    <span class="nc">Scored</span><span class="o">(</span><span class="n">md</span><span class="o">,</span> <span class="n">score</span><span class="o">)</span>
<span class="o">})</span>
<span class="n">ct</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">s</span> <span class="k">=&gt;</span> <span class="n">s</span><span class="o">.</span><span class="n">md</span><span class="o">.</span><span class="n">matched</span><span class="o">).</span><span class="n">countByValue</span><span class="o">()</span>

<span class="o">...</span>

<span class="n">scala</span><span class="o">.</span><span class="n">collection</span><span class="o">.</span><span class="nc">Map</span><span class="o">[</span><span class="kt">Boolean</span>,<span class="kt">Long</span><span class="o">]</span> <span class="k">=</span> <span class="nc">Map</span><span class="o">(</span><span class="kc">true</span> <span class="o">-&gt;</span> <span class="mi">20931</span><span class="o">,</span> <span class="kc">false</span> <span class="o">-&gt;</span> <span class="mi">5728201</span><span class="o">)</span>
</code></pre></div>
<p>생성한 <code>ct RDD</code> 에 여러 Threshold 값들을 지정하고, 매치되었는지 여부에 따라 카운팅을 함으로써 데이터의 속성에 대해 파악할 수 있다.</p>

<p>다음 결과는 Threshold 를 4.0 으로 정하였는데, 이것은 각각의 feature 에 대해 평균적으로 0.8 이상을 갖고 있음을 의미한다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="n">ct</span><span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="n">s</span> <span class="k">=&gt;</span> <span class="n">s</span><span class="o">.</span><span class="n">score</span> <span class="o">&gt;=</span> <span class="mf">4.0</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="n">s</span> <span class="k">=&gt;</span> <span class="n">s</span><span class="o">.</span><span class="n">md</span><span class="o">.</span><span class="n">matched</span><span class="o">).</span><span class="n">countByValue</span><span class="o">()</span>

<span class="o">...</span>

<span class="n">scala</span><span class="o">.</span><span class="n">collection</span><span class="o">.</span><span class="nc">Map</span><span class="o">[</span><span class="kt">Boolean</span>,<span class="kt">Long</span><span class="o">]</span> <span class="k">=</span> <span class="nc">Map</span><span class="o">(</span><span class="kc">true</span> <span class="o">-&gt;</span> <span class="mi">20871</span><span class="o">,</span> <span class="kc">false</span> <span class="o">-&gt;</span> <span class="mi">637</span><span class="o">)</span>
</code></pre></div>
<p>위와 같은 결과는 matched에 속하는 데이터 중 true를 갖는 데이터들의 99%이상이 feature(2, 5, 6, 7, 8) 합이 4 이상임을 나타내고, false를 갖는 데이터는 대부분(98.8%)이 4.0 이하의 값을 갖는다는것을 얘기한다.</p>

<p>다음과 같이 score 값을 2.0 으로 필터링 하면 다음과 같은 결과를 얻을 수 있다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="n">ct</span><span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="n">s</span> <span class="k">=&gt;</span> <span class="n">s</span><span class="o">.</span><span class="n">score</span> <span class="o">&gt;=</span> <span class="mf">2.0</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="n">s</span> <span class="k">=&gt;</span> <span class="n">s</span><span class="o">.</span><span class="n">md</span><span class="o">.</span><span class="n">matched</span><span class="o">).</span><span class="n">countByValue</span><span class="o">()</span>

<span class="o">...</span>

<span class="n">scala</span><span class="o">.</span><span class="n">collection</span><span class="o">.</span><span class="nc">Map</span><span class="o">[</span><span class="kt">Boolean</span>,<span class="kt">Long</span><span class="o">]</span> <span class="k">=</span> <span class="nc">Map</span><span class="o">(</span><span class="kc">true</span> <span class="o">-&gt;</span> <span class="mi">20931</span><span class="o">,</span> <span class="kc">false</span> <span class="o">-&gt;</span> <span class="mi">596414</span><span class="o">)</span>
</code></pre></div>
<p>이 결과는 matched 값이 true 인 경우에는 모든 데이터에가 feature 의 합이 2.0 이상이라는 것과, matched 값이 false인 경우에는 여전이 90% 이상이 feature 합이 2.0 미만이라는 것을 알 수 있다.</p>

<p>앞의 예시에서는 매우 간단한 특정 feature들의 합으로 matched 값에 따라 분류된 두 데이터 셋의 특성에 대해 알아봤지만, 이를 다양하게 변화시킴으로써 주어진 데이터셋에 대해 또 다른 새로운 정보들을 얻을 수 있을 것이다.</p>

<p>지금까지 Spark를 사용해보고, 이를 이용해 간단한 데이터셋을 필터링하고, 데이터셋의 특성에 대해 파악해보았다. 다음 장부터는 또 다른 데이터 셋을 이용해 좀 더 깊이있는 분석을 해 볼 것이다.</p>

      <footer class="entry-meta">
        <span class="entry-tags"><a href="/tags/#Spark" title="Pages tagged Spark" class="tag"><span class="term">Spark</span></a><a href="/tags/#Machine Learning" title="Pages tagged Machine Learning" class="tag"><span class="term">Machine Learning</span></a></span>
        
        <div class="social-share">
  <ul class="socialcount socialcount-small inline-list">
    <li class="facebook"><a href="https://www.facebook.com/sharer/sharer.php?u=/data%20analysis/2015/07/04/advanced-analytics-with-spark-ch2/" title="Share on Facebook"><span class="count"><i class="fa fa-facebook-square"></i> Like</span></a></li>
    <li class="twitter"><a href="https://twitter.com/intent/tweet?text=/data%20analysis/2015/07/04/advanced-analytics-with-spark-ch2/" title="Share on Twitter"><span class="count"><i class="fa fa-twitter-square"></i> Tweet</span></a></li>
    <li class="googleplus"><a href="https://plus.google.com/share?url=/data%20analysis/2015/07/04/advanced-analytics-with-spark-ch2/" title="Share on Google Plus"><span class="count"><i class="fa fa-google-plus-square"></i> +1</span></a></li>
  </ul>
</div><!-- /.social-share -->
      </footer>
    </div><!-- /.entry-content -->
    <section id="disqus_thread"></section><!-- /#disqus_thread -->
    <div class="read-more">
  
    <div class="read-more-header">
      <a href="/data%20analysis/2015/07/01/advanced-analytics-with-spark-0/" class="read-more-btn">Read More</a>
    </div><!-- /.read-more-header -->
    <div class="read-more-content">
      <h3><a href="/data%20analysis/2016/02/01/twitter-analysis/" title="PMI를 이용한 Twitter 데이터에서의 이슈 키워드 추출">PMI를 이용한 Twitter 데이터에서의 이슈 키워드 추출</a></h3>
      <p>제 1회 빅데이터 경진대회2013년도에 Team Herring이란 이름으로 제1회 빅데이터 경진대회에 참가했었다.그 당시에 트위터 데이터를 이용하여 각 날짜별 이슈 키워드를 추출하는 문제를 해결하였는데, 그 때 작성하였던 문서를 업로드한다.   ...&hellip; <a href="/data%20analysis/2016/02/01/twitter-analysis/">Continue reading</a></p>
    </div><!-- /.read-more-content -->
  
  <div class="read-more-list">
    
      <div class="list-item">
        <h4><a href="/data%20analysis/2015/12/21/yes24-recommendation-1/" title="Yes24 책 추천 알고리즘 분석 대회 후기">Yes24 책 추천 알고리즘 분석 대회 후기</a></h4>
        <span>Published on December 21, 2015</span>
      </div><!-- /.list-item -->
    
      <div class="list-item">
        <h4><a href="/data%20analysis/2015/10/24/advanced-analytics-with-spark-ch5/" title="Spark & 머신 러닝 - Anomaly Detection">Spark & 머신 러닝 - Anomaly Detection</a></h4>
        <span>Published on October 24, 2015</span>
      </div><!-- /.list-item -->
    
  </div><!-- /.read-more-list -->
</div><!-- /.read-more -->
  </article>
</div><!-- /#main -->

<div class="footer-wrapper">
  <footer role="contentinfo">
    <span>&copy; 2016 Hyunje Jo.</span>
  </footer>
</div><!-- /.footer-wrapper -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="/assets/js/scripts.min.js"></script>

<!-- Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-62281776-2', 'auto');
  ga('send', 'pageview');

</script>


<!-- Mathjax -->
<script type="text/javascript"
    src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'hyunjeblog'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function () {
            var s = document.createElement('script'); s.async = true;
            s.type = 'text/javascript';
            s.src = '//' + disqus_shortname + '.disqus.com/count.js';
            (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
        }());
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

	        

</body>
</html>
