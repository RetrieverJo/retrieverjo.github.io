<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>Hyunje Blog &#8211; Hyunje Blog</title>

<meta name="google-site-verification" content="KstVPrbjGTMueNzKiyCurwLlZ0wNcfscVNW4KmZtXC4" />

<meta name="description" content="Blog for Hyunje">
<meta name="keywords" content="Jekyll, theme, themes, responsive, blog, modern">



<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Hyunje Blog">
<meta property="og:description" content="Blog for Hyunje">
<meta property="og:url" content="/index.html">
<meta property="og:site_name" content="Hyunje Blog">





<link rel="canonical" href="/">
<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Hyunje Blog Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<!-- Webfonts -->
<link href="//fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic" rel="stylesheet" type="text/css">
<link href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
<link href='//fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
<link href='//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

<meta http-equiv="cleartype" content="on">

<!-- Load Modernizr -->
<script src="/assets/js/vendor/modernizr-2.6.2.custom.min.js"></script>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="/images/apple-touch-icon-144x144-precomposed.png">




<style type="text/css">body {background-image:url(/images/white.jpg);}</style>


</head>

<body id="post-index" class="feature">

<!--[if lt IE 9]><div class="upgrade"><strong><a href="http://whatbrowser.org/">Your browser is quite old!</strong> Why not upgrade to a different browser to better enjoy this site?</a></div><![endif]-->
<nav id="dl-menu" class="dl-menuwrapper" role="navigation">
	<button class="dl-trigger">Open Menu</button>
	<ul class="dl-menu">
		<li><a href="/">Home</a></li>
		<li>
			<a href="#">About</a>
			<ul class="dl-submenu">
				<li>
					<img src="/images/avatar.jpg" alt="Hyunje Jo photo" class="author-photo">
					<h4>Hyunje Jo</h4>
					<p>Bigdata-technology based Machine Learning & Data Analysis</p>
				</li>
				<li><a href="/about/"><span class="btn btn-inverse">Learn More</span></a></li>
				<li>
					<a href="mailto:retriever89@gmail.com"><i class="fa fa-fw fa-envelope"></i> Email</a>
				</li>
				
				<li>
					<a href="https://facebook.com/RetrieverJo"><i class="fa fa-fw fa-facebook"></i> Facebook</a>
				</li>
				
				
				<li>
					<a href="https://github.com/retrieverJo"><i class="fa fa-fw fa-github"></i> GitHub</a>
				</li>
				
				
				
				
			</ul><!-- /.dl-submenu -->
		</li>
		<li>
			<a href="#">Posts</a>
			<ul class="dl-submenu">
				<li><a href="/posts/">All Posts</a></li>
				<li><a href="/categories/">All Categories</a></li>
				<li><a href="/tags/">All Tags</a></li>
			</ul>
		</li>
		<!--
		
	    
	        
	    
	    <li><a href="/theme-setup/" >Theme Setup</a></li>
	  
	    
	        
	        
	    <li><a href="http://mademistakes.com" target="_blank">External Link</a></li>
	  
	  	-->
	</ul><!-- /.dl-menu -->
</nav><!-- /.dl-menuwrapper -->


<div class="entry-header">
  <div class="image-credit">Image source: <a href="">Hyunje Jo</a></div><!-- /.image-credit -->
  
    <div class="entry-image">
      <img src="/images/bg0.jpg" alt="Hyunje Blog">
    </div><!-- /.entry-image -->
  
  <div class="header-title">
    <div class="header-title-wrap">
      <h1>Hyunje Blog</h1>
      <h2>Hyunje Blog</h2>
    </div><!-- /.header-title-wrap -->
  </div><!-- /.header-title -->
</div><!-- /.entry-header -->

<div id="main" role="main">
  
<article class="hentry">
  <header>
    
      <div class="entry-image-index">
        <a href="/data%20analysis/2016/02/01/twitter-analysis/" title="PMI를 이용한 Twitter 데이터에서의 이슈 키워드 추출"><img src="/images/bg4.jpg" alt="PMI를 이용한 Twitter 데이터에서의 이슈 키워드 추출"></a>
      </div><!-- /.entry-image -->
    
    <div class="entry-meta">
      <span class="entry-date date published updated"><time datetime="2016-02-01T12:15:00-05:00"><a href="/data%20analysis/2016/02/01/twitter-analysis/">February 01, 2016</a></time></span><span class="author vcard"><span class="fn"><a href="/about/" title="About Hyunje Jo">Hyunje Jo</a></span></span>
      <!--
      
      <span class="entry-reading-time">
        <i class="fa fa-clock-o"></i>
        
Reading time ~1 minute
      </span>
      -->
      <!-- /.entry-reading-time -->
      
    </div><!-- /.entry-meta -->
    
      <h1 class="entry-title"><a href="/data%20analysis/2016/02/01/twitter-analysis/" rel="bookmark" title="PMI를 이용한 Twitter 데이터에서의 이슈 키워드 추출" itemprop="url">PMI를 이용한 Twitter 데이터에서의 이슈 키워드 추출</a></h1>
    
  </header>
  <div class="entry-content" style="overflow:hidden; height:500px;">
    <p>제 1회 빅데이터 경진대회</p>

<p>2013년도에 Team Herring이란 이름으로 제1회 빅데이터 경진대회에 참가했었다.</p>

<p>그 당시에 트위터 데이터를 이용하여 각 날짜별 이슈 키워드를 추출하는 문제를 해결하였는데, 그 때 작성하였던 문서를 업로드한다.</p>

<p><iframe src="//www.slideshare.net/slideshow/embed_code/key/hsQDQcOphmBuHt" width="668" height="714" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe> <div style="margin-bottom:5px"> <strong> <a href="//www.slideshare.net/RetrieverJo/pmi-twitter-57723391" title="PMI를 활용한 twitter 데이터에서의 이슈 키워드 추출" target="_blank">PMI를 활용한 twitter 데이터에서의 이슈 키워드 추출</a> </strong> from <strong><a href="//www.slideshare.net/RetrieverJo" target="_blank">Jo Hyun Je</a></strong> </div></p>

  </div><!-- /.entry-content -->
  
  <center><div><a href="/data%20analysis/2016/02/01/twitter-analysis/" class="btn">Read More...</a></div></center>
  
</article><!-- /.hentry -->

<article class="hentry">
  <header>
    
      <div class="entry-image-index">
        <a href="/data%20analysis/2015/12/21/yes24-recommendation-1/" title="Yes24 책 추천 알고리즘 분석 대회 후기"><img src="/images/bg2.jpg" alt="Yes24 책 추천 알고리즘 분석 대회 후기"></a>
      </div><!-- /.entry-image -->
    
    <div class="entry-meta">
      <span class="entry-date date published updated"><time datetime="2015-12-21T09:15:00-05:00"><a href="/data%20analysis/2015/12/21/yes24-recommendation-1/">December 21, 2015</a></time></span><span class="author vcard"><span class="fn"><a href="/about/" title="About Hyunje Jo">Hyunje Jo</a></span></span>
      <!--
      
      <span class="entry-reading-time">
        <i class="fa fa-clock-o"></i>
        
Reading time ~1 minute
      </span>
      -->
      <!-- /.entry-reading-time -->
      
    </div><!-- /.entry-meta -->
    
      <h1 class="entry-title"><a href="/data%20analysis/2015/12/21/yes24-recommendation-1/" rel="bookmark" title="Yes24 책 추천 알고리즘 분석 대회 후기" itemprop="url">Yes24 책 추천 알고리즘 분석 대회 후기</a></h1>
    
  </header>
  <div class="entry-content" style="overflow:hidden; height:500px;">
    <p>얼마전 한국 정보화 진흥원이 관리하는 <a href="http://crowd.kbig.kr">개방형 문제해결 플랫폼</a>에 올라온 Yes24 도서 추천 알고리즘 대회가 종료되었다.</p>

<p>총 230여명이 참여하였고, 25팀에 최종 결과물을 제출한 대회였다. 이 대회에서 친구와 같이 참여했으며, 입상은 아니지만 우수한 알고리즘 혹은 분석결과를 제시한 팀에 뽑혔다. <a href="http://crowd.kbig.kr/board/notice_view.php?srno=3">결과</a></p>

<p>이 포스트에서는 어떤 과정으로 대회에 참여 하였으며, 어떤 알고리즘을 이용하였는지 설명할 것이다. 또한, 다음 과정들은 혼자 진행한 것이 아니라 팀원과 함께 진행하였다.</p>

<p><br></p>

<h2>0. 문제</h2>

<p>다음과 같은 문제를 해결하는 것이 이 대회의 목적이었다.</p>

<ul>
<li>문제 </li>
</ul>

<p>YES24에서 제공하는 Training Data Set를 활용하여,  추천구매에 대한 예측력을 제고할 수 있는 도서추천 알고리즘을 만들어 주시기 바랍니다. (Test Data Set은 이미 별도로 가지고 있으나 공개하지 않고 이는 사후적으로 제출된 솔루션 결과를 평가하는 목적으로 사용하게 됩니다.)  </p>

<p>이 도서추천 알고리즘은 Hardware, Computing Time 등의 여러 가지 이유로 5개 카테고리에 한정하여 진행됩니다.  &quot;인문/자기계발/국내문학/해외문학/종교&quot; 카테고리 중 한 개 또는 여러 개의 카테고리를 선정하여 도서추천 알고리즘을 만들어 주시기 바랍니다.</p>

<ul>
<li>평가방법 </li>
</ul>

<p>제출된 추천 알고리즘은 다음의 2가지 평가기준에 의해 평가됩니다.</p>

<ol>
<li>예측결과 (Test Data Set에 기반한 제출된 알고리즘의 예측결과) </li>
<li>창의성/창의적 모델링 접근방법 </li>
</ol>

<p>이 두 가지 기준에 의해 3명의 평가위원이 제출된 알고리즘을 평가를 하게 됩니다.</p>

<p>--</p>

<p>하지만, 문제가 너무 러프하였다. 어떤 식으로 예측 결과를 내야하는지에 대한 세부적인 정보도 없었으며, 창의적 모델링 접근법을 어떻게 평가할 것인지에 대한 정보 역시 없어서 처음 문제를 접한 후에 이것을 어떻게 해석해야 하나 고민을 많이 하였다. 결론은 주최측에서 러프하게 냈으니 그냥 제시 기준에만 맞춰 내자는 결론이 나왔다.</p>

<p><br></p>

<h2>1. 데이터</h2>

<p>주최측에서 제공한 데이터는 사용자가 어떤 책을 구매하였는지에 대한 정보가 약 53만개 정도 들어있는 데이터였으며, 다음과 같은 컬럼들로 구성되어 있었다. 아쉽게도 대회의 규정상 데이터는 다른 목적으로 사용이 불가능하여 공개하지는 못한다.</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">&quot;date&quot;,&quot;state&quot;,&quot;uid&quot;,&quot;title&quot;,&quot;category&quot;,&quot;author&quot;,&quot;isbn&quot;,&quot;company&quot;,&quot;pub_day&quot;,&quot;time&quot;,&quot;amount&quot;,&quot;cart&quot;,&quot;cart_date&quot;,&quot;mobile&quot;,&quot;addr1&quot;,&quot;addr2&quot;
</code></pre></div>
<p>처음 문제와 데이터를 봤을 때 <strong>데이터가 생각보다 적다</strong>는 생각이 들었다. 실제 문제에서 요구한 카테고리는 <em>인문/자연/자기계발/국내문학/해외문학/종교</em>에 한정되어 있었으며, 이 카테고리에 대한 데이터만 추렸을 때는 10만건이 약간 넘는(정확하게 기억이 나지 않는다.) 정도였으며, 게다가 각 카테고리별로 추천을 수행하게 된다고 가정하면 그 수는 더욱 줄어들 것이기 때문이었다.</p>

<p><br></p>

<h2>2. 알고리즘 고민</h2>

<p>앞서 설명하였듯 데이터가 적은 편이었기 때문에 기본 <a href="https://en.wikipedia.org/wiki/Collaborative_filtering">CF</a> 모델 혹은 <a href="http://dl.acm.org/citation.cfm?id=1608614">ALS</a>를 그대로 적용하기에는 적절하지 않을 것이라 생각하였다. 또한 이런 모델만 적용하였을 때는 입상권에 들기 어려울 것이라 판단하여 좀 더 복잡한 추천 알고리즘을 구성할 필요가 있었다.</p>

<p>그래서 혹시 다른 정보를 같이 활용할 수 있을까 하였는데 제공된 데이터에서는 추가적으로 가지고 올 수 있는 정보가 많지 않았다. 기껏해야 구매한 시간, 구매한 위치, 구매한 시간과 카트에 넣은 시간의 차이 정도였고 이 정보를 따로 분류하거나 파싱하기에는 노력 대비 효율이 좋지 않을 것이라 예상하여 이 정보들을 추가적으로 활용할 수 없었다.</p>

<p>물론 평가 방법중 단순히 창의적인 모델링에 집중한다면 <em>위치기반</em>의 추천과 같은 추천이 가능할 수 있겠지만 데이터가 많지 않아 실제 좋은 성능을 내기는 어려울 것이라 판단하였다. 따라서 제시된 데이터가 아닌 다른 데이터를 수집하여 활용하여야 했다. 주최측에서도 모델링을 위해 외부변수를 추가적으로 사용한 경우에 대해 언급하였으므로 추가 데이터를 사용할 수 있을 것이라 생각했다.</p>

<p>그래서 고민후에 생각한 방법은 각 사용자들이 주로 어떤 토픽의 책을 구매하였는지에 대해 모델링을 수행하는 방법이었다. 예를 들면 단순히 </p>

<p>&quot;이 사람은 국내문학에 관련된 책을 많이 구매했네&quot;가 아닌</p>

<p><strong>&quot;이 사람은 국내문학 중에서도 사랑에 관련된 책을 많이 구매했네&quot;</strong> 혹은 <strong>&quot;이 사람은 국내문학 중에서도 사랑에 관련된 책에 관심이 있네&quot;</strong>와 같은</p>

<p>정도의 모델링을 수행하여, 이것을 CF 혹은 ALS와 결합한다면 좀 더 좋은 성능을 내지 않을까 생각하였다. 이 과정에서 LDA를 이용한 토픽 모델링을 사용할 수 있을 것이라고 판단하였다. LDA를 이용하여 토픽 모델링을 수행하게 되면 각 Document 별로 생성된 Topic에 대한 Probability 를 알 수 있다. 때문에 각 사용자를 하나의 Document로 하여 LDA를 수행하게 된다면 각 사용자별로 관심있는 Topic에 대해 알 수 있고, 역으로 각 토픽별로 사용자를 클러스터링 할 수 있을 것이다.</p>

<p>Topic Modeling을 수행하기 위한 데이터는 책의 소개문구를 이용하기로 하였다.</p>

<p><br></p>

<h2>3. 알고리즘 디자인</h2>

<p>다음 과정은 생각한 방법들을 기반으로 하여 어떻게 추출한 토픽과 ALS를 연관시킬지에 대한 디자인을 하는 것이었다. 고민의 결론은 각 사용자별로 LDA를 기반으로 한 Topic Modeling을 수행하고, 생성된 Topic을 기반으로 사용자를 클러스터링 한 후, 각 클러스터별로 ALS기반의 추천을 수행하고, 가중평균을 이용하여 각 사용자에게 최종 추천을 수행하는 것이었다.</p>

<p>다음과 같은 과정으로 추천이 수행된다.</p>

<ol>
<li>각 사용자별로 구매한 책들의 소개글을 합하여 하나의 Document라 가정한 후, 각 사용자를 하나의 Document, 각 단어를 Word로 하는 LDA를 수행한다.</li>
<li>각 Document(사용자) 별로 높은 상위 3 개의 Topic에 해당 사용자를 할당한다.</li>
<li>각 클러스터(Topic)별로 User-Item Matrix를 생성한다. 이 Matrix를 생성할 때, 해당 클러스터에 속하는 사용자만을 이용하여 구성한다.</li>
<li>각 클러스터별로 생성한 User-Item matrix를 이용하여 ALS를 수행한다. ALS의 수행 결과로 각 사용자별 아이템에 대한 예상 수치를 얻을 수 있다.</li>
<li>모든 사용자별로 각 사용자가 속하는 3 개의 클러스터에서 각 클러스터별 유사도와, 각 클러스터의 ALS에서 추천된 N개의 아이템의 아이템과 그 예상 수치를 이용하여 각 아이템별로 가중평균을 구한다. 같은 아이템이 양쪽 클러스터에서 같이 등장한다면 추가 가중치를 부여한다.</li>
<li>계산된 가중평균을 기준으로 내림차순 정렬하여 최대 N 개를 추천한다.</li>
</ol>

<p><br></p>

<h2>4. 데이터 크롤링</h2>

<p>앞서 디자인한 알고리즘을 수행하기 위해선 추가적인 데이터의 수집이 필요했다. 따라서 Yes24 홈페이지에서 각 책별로 존재하는 책 소개 내용을 수집하였으며, 책 소개가 없는 경우에는 책 제목으로 대체하였다.</p>

<p>이 과정은 같이 대회에 참여하였던 <a href="http://chiwanpark.com">박치완</a>님이 도와주었다.</p>

<p><br></p>

<h2>5. 구현</h2>

<p>알고리즘의 구현체는 <a href="https://github.com/RetrieverJo/yes24">Github Repository</a>에 업로드 하였다.</p>

<p>초기 계획은 비교 대조군을 몇개 만들어 놓고, 그 중에 가장 성능이 좋은 것을 선택하여 제출하려 했으나.... 짧은 개발 기간(3일)로 인해 꿈으로만 남았다.</p>

<p><strong>아직 코드가 제대로 정리되어 있지 않다. 코드 정리가 필요한 상황이다.</strong></p>

<p>Maven 기반의 Scala 프로젝트이며, 동작 환경은 Spark 1.5.x 이다.</p>

<p><br></p>

<h2>6. 중간 결과</h2>

<p>LDA를 이용하여 각 토픽별로 어떠한 단어들이 등장하는지에 대한 중간 결과를 확인할 수 있었다. 다음과 같다.</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">TOPIC0:                                                                         
사랑      0.038950771399064034
인생      0.03515207672645974
이야기     0.025418685837176613
감각      0.025245626823315444
마음      0.020893368477979433
현장      0.01642261966657828
사람      0.01481647339996354
자신      0.013958826369854944
스님      0.011214607773803646
가지      0.009985940266383107

TOPIC1:
세계      0.04994877001062086
경제      0.034433078200563016
우리      0.03254562163029728
한국      0.01958911018319702
미래      0.01692410713112926
통해      0.01682498169768221
독자      0.01671768092723129
지금      0.01665981297149608
작가      0.016495697094411226
중국      0.01644162358505943

TOPIC2:
소설      0.038058091178287554
작가      0.03164151030320994
사랑      0.014982771499678716
작품      0.013980950020051253
여자      0.011241435352324514
시인      0.010293643455372868
이번      0.009588547443499656
문학      0.009384890941094364
남자      0.009172136669658392
세계      0.00875815649112367

TOPIC3:
철학      0.027872185181795257
고전      0.01899458579086188
사상      0.009970794191175998
역사      0.009145088267109771
이해      0.009090435616220563
대한      0.00891559440526876
증명      0.007949637931088908
저자      0.007737877329008972
시대      0.007504918744110347
지식      0.007190884930254014

TOPIC4:
세계      0.024141657195419507
확신      0.023254790478907144
무엇      0.020561955505817603
작품      0.01796548295193048
정치      0.015422368617599365
역사      0.013493955309093881
이야기     0.013344052090964226
사건      0.012988721657737918
인생      0.01289824138631931
가장      0.011198337930209776

TOPIC5:
작품      0.020456171283759938
독자      0.015376050675311888
작가      0.015130099763268453
이야기     0.014561306081437523
시리즈     0.013887056794027141
소설      0.01234213886292947
아이디어            0.011188108952049788
세계      0.010898025197746665
고전      0.008525176136316384
사랑      0.00786297203438913

TOPIC6:
사건      0.02103824609772385
작품      0.017807257180762197
소설      0.017457953856403502
작가      0.01712331329720654
살인      0.008785026764247469
이야기     0.0072546581159950805
독자      0.006984216038646738
시리즈     0.006544779598922323
일본      0.006095210735821216
시작      0.00534694833892813

TOPIC7:
인생      0.04574771191525166
우리      0.0331295665851022
마음      0.02600983683922045
사람      0.02263497670866045
시간      0.018730727114082156
독서      0.017798183470428906
세상      0.01485754375840436
통해      0.01416859840332696
대해      0.013191241858221675
저자      0.013101317163704397

TOPIC8:
사람      0.024483916096268845
강의      0.020224518288395794
대화      0.016782886277784723
교수      0.015770886259112514
최고      0.010996576573475025
사회      0.010535599207417902
방법      0.009966624687028717
성공      0.009807661545913731
상대      0.009222202033299464
습관      0.009121246755516243

TOPIC9:
사랑      0.02213784197615728
이야기     0.01772322621102953
대한      0.017309430909218677
여행      0.01465205015939723
사람      0.01456699329694893
우리      0.013797265937478648
자신      0.01166775423889618
통해      0.011017462627371669
일상      0.009267416924552943
사회      0.009213923922705928

TOPIC10:
이야기     0.020616023081828375
편지      0.013932305666324857
소설      0.013669690497313864
과거      0.01076967158824421
자신      0.009807666523129583
소년      0.009688170650006968
고민      0.009565007212529605
작품      0.009468309454259458
기억      0.009393742898172668
작가      0.009387598027138165

TOPIC11:
하나님     0.028877801631496967
성경      0.026571636427607372
교회      0.016071591478662054
우리      0.013651128335939367
기도      0.01190310850373663
저자      0.011412814240508724
기독교     0.009753764891267266
말씀      0.008998065889125427
사람      0.008869120816531921
예수      0.008501843457410042

TOPIC12:
사람      0.028783455203289957
공부      0.01789677322548907
저자      0.01758348460534456
마음      0.016980841060103936
심리학     0.015450609696654164
자신      0.015426573857353887
방법      0.014921197551560475
생각      0.013316907130197864
심리      0.012283333703454424
글쓰기     0.011017951281154943

TOPIC13:
사랑      0.01629699122010116
세상      0.014119800121617326
자신      0.008852907628560024
남자      0.008599152420418884
시인      0.008096688544342551
사람      0.007591992606568243
작가      0.007224683357099236
이야기     0.007044728358115589
조선      0.006744395180701537
여자      0.006657011146982586

TOPIC14:
감정      0.041194666696242735
우리      0.029147186160630938
사랑      0.027256701576788202
이야기     0.019030340353812132
자신      0.016117387258532154
용기      0.015257783215476176
철학자     0.015150579463710349
하나      0.01503732449961679
저자      0.012974779070331585
독자      0.012641342715594273

TOPIC15:
인류      0.0498372102472762
인간      0.03379429042702267
소설      0.028014827738242452
작품      0.021200628208484628
과학      0.01794840144695439
만남      0.01641915725242832
시작      0.014654742183719486
상상력     0.01445620734844426
사회      0.010700420329539783
창조      0.01057772568162761

TOPIC16:
성공      0.02660171637591407
사람      0.022367799493907953
자신      0.01505699603653131
저자      0.014896546653713778
인생      0.013526588119255934
시간      0.010959792605428396
당신      0.009557989569069886
생각      0.008127274061635938
가지      0.007727816536524141
방법      0.007410024004336087

TOPIC17:
이야기     0.023695377724228722
인간      0.01946201361094322
역사      0.016362912320875042
우리      0.015870888389808404
시대      0.013738434081786773
사회      0.013643307625891594
세계      0.010892085337965499
신화      0.010808663879575329
지식      0.010749682143135467
저자      0.00957354797979392

TOPIC18:
우리      0.0378256076523149
사람      0.029814703470588417
가장      0.0277431062535585
이야기     0.027134071365245132
행복      0.020619528174727907
인생      0.01857040565668168
당신      0.016352557769813394
죽음      0.016078070887595428
가족      0.01538197357160221
자신      0.015314170280887558

TOPIC19:
작품      0.029106267733493736
인간      0.016823144261245
문학      0.012818792642740058
사회      0.012617625920241113
대한      0.01120908393427178
소설      0.011030423016008779
세기      0.0105561854448285
작가      0.010293366024680773
대표      0.009802885112187715
사랑      0.007696910129304892
</code></pre></div>
<p>각 토픽 별로 어떠한 단어들이 구분되는지 추측할 수 있다. 예를 들면 Topic 0은 사랑과 인생에 관한 이야기, Topic 1은 경제에 관련된 것들, Topic 11은 종교에 관련된 것들로 말이다.</p>

<p>이 결과는 LDA의 수행 결과중 일부인데, 어떤 새로운 Document가 갖고 있는 단어의 분포를 이용하여 위에서 보이는 것과 같은 각 Topic 별 단어의 분포를 이용해 새 Document가 어떤 Topic에 가까운지에 대한 분포를 추론할 수 있다. 물론, 트레이닝에 사용된 Document 역시 추론할 수 있으며 그 결과는 LDA의 수행 결과중 하나로 이미 존재한다.</p>

<p><br></p>

<h2>7. 최종 결과</h2>

<p>최종 결과는 <a href="https://db.tt/G4NmGugN">링크</a>에서 다운로드 할 수 있다. 해당 링크는 모든 카테고리(6개)에 속하는 데이터들 안에서 추천을 수행한 경우이다.</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">사용자 ID[Delimiter]책 제목[Delimiter]추천 Score
</code></pre></div>
<p>형태로 저장이 되어있다.</p>

<p><br></p>

<h2>8. 부족한 부분</h2>

<ol>
<li><p><strong>정말 한심하게도 성능평가가 수행되어 있지 않다.</strong> 단순히 추천 결과만 내어놓았다. 초기 예상으로는 3일정도의 개발 기간이라면 추천 결과를 평가하는 Metric도 정의하여 다양한 알고리즘의 성능을 평가해 볼 수 있을 것이라 예상하였지만, Spark에서 RDD 연산을 반복하여 수행하는 과정에서 여러 문제점들이 발생하는 바람에, 그 부분을 다른 방법으로 해결하는 과정에서 시간이 많이 소비되었다. 심지어 파라미터 최적화도 수행하지 못하였다..;;</p></li>
<li><p><strong>부족한 알고리즘의 구성.</strong> 실제 알고리즘을 개발하거나, 수정한 것이 아닌 단순히 두 개의 알고리즘을 잘 연결시킨 것일 뿐이다. 좀 더 좋은 성능을 이끌어내려면 깊은 레벨에서의 개선이 필요할 것이다.</p></li>
<li><p><strong>코드가 지저분하다.</strong> 대회에 제출하였던 코드 그 상태이므로 주석도 제대로 달려있지 않고, 코드가 깔끔하지 않다. 게다가 검증을 못하였으므로 정상적으로 작성한 코드인지도 검증이 안되어있다. 한심하다. 다음 포스트를 작성할 때는 개선된 코드를 이용해 설명할 것이다.</p></li>
<li><p><strong>상을 못탔다.</strong> 상을 못탔다.... 시간투자를 좀 더 해서 결과 더 다듬고 했으면 괜찮은 결과가 나왔을 것 같은데 그러지 못했다. 어디 이력서에 한줄 넣기도 애매한 결과다.</p></li>
</ol>

  </div><!-- /.entry-content -->
  
  <center><div><a href="/data%20analysis/2015/12/21/yes24-recommendation-1/" class="btn">Read More...</a></div></center>
  
</article><!-- /.hentry -->

<article class="hentry">
  <header>
    
      <div class="entry-image-index">
        <a href="/data%20analysis/2015/10/24/advanced-analytics-with-spark-ch5/" title="Spark & 머신 러닝 - Anomaly Detection"><img src="/images/bg1.jpg" alt="Spark & 머신 러닝 - Anomaly Detection"></a>
      </div><!-- /.entry-image -->
    
    <div class="entry-meta">
      <span class="entry-date date published updated"><time datetime="2015-10-24T13:15:00-04:00"><a href="/data%20analysis/2015/10/24/advanced-analytics-with-spark-ch5/">October 24, 2015</a></time></span><span class="author vcard"><span class="fn"><a href="/about/" title="About Hyunje Jo">Hyunje Jo</a></span></span>
      <!--
      
      <span class="entry-reading-time">
        <i class="fa fa-clock-o"></i>
        
Reading time ~1 minute
      </span>
      -->
      <!-- /.entry-reading-time -->
      
    </div><!-- /.entry-meta -->
    
      <h1 class="entry-title"><a href="/data%20analysis/2015/10/24/advanced-analytics-with-spark-ch5/" rel="bookmark" title="Spark & 머신 러닝 - Anomaly Detection" itemprop="url">Spark & 머신 러닝 - Anomaly Detection</a></h1>
    
  </header>
  <div class="entry-content" style="overflow:hidden; height:500px;">
    <p>이 포스트는 K-means Clustering을 이용하여 네트워크 트래픽에서의 비정상 트래픽을 감지해 내는 과정에 대한 내용을 담고 있다. 이 장에서 수행한 결과는 수행시마다 바뀌기 때문에, 수행 결과가 이 문서에서 제시하는 결과와 완벽히 일치하지 않는다.</p>

<p>이 포스트는 <a href="http://shop.oreilly.com/product/0636920035091.do">Advanced Analytics with Spark</a>을 정리한 글이다.
<br>
<br></p>

<h2>Unsupervised Learning and Anomaly Detection</h2>

<p>앞선 챕터에서 살펴본 Classification과 Regression은  강력하기도 하며 많은 연구가 진행된 머신 러닝 테크닉중 하나이다. 하지만 Decision Tree나, Random Dicision Forest등을 이용하여 새롭게 들어온 데이터를 이용해 어떤 값을 예측을 할 때는 그 값이 이전 훈련 과정에서 이미 알고 있는 값 중 하나여야만 했다. 그리고 이러한 과정이 Supervised Learning의 일반적인 방식이라 설명하였다.</p>

<p>하지만 다음과 같은 경우가 있을 수 있다. 어떤 인터넷 쇼핑몰 사이트의 회원을 그들의 쇼핑 습관과 관심 상품등을 기준으로 구분하고자 한다. 이 때의 입력 Feature는 사용자들의 구매 목록, 클릭한 내용들, 통계학적 데이터와 같은 것들이 될 수 있다. 이러한 입력 데이터들의 결과로 아웃풋은 사용자들의 그룹이 되어야 하는데, 예를 들면 한 그룹은 패션에 민감한 사람들의 그룹 또 다른 그룹은 가격에 민감한 사람들의 그룹과 같은 형태를 나타내어야 한다.</p>

<p>만약 Decision Tree와 같은 Supervised Learning 테크닉만 사용하여 위 문제를 해결하려 한다면 새로운 데이터를 각각 Classifier에 적용시켜야 하는데  어떤 데이터가 어떤 값을 가져야 하는지에 대한 사전정보가 전혀 없기 때문에 불가능에 가깝다. 떄문에 이런 문제를 해결할 때에는 Supervised Learning이 아닌 <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">Unsupervised Learning</a>을 이용하여 해결해야 한다. Unsupervised Learning은 Supervised Learning과 다르게 어떤 값을 예측해야 한다고 하여 사전에 그 값이 어떤 것인지 트레이닝 시킬 필요가 없다. 왜냐하면 Unsupervised Learning에 속하는 방법들은 <strong>주어진 데이터들 사이에서 비슷한 것들끼리 그룹을 만들고, 새로운 데이터가 어떤 그룹에 속하는지 판단하는 역할을 하기 때문이다.</strong></p>

<p>Anomaly Detection은 이름에서도 알 수 있듯이 비정상적인 것을 찾는 것을 의미한다. Anomaly Detection은 네트워크 공격 혹은 서버에서의 문제 발생등을 검출하는데에 이용된다. 여기서 중요한 것은 새로운 형태의 공격이라던가 그동안 발생하지 않았던 서버 문제등을 발견할 수 있다는 것이다. Unsupervised Learning은 이 경우에 일반적인 형태의 데이터를 이용해 훈련하고, 기존에 있던 것과 다른 것이 입력으로 들어왔을 때 그것을 감지하는 형태로 Anomaly Detection 문제를 해결할 수 있다.</p>

<p><br>
<br></p>

<h2>K-means Clustering</h2>

<p>클러스터링 방법은 Unsupervised Learning 중에서 가장 잘 알려진 방법 중 하나이다. 클러스터링은 <strong>주어진 데이터를 이용하여 가장 자연스러운 그룹을 찾아내는 것</strong>을 시도하는 알고리즘이다. K-means Clustering은 이러한 클러스터링 알고리즘 중에 가장 널리 알려진 알고리즘이다. 데이터셋에서 \(k\)개의 클러스터를 찾는데 이 때 \(k\)는 데이터를 분석하는 사람으로부터 주어진 것이다. 또한 이 \(k\)는 Hyperparameter이며, 각각의 데이터마다 최적 값이 다르다. 실제로 이 챕터에서 적절한 \(k\)값을 찾는 과정이 중요한 부분이 될 것이다.</p>

<p>사용자들의 행동에 대한 데이터 혹은 거래 기록에 대한 데이터에서 <code>비슷하다</code>라는 것은  어떤 것인가? 이러한 질문에 대답하기 위하여 K-means Clustering 방식은 데이터 사이의 거리에 대한 정의를 필요로한다. 가장 간단한 방법중 하나는 Spark MLlib에도 구현되어 있는 Eculidean Distance를 이용하는 것이다. 이것을 이용하면 <code>비슷한</code>데이터는 거리가 가깝게 나올 것이다.</p>

<p>K-means Clustering에서의 각 클러스터는 하나의 데이터 포인트로 표현된다. 각 클러스터에 속하는 데이터 포인트들의 평균값이 그 클러스터의 중심이 되며, 각 클러스터의 중심을 평균으로 구하기 때문에 K-means라는 이름이 붙었다. 이 때의 가정은 각 Feature의 값들이 숫자 형태의 값임을 가정으로 하며, 각 클러스터의 중심은 <strong>centroid</strong>라고 부른다. K-means Clustering의 동작 과정은 매우 간단하다. 제일 먼저 알고리즘은 \(k\)개의 데이터를 선택함으로써 각 클러스터의 centroid를 초기화한다. 그리고 각 데이터는 가장 가까운 centroid의 클러스터로 할당된다. 그리고 각각의 클러스터별로 새로운 데이터의 평균을 구해 새로운 centorid로 지정한다. 이 과정이 반복된다.</p>

<p><br>
<br></p>

<h2>Network Intrusion</h2>

<p>사이버 공격이라는 형태의 해킹이 뉴스에서도 심심치 않게 등장하고있다. 몇몇 공격들은 네트워크 트래픽을 점령하여 정상적인 트래픽을 밀어내기도 한다. 하지만 네트워킹 소프트웨어의 결점 등을 이용해 컴퓨터에 대한 비정상적인 권한을 탈취하는 공격도 존재한다. 이 때 공격받는 컴퓨터에서는 공격받는지 알아채기가 매우 어렵다. 이러한 공격(<a href="https://en.wikipedia.org/wiki/Exploit_(computer_security)">Exploit</a>)을 찾아내기 위해선 매우 많은 네트워크 요청들 사이에 비정상적인 공격을 찾아내야 하기 때문이다.</p>

<p>몇몇 공격들은 특정 알려진 패턴을 따른다. 예를 들면 가능한 모든 포트를 빠른 시간안에 접근하는데, 이것은 일반 소프트웨어들은 일반적으로 하지 않는 패턴이다. 하지만 이것은 일반적으로 Expolit을 하기 위한 컴퓨터를 찾는 공격자들이 일반적으로 제일 첫단계로 수행하는 과정이다.</p>

<p>만약 짧은 시간 내애 몇개의 포트에 대해 접속 시도가 발생한다면 몇 개의 접속 시도는 일반적인 것으로 간주 될 수 있지만 대부분의 시도들은 비정상 적인 것일 것이므로 우리는 이것을 port-scanning 공격이 들어온 것으로 판단할 수 있다. 이러한 이미 알려진 형태의 공격들은 미리 알고 감지할 수 있다. 하지만 알려져 있지 않은 형태의 공격이 들어온다면 어떻게 해야될까? 가장 큰 문제점은 어떤 형태의 공격일지 모른다는 것이다. 그동안과의 다른 형태의 접근 시도를 잠재적인 공격 트래픽으로 간주하여 감시해야 할 것이다.</p>

<p>여기에서 Unsupervised Learning이 사용될 수 있다. K-means Clustering과 같은 방법을 이용하면 비정상적인 네트워크 연결을 탐지해 낼 수 있다. K-means Clustering을 이용하여 네트워크 연결을 클러스터링 하고 기존의 정상적인 네트워크 연결의 클러스터와는 다른 연결이 요청되었을 때, 이것을 비정상적인 연결이라고 판단할 수 있다.</p>

<p><br>
<br></p>

<h2>KDD Cup 1999 Data Set</h2>

<p>KDD Cup은 ACM에서 매년 열리는 데이터 마이닝 대회이다. 각 해마다 머신 러닝 문제가 주어지고, 그것을 얼마만큼의 정확도로 해결하는가에 대한 대회이다. 1999년에 열렸던 대회는 네트워크 침입에 대한 대회였는데 데이터셋은 지금도 접근 가능하다. 이 포스트에서는 이 데이터를 Spark을 통해 분석하여 비정상적인 접근을 찾아내도록 할 것이다.</p>

<p>다행히도 대회 개최자들이 이미 Raw 네트워크 데이터를 전처리하여 요약한 데이터를 제공하며 약 743MB의 490만개의 네트워크 연결에 대한 데이터이다. 데이터가 엄청 많은 것은 아니지만 이 챕터에서 수행하고자 하는 것들을 수행해보기에는 적절하다. 데이터 셋은 <a href="http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data.gz">이 링크</a>에서 다운로드 할 수 있다.</p>

<p>데이터의 각 행은 전달된 바이트 수, 로그인 시도, TCP 에러 등과 같은 정보를 포함한다. 각 데이터는 CSV 형태로 존재하며 제일 마지막 레이블을 제외한 41개의 Feature로 구성되어 있다.</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">0,tcp,http,SF,215,45076,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,1,0.00,0.00,0.00,0.00,1.00,0.00,0.00,0,0,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,normal.
</code></pre></div>
<p>위와 같은 형태로 존재하는데, TCP 연결, HTTP 서비스, 215바이트 송신, 45076바이트 수신과 같은 정보를 나타내며 각 Feature의 의미는 다음과 같다.</p>

<p><center><img src="https://db.tt/DO8fq1YF" width="300"></center></p>

<p>데이터를 살펴보면 많은 값이 15번째 컬럼과 같이 0 혹은 1임을 알 수 있다. 이것은 해당 값이 있는지 없는지 여부를 나타내며 이전 포트스에서처럼 특정 값을 비트로 표현한 것이 아니라 각각의 Feature가 특정 의미를 갖고 있는 것이다. 그리고 <em>dst_host_srv_rerror_rate</em> 이후의 컬럼은 0.0에서 1.0까지의 값을 갖는다.</p>

<p>가장 마지막 필드에는 해당 네트워크 연결의 레이블이 주어져있다. 대부분의 레이블이 <code>normal</code>이지만 몇몇 값들은 다음과 같이 특정 공격에 대한 타입이 기입되어 있다.</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">0,icmp,ecr_i,SF,1032,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,511,511,0.00,0.00,0.00,0.00,1.00,0.00,0.00,255,255,1.00,0.00,1.00,0.00,0.00,0.00,0.00,0.00,smurf.
</code></pre></div>
<p>이러한 정보들은 훈련 과정에서 유용하게 사용될 수 있지만, 이 장에서 하고자 하는 것은 비정상적인 접근 트래픽을 감지하는 것이기 때문에 잠재적으로 새롭고 알려지지 않은 접근을 찾아낼 것이다. 따라서 이 레이블 정보는 거의 제외된 상태로 사용될 것이다.</p>

<p><br>
<br></p>

<h2>A First Take on Clustering</h2>

<p>kddcup.data.gz파일의 압축을 해제하고, <strong>kddcup.data.corrected</strong> 파일을 HDFS로 업로드한다. 이 포스트에서는 <strong>/kdd/kddcup.data.corrected</strong>경로에 업로드 한 것을 가정한다.</p>

<p>Spark-shell에서 다음과 같이 파일을 로드하고, 각 레이블별로 어느정도의 양이 있는지 확인함으로써 간단히 데이터를 확인한다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">rawData</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="o">(</span><span class="s">&quot;/kdd/kddcup.data.corrected&quot;</span><span class="o">)</span>
<span class="n">rawData</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="sc">&#39;,&#39;</span><span class="o">).</span><span class="n">last</span><span class="o">).</span><span class="n">countByValue</span><span class="o">().</span><span class="n">toSeq</span><span class="o">.</span><span class="n">sortBy</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">_2</span><span class="o">).</span><span class="n">reverse</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>
</code></pre></div>
<p>다음과 같이 23개의 레이블이 존재하며, 가장 많은 공격 형태는 smurf 이고, neptune 순서이다.</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">(smurf.,2807886)
(neptune.,1072017)
(normal.,972781)
...
</code></pre></div>
<p>K-means Clustering을 수행하기 전에 주의해야 할 것이 있다. KDD 데이터셋은 숫자 형태의 데이터가 아닌 Feature(nonnumeric feature)가 있다. 예를 들면 두 번째 열과 같은 경우에는 그 값이 <strong>tcp, udp, icmp</strong>와 같은 값들이다. 하지만 K-means Clustering에서는 숫자 형태의 Feature만 사용할 수 있다. 처음에는 이 값을들 무시하고 진행을 할 것이다. 그리고 뒷 부분에서 이 Categorical Feature를 포함하여 클러스터링을 수행할 것이다.</p>

<p>다음의 코드는 데이터를 파싱하여 K-means Clustering에 필요한 데이터로 필터링 하는 과정이다. 이 과정에서 제일 마지막의 레이블을 포함한 Categorical Feature를 제외한다. 그리고 이 데이터를 이용하여 K-means Clustering을 수행한다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.spark.mllib.linalg._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.mllib.clustering._</span>

<span class="k">val</span> <span class="n">labelsAndData</span> <span class="k">=</span> <span class="n">rawData</span><span class="o">.</span><span class="n">map</span> <span class="o">{</span> <span class="n">line</span> <span class="k">=&gt;</span>
    <span class="k">val</span> <span class="n">buffer</span> <span class="k">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="sc">&#39;,&#39;</span><span class="o">).</span><span class="n">toBuffer</span>
    <span class="n">buffer</span><span class="o">.</span><span class="n">remove</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">3</span><span class="o">)</span>
    <span class="k">val</span> <span class="n">label</span> <span class="k">=</span> <span class="n">buffer</span><span class="o">.</span><span class="n">remove</span><span class="o">(</span><span class="n">buffer</span><span class="o">.</span><span class="n">length</span> <span class="o">-</span> <span class="mi">1</span><span class="o">)</span>
    <span class="k">val</span> <span class="n">vector</span> <span class="k">=</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="n">buffer</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">toDouble</span><span class="o">).</span><span class="n">toArray</span><span class="o">)</span>
    <span class="o">(</span><span class="n">label</span><span class="o">,</span> <span class="n">vector</span><span class="o">)</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="n">labelsAndData</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">cache</span><span class="o">()</span>

<span class="k">val</span> <span class="n">kmeans</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">KMeans</span><span class="o">()</span>
<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">run</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">clusterCenters</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>
</code></pre></div>
<p>위 코드의 수행 결과로 다음과 같이 두 개의 클러스터의 중심 벡터가 출력될 것이다. 그것은 K-means Clustering을 통해 \(k=2\)로 데이터가 맞춰졌다는 것이다.</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">[48.34019491959669,1834.6215497618625,826.2031900016945,5.7161172049003456E-6,6.487793027561892E-4,7.961734678254053E-6,0.012437658596734055,3.205108575604837E-5,0.14352904910348827,0.00808830584493399,6.818511237273984E-5,3.6746467745787934E-5,0.012934960793560386,0.0011887482315762398,7.430952366370449E-5,0.0010211435092468404,0.0,4.082940860643104E-7,8.351655530445469E-4,334.9735084506668,295.26714620807076,0.17797031701994342,0.1780369894027253,0.05766489875327374,0.05772990937912739,0.7898841322630883,0.021179610609908736,0.02826081009629284,232.98107822302248,189.21428335201279,0.7537133898006421,0.030710978823798966,0.6050519309248854,0.006464107887636004,0.1780911843182601,0.17788589813474293,0.05792761150001131,0.05765922142400886]

[10999.0,0.0,1.309937401E9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,0.0,1.0,1.0,1.0,0.0,0.0,255.0,1.0,0.0,0.65,1.0,0.0,0.0,0.0,1.0,1.0]
</code></pre></div>
<p>하지만 앞서 데이터를 살펴보았던 것과 마찬가지로 총 23개의 레이블이 존재하는데, 단순히 두 개의 클러스터로 구분하는 것은 적절치 않다는 것을 직관적으로 알 수 있다. 때문에 이미 알고 있는 레이블 정보를 이용하여 클러스터링 결과가 실제 데이터와 어떤 차이를 보이는지 확인 해 보는것은 많은 도움이 된다. 다음 코드를 이용하면 각 클러스터별로 어떤 형태의 공격에 대한 레이블이 포함되었는지 확인할 수 있다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">clusterLabelCount</span> <span class="k">=</span> <span class="n">labelsAndData</span><span class="o">.</span><span class="n">map</span> <span class="o">{</span> <span class="k">case</span> <span class="o">(</span><span class="n">label</span><span class="o">,</span> <span class="n">datum</span><span class="o">)</span> <span class="k">=&gt;</span>
    <span class="k">val</span> <span class="n">cluster</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="o">(</span><span class="n">datum</span><span class="o">)</span>
    <span class="o">(</span><span class="n">cluster</span><span class="o">,</span> <span class="n">label</span><span class="o">)</span>
<span class="o">}.</span><span class="n">countByValue</span>

<span class="n">clusterLabelCount</span><span class="o">.</span><span class="n">toSeq</span><span class="o">.</span><span class="n">sorted</span><span class="o">.</span><span class="n">foreach</span> <span class="o">{</span>
    <span class="k">case</span> <span class="o">((</span><span class="n">cluster</span><span class="o">,</span> <span class="n">label</span><span class="o">),</span> <span class="n">count</span><span class="o">)</span> <span class="k">=&gt;</span>
    <span class="n">println</span><span class="o">(</span><span class="n">f</span><span class="s">&quot;$cluster%1s$label%18s$count%8s&quot;</span><span class="o">)</span>
<span class="o">}</span>
</code></pre></div>
<p>그 결과는 다음과 같다.</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">0             back.    2203
0  buffer_overflow.      30
0        ftp_write.       8
0     guess_passwd.      53
0             imap.      12
0          ipsweep.   12481
0             land.      21
0       loadmodule.       9
0         multihop.       7
0          neptune. 1072017
0             nmap.    2316
0           normal.  972781
0             perl.       3
0              phf.       4
0              pod.     264
0        portsweep.   10412
0          rootkit.      10
0            satan.   15892
0            smurf. 2807886
0              spy.       2
0         teardrop.     979
0      warezclient.    1020
0      warezmaster.      20
1        portsweep.       1
</code></pre></div>
<p>위 결과는 <strong>portsweep</strong> 공격에 대한 데이터를 제외한 모든 데이터들이 <strong>0번 클러스터</strong>에 할당되어 있음을 알 수 있다.</p>

<p><br>
<br></p>

<h2>Choosing K</h2>

<p>앞선 결과를 통해 단순히 두개의 클러스터는 부족하다는 것을 알 수 있다. 그렇다면 몇 개의 클러스터가 이 데이터셋에 적절할것인가? 이 데이터에 존재하는 레이블의 종류가 23개 이므로 \(k\)는 최소 23과 비슷하거나 큰 것이 결과가 좋을 것이다. 일반적으로 \(k\)를 결정할 때는 많은 값들이 고려된다. 근데, 어떤 것이 과연 &quot;좋은&quot; \(k\)일까?</p>

<p>클러스터링이 잘 되었다는 것은 각 데이터와 그 데이터가 속하는 클러스터의 중심과 거리가 가까운 것을 이야기한다. 그래서 그것을 계산하기 위해 Eculidean distance를 계산하는 함수를 정의하고, 그 함수를 이용해 각 데이터가 가장 가까운 클러스터의 중심과 얼마만큼 떨어져 있는지 계산할 것이다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">def</span> <span class="n">distance</span><span class="o">(</span><span class="n">a</span><span class="k">:</span> <span class="kt">Vector</span><span class="o">,</span> <span class="n">b</span><span class="k">:</span> <span class="kt">Vector</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span>
    <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="o">(</span><span class="n">a</span><span class="o">.</span><span class="n">toArray</span><span class="o">.</span><span class="n">zip</span><span class="o">(</span><span class="n">b</span><span class="o">.</span><span class="n">toArray</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="n">p</span> <span class="k">=&gt;</span> <span class="n">math</span><span class="o">.</span><span class="n">pow</span><span class="o">(</span><span class="n">p</span><span class="o">.</span><span class="n">_1</span> <span class="o">-</span> <span class="n">p</span><span class="o">.</span><span class="n">_2</span><span class="o">,</span> <span class="mi">2</span><span class="o">)).</span><span class="n">sum</span><span class="o">)</span>
<span class="o">}</span>

<span class="k">def</span> <span class="n">distToCentroid</span><span class="o">(</span><span class="n">datum</span><span class="k">:</span> <span class="kt">Vector</span><span class="o">,</span> <span class="n">model</span><span class="k">:</span> <span class="kt">KMeansModel</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">cluster</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="o">(</span><span class="n">datum</span><span class="o">)</span>
    <span class="k">val</span> <span class="n">centroid</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">clusterCenters</span><span class="o">(</span><span class="n">cluster</span><span class="o">)</span>
    <span class="n">distance</span><span class="o">(</span><span class="n">centroid</span><span class="o">,</span> <span class="n">datum</span><span class="o">)</span>
<span class="o">}</span>
</code></pre></div>
<p>이 함수를 이용하여 클러스터의 갯수 \(k\)가 주어졌을 때, 각 데이터와 가장 가까운 클러스터 사이의 거리에 대한 평균값을 계산할 수 있다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.spark.rdd._</span>

<span class="k">def</span> <span class="n">clusteringScore</span><span class="o">(</span><span class="n">data</span><span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">Vector</span><span class="o">],</span> <span class="n">k</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">kmeans</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">KMeans</span><span class="o">()</span>
    <span class="n">kmeans</span><span class="o">.</span><span class="n">setK</span><span class="o">(</span><span class="n">k</span><span class="o">)</span>
    <span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">run</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
    <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">datum</span> <span class="k">=&gt;</span> <span class="n">distToCentroid</span><span class="o">(</span><span class="n">datum</span><span class="o">,</span> <span class="n">model</span><span class="o">)).</span><span class="n">mean</span><span class="o">()</span>
<span class="o">}</span>

<span class="o">(</span><span class="mi">5</span> <span class="n">to</span> <span class="mi">40</span> <span class="n">by</span> <span class="mi">5</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="n">k</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">k</span><span class="o">,</span> <span class="n">clusteringScore</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">k</span><span class="o">))).</span><span class="n">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>
</code></pre></div>
<p>다음과 같은 결과를 볼 수 있는데, 클러스터의 수가 늘어날수록 각 데이터와 클러스터의 중심점과의 거리 평균이 줄어드는 경향을 보인다는 것을 알 수 있다.</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">(5,1938.8583418059188)
(10,1661.2533261157496)
(15,1405.536523064836)
(20,1111.7423030526104)
(25,946.2578661660172)
(30,597.6141598314152)
(35,748.4808532423143)
(40,513.382773134806)
</code></pre></div>
<p>하지만, 이러한 결과는 너무 뻔한 것이다. 많은 클러스터 중심을 이용 할 수록 데이터들이 각 클러스터의 중심과 가까울 것은 명백하고, 만약 데이터의 수와 클러스터의 수를 동일하게 설정한다면 각 데이터가 하나의 클러스터가 될 것이므로 각 데이터와 클러스터의 중심 사이의 거리는 0일 것이다. 또한 이상하게도 클러스터 개수가 35개일 때의 거리의 평균이 클러스터 개수가 30개일 때보다도 높다. 이것은 반드시 \(k\)가 높을 때에도 적은 \(k\)로 좋은 클러스터링을 수행하는 것을 허용하기 때문이다. 이것은 K-means Clustering은 꼭 주어진 \(k\)만을 이용해서 클러스터링을 수행해야만 하는 것은 아님을 이야기한다. 이것은 반복 과정에서  좋긴 하지만 최적은 아닌 local minimum 등에서 클러스터링이 멈출 수 있음을 의미한다. 이러한 것은 좀 더 지능적인 K-means Clustering을 이용하여 좋은 initial centroid(초기 중심점)을 선택할 때에도 마찬가지로 존재하는 문제이다. 예를 들면 K-means++, K-means|| 과 같은 방법들은 여러 선택 알고리즘을 이용하여 다양하고, 분산된 중심점들을 선택하여 가장 기초적인 K-means Clustering 방식보다 좋은 결과를 이끌어낸다. 하지만 이러한 방법들도 마찬가지로 무작위(Random)적인 선택을 기반으로 하기 때문에 최적의 클러스터링을 보장하지는 않는다.</p>

<p>이 결과를 반복 횟수를 증가시킴으로써 성능을 증가시킬수 있다. <code>setRuns()</code>함수는 하나의 \(k\)마다 클러스터링을 수행하는 횟수를 설정하는 것이며, <code>setEpsilon()</code>함수는  각 반복마다  확인하는 클러스터의 중심의 이동한 차이에 대한 Threshold이다. Epsilon을 조절함으로써 각 클러스터링의 수행마다 얼마만큼의 반복이 수행될 지를 결정하는데 영향을 미친다. Epsilon을 큰 값으로 설정하면 클러스터 중심점의 변경에 민감하지 않을 것이고 작은 값으로 설정한다면 작은 클러스터 중심점의 변경에도 민감하게 반응할 것이다.(민감하다는 것은 적은 차이에도 새로운 반복을 수행한다는 것)</p>

<p>다음과 같이 해당 부분들을 변경시켜 수행할 수 있다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="n">kmeans</span><span class="o">.</span><span class="n">setRuns</span><span class="o">(</span><span class="mi">10</span><span class="o">)</span>
<span class="n">kmeans</span><span class="o">.</span><span class="n">setEpsilon</span><span class="o">(</span><span class="mf">1.0e-6</span><span class="o">)</span> <span class="c1">//Epsilon의 기본값은 1.0e-4</span>

<span class="o">(</span><span class="mi">30</span> <span class="n">to</span> <span class="mi">100</span> <span class="n">by</span> <span class="mi">10</span><span class="o">).</span><span class="n">par</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">k</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">k</span><span class="o">,</span> <span class="n">clusteringScore</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">k</span><span class="o">))).</span><span class="n">toList</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>
</code></pre></div>
<p>위 코드의 수행 결과로 이제는 평가 수치가 점점 감소하는 결과를 보인다.</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">(30,654.6479150668039)
(40,833.771092804366)
(50,408.29802592345465)
(60,298.43382866843206)
(70,256.6636429518882)
(80,163.15198293023954)
(90,135.78737972772348)
(100,118.73064012152163)
</code></pre></div>
<p>이 결과를 이용하여 최적의 \(k\)를 선택해야 하는데, <a href="https://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set#The_Elbow_Method">Elbow를 선택하는 방법</a>을 이용하면 \(k=50, k=80\) 혹은 가장 작은 \(k=100\) 등의 값이 적절해보인다.</p>

<p><br>
<br></p>

<h2>Visualization in R</h2>

<p>이 시점에서 데이터들이 어떤 형태로 구성되어 있는가 확인해보는 것은 많은 도움이 된다. 하지만  Spark에는 자체적인 시각화 도구를 갖고 있지 않기 때문에 다른 도구의 도움을 받아야 한다. 하지만 Spark에서 수행하는 결과들은 쉽게 HDFS로 저장될 수 있고, 그것은 쉽게 다른 통계 툴에서 사용할 수 있다. 이 챕터에서는 R을 이용하여 데이터를 시각화 해 볼 것이다.</p>

<p>R은 2차원 혹은 3차원의 데이터를 시각화 하는 반면 우리가 지금까지 사용해 온 데이터는 38차원이다. 때문에 이 데이터를 최대 3차원을 갖는 데이터로 줄여야(Project)할 필요성이 있다. 게다가 R에서는 많은 데이터를 처리하기에는 무리가 있다. 따라서 데이터의 수 역시 샘플링을 통해 줄여야 한다.</p>

<p>시작에 앞서 \(k=100\)을 이용해 모델을 생성하고, 각 데이터가 속하는 클러스터의 번호를 각 데이터에 매핑한다. 그리고 이것을 CSV 형태로 HDFS에 출력한다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">kmeans</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">KMeans</span><span class="o">()</span>
<span class="n">kmeans</span><span class="o">.</span><span class="n">setK</span><span class="o">(</span><span class="mi">100</span><span class="o">)</span>
<span class="n">kmeans</span><span class="o">.</span><span class="n">setRuns</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>
<span class="n">kmeans</span><span class="o">.</span><span class="n">setEpsilon</span><span class="o">(</span><span class="mf">1.0e-6</span><span class="o">)</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">run</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="k">val</span> <span class="n">sample</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">datum</span> <span class="k">=&gt;</span>
    <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="o">(</span><span class="n">datum</span><span class="o">)</span> <span class="o">+</span> <span class="s">&quot;,&quot;</span> <span class="o">+</span> <span class="n">datum</span><span class="o">.</span><span class="n">toArray</span><span class="o">.</span><span class="n">mkString</span><span class="o">(</span><span class="s">&quot;,&quot;</span><span class="o">)</span>
<span class="o">).</span><span class="n">sample</span><span class="o">(</span><span class="kc">false</span><span class="o">,</span> <span class="mf">0.05</span><span class="o">)</span>

<span class="n">sample</span><span class="o">.</span><span class="n">saveAsTextFile</span><span class="o">(</span><span class="s">&quot;/kdd/sample&quot;</span><span class="o">)</span>
</code></pre></div>
<p><code>sample</code> 함수는 전체 데이터에서 원하는 만큼의 데이터를 샘플링 할 수 있도록 해 준다. 이 예시에서는 전체 데이터 중 5%를 반복 없이 샘플링한다.</p>

<p>다음의 R 코드는 HDFS에서 CSV파일을 읽어서 활용하는 코드이다. 이 코드에서는 <code>rgl</code>이라는 패키지를 이용하여 데이터를 그래프에 나타낸다. 이 과정에서 38차원의 데이터 중 무작위로 세 개의 Unit Vector를 선택하여 그 값을 이용해 3차원 벡터를 생성하고, 그것을 그래프에 그린다. 이 과정은 간단한 과정의 Dimension Reduction(차원 감소)이다. 물론 이 과정보다 훨씬 정한 알고리즘들(ex: <a href="https://en.wikipedia.org/wiki/Principal_component_analysis">PCA</a>, <a href="https://en.wikipedia.org/wiki/Singular_value_decomposition">SVD</a>)이 존재하고, 이것을 Spark에서나 R에서 수행이 가능하지만 이것을 추가로 수행하는데에 추가적인 시간이 소요되고, 이 챕터의 내용을 벗어나는 것이어서 사용하지는 않는다.</p>

<p>(다음 코드를 수행하기 위해서는 <code>rgl</code>패키지를 설치할 수 있는 환경이 구성되어야 한다.)</p>
<div class="highlight"><pre><code class="language-r" data-lang="r">install.packages<span class="p">(</span><span class="s">&quot;rgl&quot;</span><span class="p">)</span> <span class="c1">#처음 한번만 수행하면 된다.</span>
<span class="kn">library</span><span class="p">(</span>rgl<span class="p">)</span>

<span class="c1">#HDFS로부터 CSV형태의 데이터 읽기</span>
clusters_data <span class="o">&lt;-</span> read.csv<span class="p">(</span><span class="kp">pipe</span><span class="p">(</span><span class="s">&quot;hdfs dfs -cat /kdd/sample/*&quot;</span><span class="p">))</span>
clusters <span class="o">&lt;-</span> clusters_data<span class="p">[</span><span class="m">1</span><span class="p">]</span>
data <span class="o">&lt;-</span> <span class="kp">data.matrix</span><span class="p">(</span>clusters_data<span class="p">[</span><span class="o">-</span><span class="kt">c</span><span class="p">(</span><span class="m">1</span><span class="p">)])</span>
<span class="kp">rm</span><span class="p">(</span>clusters_data<span class="p">)</span>

<span class="c1">#Random Unit Vector 생성</span>
random_projection <span class="o">&lt;-</span> <span class="kt">matrix</span><span class="p">(</span>data <span class="o">=</span> rnorm<span class="p">(</span><span class="m">3</span><span class="o">*</span><span class="kp">ncol</span><span class="p">(</span>data<span class="p">)),</span> ncol <span class="o">=</span> <span class="m">3</span><span class="p">)</span>
random_projection_norm <span class="o">&lt;-</span>
    random_projection <span class="o">/</span> <span class="kp">sqrt</span><span class="p">(</span><span class="kp">rowSums</span><span class="p">(</span>random_projection <span class="o">*</span> random_projection<span class="p">))</span>

projected_data <span class="o">&lt;-</span> <span class="kt">data.frame</span><span class="p">(</span>data <span class="o">%*%</span> random_projection_norm<span class="p">)</span>

num_clusters <span class="o">&lt;-</span> <span class="kp">nrow</span><span class="p">(</span><span class="kp">unique</span><span class="p">(</span>clusters<span class="p">))</span>
palette <span class="o">&lt;-</span> rainbow<span class="p">(</span>num_clusters<span class="p">)</span>
colors <span class="o">=</span> <span class="kp">sapply</span><span class="p">(</span>clusters<span class="p">,</span> <span class="kr">function</span><span class="p">(</span><span class="kt">c</span><span class="p">)</span> palette<span class="p">[</span><span class="kt">c</span><span class="p">])</span>
plot3d<span class="p">(</span>projected_data<span class="p">,</span> col <span class="o">=</span> colors<span class="p">,</span> size <span class="o">=</span> <span class="m">10</span><span class="p">)</span>
</code></pre></div>
<p>위 코드의 수행 결과로는 다음과 같은 형태의 3D 그래프가 출력된다.</p>

<p><img src="https://db.tt/NLkpVFIZ" alt="Random 3D Projection"></p>

<p>이 결과는 각 클러스터의 번호가 색깔로 구분된 데이터들의 좌표(위 그림에서는 하나의 클러스터가 대부분을 차지하는 것으로 나오지만 확대하면 다양한 클러스터의 색깔을 볼 수 있다.)로 표현된 것이다. 데이터를 어떻게 분석해야 할지 막막하지만, 데이터의 분포가 <code>&quot;L&quot;</code>자 형태인 것만은 분명하다. 그리고 그 L의 한 쪽은 길고, 한쪽은 짧다.</p>

<p>이것은 Feature중에 그 값의 범위가 다른 Feature에 비해 큰 것들이 존재한다는 것이다. 예를 들면 대부분의 Feature의 값은 0과 1 사이인 것에 비해 주고받은 Byte의 수에 대한 Feature는 그 범위가 매우 크다. 때문에 각 클러스터로부터의 거리를 계산하여 클러스터링의 성능을 평가할 때 주고받은 Byte 수에 대한 Feature가 영향령이 크다는 것이 된다. 따라서 앞서 계산한 Euclidean Distance에서는 다른 Feature들이 거의 무시되고 주고받은 Byte 수에 대한 것이 대부분이라는 것이다. 이것을 방지하기 위해 각 Feature 값을 Normalize 할 필요가 있다.</p>

<p><br>
<br></p>

<h2>Feature Normalization</h2>

<p>우리는 다음과 같은 식을 이용하여 각 Feature를 Normalize할 수 있다.</p>

<p>\(
{ normalized }_{ i }=\frac { { feature }_{ i }-{ \mu  }_{ i } }{ { \sigma  }_{ i } } 
\)</p>

<p>위 식은 각 Feature의 값에서 평균을 뺀 후에, 그것을 표준편차로 나누어 정규화 시키는 것이다. 사실 평균을 각 데이터에서 빼는 것은 클러스터링 과정에 아무 영향을 미치지 않는다. 모든 값을 같은 양만큼 같은 뱡향으로 움직이는 것이기 때문이다. 그렇지만, 일반적으로 사용하는 정규화 식을 그대로 이용하기 위하여 평균을 빼는 과정을 제외하지는 않았다.</p>

<p>표준값은 각 Feature별로 갯수, 합, 제곱합을 계산함으로써 구할 수 있다. 다음과 같은 코드를 이용해 각 Feature의 값을 Normalization할 수 있다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">dataAsArray</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">toArray</span><span class="o">)</span>
<span class="k">val</span> <span class="n">numCols</span> <span class="k">=</span> <span class="n">dataAsArray</span><span class="o">.</span><span class="n">first</span><span class="o">().</span><span class="n">length</span>
<span class="k">val</span> <span class="n">n</span> <span class="k">=</span> <span class="n">dataAsArray</span><span class="o">.</span><span class="n">count</span><span class="o">()</span>
<span class="k">val</span> <span class="n">sums</span> <span class="k">=</span> <span class="n">dataAsArray</span><span class="o">.</span><span class="n">reduce</span> <span class="o">{</span>
    <span class="o">(</span><span class="n">a</span><span class="o">,</span> <span class="n">b</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">zip</span><span class="o">(</span><span class="n">b</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="n">t</span> <span class="k">=&gt;</span> <span class="n">t</span><span class="o">.</span><span class="n">_1</span> <span class="o">+</span> <span class="n">t</span><span class="o">.</span><span class="n">_2</span><span class="o">)</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">sumSquares</span> <span class="k">=</span> <span class="n">dataAsArray</span><span class="o">.</span><span class="n">aggregate</span><span class="o">(</span>
    <span class="k">new</span> <span class="nc">Array</span><span class="o">[</span><span class="kt">Double</span><span class="o">](</span><span class="n">numCols</span><span class="o">)</span>
    <span class="o">)(</span>
        <span class="o">(</span><span class="n">a</span><span class="o">,</span> <span class="n">b</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">zip</span><span class="o">(</span><span class="n">b</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="n">t</span> <span class="k">=&gt;</span> <span class="n">t</span><span class="o">.</span><span class="n">_1</span> <span class="o">+</span> <span class="n">t</span><span class="o">.</span><span class="n">_2</span> <span class="o">*</span> <span class="n">t</span><span class="o">.</span><span class="n">_2</span><span class="o">),</span>
        <span class="o">(</span><span class="n">a</span><span class="o">,</span> <span class="n">b</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">zip</span><span class="o">(</span><span class="n">b</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="n">t</span> <span class="k">=&gt;</span> <span class="n">t</span><span class="o">.</span><span class="n">_1</span> <span class="o">+</span> <span class="n">t</span><span class="o">.</span><span class="n">_2</span><span class="o">)</span>
    <span class="o">)</span>   

<span class="k">val</span> <span class="n">stdevs</span> <span class="k">=</span> <span class="n">sumSquares</span><span class="o">.</span><span class="n">zip</span><span class="o">(</span><span class="n">sums</span><span class="o">).</span><span class="n">map</span> <span class="o">{</span>
    <span class="k">case</span> <span class="o">(</span><span class="n">sumSq</span><span class="o">,</span> <span class="n">sum</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="o">(</span><span class="n">n</span> <span class="o">*</span> <span class="n">sumSq</span> <span class="o">-</span> <span class="n">sum</span> <span class="o">*</span> <span class="n">sum</span><span class="o">)</span> <span class="o">/</span> <span class="n">n</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">means</span> <span class="k">=</span> <span class="n">sums</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span> <span class="o">/</span> <span class="n">n</span><span class="o">)</span>
</code></pre></div>
<p>위 코드에서 <code>aggregate</code> 함수에 대해 어려움을 느낄 수 있는데, Python API를 이용해 설명하고 있지만, <a href="http://atlantageek.com/2015/05/30/python-aggregate-rdd/">이 블로그</a>에서 잘 설명을 하고 있다. 간단히 얘기하면 aggregate 함수의 파라미터로는 초기값(0 Value)이 사용되고, 첫번째 람다함수는 결과 Object를 생성하는 과정에서 어떻게 그 결과를 만들어 낼 것인지(위 코드의 예시에서는 제곱의 합을 구하는 과정)에 대한 것이고, 두번째 람다함수는 여러개의 결과 Object를 Combine할 때 어떻게 할 것인지에 대한 함수이다. 결론적으로 위 과정에서 제곱의 합을 구하는 과정은 각 Partition에서는 zip 된 두 개의 데이터 중 Feature별로 다음 것을 제곱하여 이전의 값에 더해나가고, 그 Partition을 합할 때는 덧셈을 수행함으로써 모든 데이터의 Feature별 제곱의 합을 구한다.</p>

<p>앞서 구한 값들을 이용해 데이터를 정규화하고, 그 데이터를 이용해 K-means 클러스터링을 수행시킨 뒤 다시 Euclidean Distance를 계산한다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">def</span> <span class="n">normalize</span><span class="o">(</span><span class="n">datum</span><span class="k">:</span> <span class="kt">Vector</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">normalizedArray</span> <span class="k">=</span> <span class="o">(</span><span class="n">datum</span><span class="o">.</span><span class="n">toArray</span><span class="o">,</span> <span class="n">means</span><span class="o">,</span> <span class="n">stdevs</span><span class="o">).</span><span class="n">zipped</span><span class="o">.</span><span class="n">map</span> <span class="o">{</span>
    <span class="o">(</span><span class="n">value</span><span class="o">,</span> <span class="n">mean</span><span class="o">,</span> <span class="n">stdev</span><span class="o">)</span> <span class="k">=&gt;</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">stdev</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="o">)</span> <span class="o">(</span><span class="n">value</span> <span class="o">-</span> <span class="n">mean</span><span class="o">)</span> <span class="k">else</span> <span class="o">(</span><span class="n">value</span> <span class="o">-</span> <span class="n">mean</span><span class="o">)</span> <span class="o">/</span> <span class="n">stdev</span>
    <span class="o">}</span>
    <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="n">normalizedArray</span><span class="o">)</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">normalizedData</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">normalize</span><span class="o">).</span><span class="n">cache</span><span class="o">()</span>

<span class="o">(</span><span class="mi">60</span> <span class="n">to</span> <span class="mi">120</span> <span class="n">by</span> <span class="mi">10</span><span class="o">).</span><span class="n">par</span><span class="o">.</span><span class="n">map</span> <span class="o">{</span>
    <span class="n">k</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">k</span><span class="o">,</span> <span class="n">clusteringScore</span><span class="o">(</span><span class="n">normalizedData</span><span class="o">,</span> <span class="n">k</span><span class="o">))</span>
<span class="o">}.</span><span class="n">toList</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>
</code></pre></div>
<p>위 코드의 수행 결과는 다음과 같다.</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">(60,0.35788542308188337)
(70,0.33739539223932735)
(80,0.35734816618118775)
(90,0.3333896914476046)
(100,0.2866857023435722)
(110,0.27457555082113716)
(120,0.25987997589819595)
</code></pre></div>
<p>위 결과를 통해 elbow인 \(k=100\)은 괜찮은 선택이었음을 알 수 있다. 앞서 정규화한 데이터를 다시 R을 통해 시각화하여 어떤 차이가 있는지 확인해 볼 수 있다. 다음 코드를 이용해 Normalize된 데이터를 이용하여 K-means Clustering을 수행시키고, 그것을 HDFS에 저장한다. (확실한 결과를 위해 setRun()을 통해 옵션을 정하였다.)</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">kmeans</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">KMeans</span><span class="o">()</span>
<span class="n">kmeans</span><span class="o">.</span><span class="n">setK</span><span class="o">(</span><span class="mi">100</span><span class="o">)</span>
<span class="n">kmeans</span><span class="o">.</span><span class="n">setRuns</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>
<span class="n">kmeans</span><span class="o">.</span><span class="n">setEpsilon</span><span class="o">(</span><span class="mf">1.0e-6</span><span class="o">)</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">run</span><span class="o">(</span><span class="n">normalizedData</span><span class="o">)</span>

<span class="k">val</span> <span class="n">sample</span> <span class="k">=</span> <span class="n">normalizedData</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">datum</span> <span class="k">=&gt;</span>
    <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="o">(</span><span class="n">datum</span><span class="o">)</span> <span class="o">+</span> <span class="s">&quot;,&quot;</span> <span class="o">+</span> <span class="n">datum</span><span class="o">.</span><span class="n">toArray</span><span class="o">.</span><span class="n">mkString</span><span class="o">(</span><span class="s">&quot;,&quot;</span><span class="o">)</span>
<span class="o">).</span><span class="n">sample</span><span class="o">(</span><span class="kc">false</span><span class="o">,</span> <span class="mf">0.05</span><span class="o">)</span>

<span class="n">sample</span><span class="o">.</span><span class="n">saveAsTextFile</span><span class="o">(</span><span class="s">&quot;/kdd/normalized_sample&quot;</span><span class="o">)</span>
</code></pre></div>
<p>그리고 R에서 다시 그래프를 생성하였다.</p>
<div class="highlight"><pre><code class="language-r" data-lang="r"><span class="kn">library</span><span class="p">(</span>rgl<span class="p">)</span>

<span class="c1">#HDFS로부터 CSV형태의 데이터 읽기</span>
clusters_data <span class="o">&lt;-</span> read.csv<span class="p">(</span><span class="kp">pipe</span><span class="p">(</span><span class="s">&quot;hdfs dfs -cat /kdd/normalized_sample/*&quot;</span><span class="p">))</span>
clusters <span class="o">&lt;-</span> clusters_data<span class="p">[</span><span class="m">1</span><span class="p">]</span>
data <span class="o">&lt;-</span> <span class="kp">data.matrix</span><span class="p">(</span>clusters_data<span class="p">[</span><span class="o">-</span><span class="kt">c</span><span class="p">(</span><span class="m">1</span><span class="p">)])</span>
<span class="kp">rm</span><span class="p">(</span>clusters_data<span class="p">)</span>

<span class="c1">#Random Unit Vector 생성</span>
random_projection <span class="o">&lt;-</span> <span class="kt">matrix</span><span class="p">(</span>data <span class="o">=</span> rnorm<span class="p">(</span><span class="m">3</span><span class="o">*</span><span class="kp">ncol</span><span class="p">(</span>data<span class="p">)),</span> ncol <span class="o">=</span> <span class="m">3</span><span class="p">)</span>
random_projection_norm <span class="o">&lt;-</span>
    random_projection <span class="o">/</span> <span class="kp">sqrt</span><span class="p">(</span><span class="kp">rowSums</span><span class="p">(</span>random_projection <span class="o">*</span> random_projection<span class="p">))</span>

projected_data <span class="o">&lt;-</span> <span class="kt">data.frame</span><span class="p">(</span>data <span class="o">%*%</span> random_projection_norm<span class="p">)</span>

num_clusters <span class="o">&lt;-</span> <span class="kp">nrow</span><span class="p">(</span><span class="kp">unique</span><span class="p">(</span>clusters<span class="p">))</span>
palette <span class="o">&lt;-</span> rainbow<span class="p">(</span>num_clusters<span class="p">)</span>
colors <span class="o">=</span> <span class="kp">sapply</span><span class="p">(</span>clusters<span class="p">,</span> <span class="kr">function</span><span class="p">(</span><span class="kt">c</span><span class="p">)</span> palette<span class="p">[</span><span class="kt">c</span><span class="p">])</span>
plot3d<span class="p">(</span>projected_data<span class="p">,</span> col <span class="o">=</span> colors<span class="p">,</span> size <span class="o">=</span> <span class="m">10</span><span class="p">)</span>
</code></pre></div>
<p>생성된 그래프는 다음과 같으며, 정규화 이전의 데이터에 비해 좀 더 풍부한(richer) 구조를 띄고 있음을 알 수 있다.</p>

<p><img src="https://db.tt/jZ8WlR1x" alt="Random 3D Projection of Normalized Data"></p>

<p><br>
<br></p>

<h2>Using Labels with Entropy</h2>

<p>지금까지 우리는 클러스터링의 성능을 판단하기 위해, 그리고 그것을 이용해 적절한 \(k\)를 찾는 과정에서 매우 간단한 것을 이용하였다. 여기에 지난 Chapter에서 사용한 방식을 적용할 수 있다. <code>Gini inputiry</code>와 <code>Entropy</code>방식이 그것인데, 여기서는 Entropy 방식을 이용하여 설명할 것이다.</p>

<p>좋은 클러스터링이라는 것은 각각의 클러스터가 하나의 label에 대한 데이터만 가지고 있고, 결과적으로 낮은 Entropy를 갖는 것을 의미한다. 때문에 여기에 가중평균을 적용하여 클러스터링의 스코어를 계산할 수 있다.*</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">entropy</span><span class="o">(</span><span class="n">counts</span><span class="k">:</span> <span class="kt">Iterable</span><span class="o">[</span><span class="kt">Int</span><span class="o">])</span> <span class="k">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">values</span> <span class="k">=</span> <span class="n">counts</span><span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="k">_</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="o">)</span>
    <span class="k">val</span> <span class="n">n</span><span class="k">:</span> <span class="kt">Double</span> <span class="o">=</span> <span class="n">values</span><span class="o">.</span><span class="n">sum</span>
    <span class="n">values</span><span class="o">.</span><span class="n">map</span> <span class="o">{</span> <span class="n">v</span> <span class="k">=&gt;</span>
        <span class="k">val</span> <span class="n">p</span> <span class="k">=</span> <span class="n">v</span> <span class="o">/</span> <span class="n">n</span>
        <span class="o">-</span><span class="n">p</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="o">(</span><span class="n">p</span><span class="o">)</span>
    <span class="o">}.</span><span class="n">sum</span>
<span class="o">}</span>

<span class="k">def</span> <span class="n">clusteringScore</span><span class="o">(</span><span class="n">normLabelAndData</span><span class="k">:</span> <span class="kt">RDD</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Vector</span><span class="o">)],</span> <span class="n">k</span><span class="k">:</span><span class="kt">Int</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">kmeans</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">KMeans</span><span class="o">()</span>
    <span class="n">kmeans</span><span class="o">.</span><span class="n">setK</span><span class="o">(</span><span class="n">k</span><span class="o">)</span>
    <span class="n">kmeans</span><span class="o">.</span><span class="n">setRuns</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>
    <span class="n">kmeans</span><span class="o">.</span><span class="n">setEpsilon</span><span class="o">(</span><span class="mf">1.0e-6</span><span class="o">)</span>

    <span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">run</span><span class="o">(</span><span class="n">normLabelAndData</span><span class="o">.</span><span class="n">values</span><span class="o">)</span>

    <span class="k">val</span> <span class="n">labelsAndClusters</span> <span class="k">=</span> <span class="n">normLabelAndData</span><span class="o">.</span><span class="n">mapValues</span><span class="o">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="o">)</span>
    <span class="k">val</span> <span class="n">clustersAndLabels</span> <span class="k">=</span> <span class="n">labelsAndClusters</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">swap</span><span class="o">)</span>
    <span class="k">val</span> <span class="n">labelsInCluster</span> <span class="k">=</span> <span class="n">clustersAndLabels</span><span class="o">.</span><span class="n">groupByKey</span><span class="o">().</span><span class="n">values</span>
    <span class="k">val</span> <span class="n">labelCounts</span> <span class="k">=</span> <span class="n">labelsInCluster</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="n">l</span> <span class="k">=&gt;</span> <span class="n">l</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">_2</span><span class="o">.</span><span class="n">size</span><span class="o">))</span>
    <span class="k">val</span> <span class="n">n</span> <span class="k">=</span> <span class="n">normLabelAndData</span><span class="o">.</span><span class="n">count</span><span class="o">()</span>

    <span class="n">labelCounts</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">m</span> <span class="k">=&gt;</span> <span class="n">m</span><span class="o">.</span><span class="n">sum</span> <span class="o">*</span> <span class="n">entropy</span><span class="o">(</span><span class="n">m</span><span class="o">)).</span><span class="n">sum</span> <span class="o">/</span> <span class="n">n</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">normalizedLabelsAndData</span> <span class="k">=</span> <span class="n">labelsAndData</span><span class="o">.</span><span class="n">mapValues</span><span class="o">(</span><span class="n">normalize</span><span class="o">).</span><span class="n">cache</span><span class="o">()</span>

<span class="o">(</span><span class="mi">80</span> <span class="n">to</span> <span class="mi">160</span> <span class="n">by</span> <span class="mi">10</span><span class="o">).</span><span class="n">par</span><span class="o">.</span><span class="n">map</span> <span class="o">{</span>
    <span class="n">k</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">k</span><span class="o">,</span> <span class="n">clusteringScore</span><span class="o">(</span><span class="n">normalizedLabelsAndData</span><span class="o">,</span> <span class="n">k</span><span class="o">))</span>
<span class="o">}.</span><span class="n">toList</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>

<span class="n">normalizedLabelsAndData</span><span class="o">.</span><span class="n">unpersist</span><span class="o">()</span>
</code></pre></div>
<p><br>
위 코드의 수행 결과는 다음과 같으며, \(k=150\)일때 가장 좋은 성능을 나타냄을 알 수 있다.**
<br></p>
<div class="highlight"><pre><code class="language-text" data-lang="text">(80,0.01633056783505308)
(90,0.014086821003939093)
(100,0.013287591809429072)
(110,0.011314751300005676)
(120,0.012290307370115603)
(130,0.00949651182021723)
(140,0.008943810114864363)
(150,0.007499306029722229)
(160,0.008704684195176402)
(170,0.008691369298104417)
(180,0.008559061207118177)
</code></pre></div>
<h2>Categorical Variables</h2>

<p>지금까지 수행한 클러스터링은 세 개의 Categorical Feature를 제외하고 수행하였다. 왜냐면, MLlib에서의 K-means Clustering은 숫자 형태의 데이터가 아닌 것에 대해서는 클러스터링을 수행할 수 없기 때문이다. Categorical Feature를 클러스터링에 포함시키기 위하여 지난 챕터에서 사용한 데이터베이스가 활용하고 있는 방법인, Feature의 값의 범위를 하나의 비트로 표현하는 방법을 이용할 것이다.</p>

<p>예를 들면 두 번째 Feature의 경우에는 어떤 형태의 프로토콜이 사용되었는지에 대한 값이다. 이것은 <strong>tcp, udp, icmp</strong>의 값을 갖는데, 이 것을 바이너리의 값을 갖는 세 개의 Feature, 예를들어 <strong>is<em>tcp, is</em>udp, is_icmp</strong>와 같은 Feature로 나누어 저장하는 것이다. 그리고 어떤 데이터가 원래 데이터에서 <strong>udp</strong> 프로토콜을 사용한 데이터였다면, <strong>0.0, 1.0, 0.0</strong>으로 표현하는 것이다.</p>

<p>이 방법을 데이터에 적용하면 다시 Normalize와, 클러스터링을 수행시켜야 한다. 책에는 이 과정에 대한 코드가 있지 않지만, <a href="https://github.com/sryza/aas">Github Repository</a>에 해당 코드가 있어 사용하였다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.spark.mllib.clustering._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.mllib.linalg._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.rdd._</span>

<span class="k">def</span> <span class="n">buildCategoricalAndLabelFunction</span><span class="o">(</span><span class="n">rawData</span><span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span><span class="k">:</span> <span class="o">(</span><span class="kt">String</span> <span class="o">=&gt;</span> <span class="o">(</span><span class="kt">String</span><span class="o">,</span><span class="kt">Vector</span><span class="o">))</span> <span class="k">=</span> <span class="o">{</span>
  <span class="k">val</span> <span class="n">splitData</span> <span class="k">=</span> <span class="n">rawData</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="sc">&#39;,&#39;</span><span class="o">))</span>
  <span class="k">val</span> <span class="n">protocols</span> <span class="k">=</span> <span class="n">splitData</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">(</span><span class="mi">1</span><span class="o">)).</span><span class="n">distinct</span><span class="o">().</span><span class="n">collect</span><span class="o">().</span><span class="n">zipWithIndex</span><span class="o">.</span><span class="n">toMap</span>
  <span class="k">val</span> <span class="n">services</span> <span class="k">=</span> <span class="n">splitData</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">(</span><span class="mi">2</span><span class="o">)).</span><span class="n">distinct</span><span class="o">().</span><span class="n">collect</span><span class="o">().</span><span class="n">zipWithIndex</span><span class="o">.</span><span class="n">toMap</span>
  <span class="k">val</span> <span class="n">tcpStates</span> <span class="k">=</span> <span class="n">splitData</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">(</span><span class="mi">3</span><span class="o">)).</span><span class="n">distinct</span><span class="o">().</span><span class="n">collect</span><span class="o">().</span><span class="n">zipWithIndex</span><span class="o">.</span><span class="n">toMap</span>
  <span class="o">(</span><span class="n">line</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">buffer</span> <span class="k">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="sc">&#39;,&#39;</span><span class="o">).</span><span class="n">toBuffer</span>
    <span class="k">val</span> <span class="n">protocol</span> <span class="k">=</span> <span class="n">buffer</span><span class="o">.</span><span class="n">remove</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
    <span class="k">val</span> <span class="n">service</span> <span class="k">=</span> <span class="n">buffer</span><span class="o">.</span><span class="n">remove</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
    <span class="k">val</span> <span class="n">tcpState</span> <span class="k">=</span> <span class="n">buffer</span><span class="o">.</span><span class="n">remove</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
    <span class="k">val</span> <span class="n">label</span> <span class="k">=</span> <span class="n">buffer</span><span class="o">.</span><span class="n">remove</span><span class="o">(</span><span class="n">buffer</span><span class="o">.</span><span class="n">length</span> <span class="o">-</span> <span class="mi">1</span><span class="o">)</span>
    <span class="k">val</span> <span class="n">vector</span> <span class="k">=</span> <span class="n">buffer</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">toDouble</span><span class="o">)</span>

    <span class="k">val</span> <span class="n">newProtocolFeatures</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Array</span><span class="o">[</span><span class="kt">Double</span><span class="o">](</span><span class="n">protocols</span><span class="o">.</span><span class="n">size</span><span class="o">)</span>
    <span class="n">newProtocolFeatures</span><span class="o">(</span><span class="n">protocols</span><span class="o">(</span><span class="n">protocol</span><span class="o">))</span> <span class="k">=</span> <span class="mf">1.0</span>
    <span class="k">val</span> <span class="n">newServiceFeatures</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Array</span><span class="o">[</span><span class="kt">Double</span><span class="o">](</span><span class="n">services</span><span class="o">.</span><span class="n">size</span><span class="o">)</span>
    <span class="n">newServiceFeatures</span><span class="o">(</span><span class="n">services</span><span class="o">(</span><span class="n">service</span><span class="o">))</span> <span class="k">=</span> <span class="mf">1.0</span>
    <span class="k">val</span> <span class="n">newTcpStateFeatures</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Array</span><span class="o">[</span><span class="kt">Double</span><span class="o">](</span><span class="n">tcpStates</span><span class="o">.</span><span class="n">size</span><span class="o">)</span>
    <span class="n">newTcpStateFeatures</span><span class="o">(</span><span class="n">tcpStates</span><span class="o">(</span><span class="n">tcpState</span><span class="o">))</span> <span class="k">=</span> <span class="mf">1.0</span>

    <span class="n">vector</span><span class="o">.</span><span class="n">insertAll</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="n">newTcpStateFeatures</span><span class="o">)</span>
    <span class="n">vector</span><span class="o">.</span><span class="n">insertAll</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="n">newServiceFeatures</span><span class="o">)</span>
    <span class="n">vector</span><span class="o">.</span><span class="n">insertAll</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="n">newProtocolFeatures</span><span class="o">)</span>

    <span class="o">(</span><span class="n">label</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="n">vector</span><span class="o">.</span><span class="n">toArray</span><span class="o">))</span>
  <span class="o">}</span>
<span class="o">}</span>

<span class="k">def</span> <span class="n">buildNormalizationFunction</span><span class="o">(</span><span class="n">data</span><span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">Vector</span><span class="o">])</span><span class="k">:</span> <span class="o">(</span><span class="kt">Vector</span> <span class="o">=&gt;</span> <span class="kt">Vector</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span>
  <span class="k">val</span> <span class="n">dataAsArray</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">toArray</span><span class="o">)</span>
  <span class="k">val</span> <span class="n">numCols</span> <span class="k">=</span> <span class="n">dataAsArray</span><span class="o">.</span><span class="n">first</span><span class="o">().</span><span class="n">length</span>
  <span class="k">val</span> <span class="n">n</span> <span class="k">=</span> <span class="n">dataAsArray</span><span class="o">.</span><span class="n">count</span><span class="o">()</span>
  <span class="k">val</span> <span class="n">sums</span> <span class="k">=</span> <span class="n">dataAsArray</span><span class="o">.</span><span class="n">reduce</span><span class="o">(</span>
    <span class="o">(</span><span class="n">a</span><span class="o">,</span> <span class="n">b</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">zip</span><span class="o">(</span><span class="n">b</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="n">t</span> <span class="k">=&gt;</span> <span class="n">t</span><span class="o">.</span><span class="n">_1</span> <span class="o">+</span> <span class="n">t</span><span class="o">.</span><span class="n">_2</span><span class="o">))</span>
  <span class="k">val</span> <span class="n">sumSquares</span> <span class="k">=</span> <span class="n">dataAsArray</span><span class="o">.</span><span class="n">aggregate</span><span class="o">(</span>
    <span class="k">new</span> <span class="nc">Array</span><span class="o">[</span><span class="kt">Double</span><span class="o">](</span><span class="n">numCols</span><span class="o">)</span>
    <span class="o">)(</span>
    <span class="o">(</span><span class="n">a</span><span class="o">,</span> <span class="n">b</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">zip</span><span class="o">(</span><span class="n">b</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="n">t</span> <span class="k">=&gt;</span> <span class="n">t</span><span class="o">.</span><span class="n">_1</span> <span class="o">+</span> <span class="n">t</span><span class="o">.</span><span class="n">_2</span> <span class="o">*</span> <span class="n">t</span><span class="o">.</span><span class="n">_2</span><span class="o">),</span>
    <span class="o">(</span><span class="n">a</span><span class="o">,</span> <span class="n">b</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">zip</span><span class="o">(</span><span class="n">b</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="n">t</span> <span class="k">=&gt;</span> <span class="n">t</span><span class="o">.</span><span class="n">_1</span> <span class="o">+</span> <span class="n">t</span><span class="o">.</span><span class="n">_2</span><span class="o">)</span>
    <span class="o">)</span>
    <span class="k">val</span> <span class="n">stdevs</span> <span class="k">=</span> <span class="n">sumSquares</span><span class="o">.</span><span class="n">zip</span><span class="o">(</span><span class="n">sums</span><span class="o">).</span><span class="n">map</span> <span class="o">{</span>
      <span class="k">case</span> <span class="o">(</span><span class="n">sumSq</span><span class="o">,</span> <span class="n">sum</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="o">(</span><span class="n">n</span> <span class="o">*</span> <span class="n">sumSq</span> <span class="o">-</span> <span class="n">sum</span> <span class="o">*</span> <span class="n">sum</span><span class="o">)</span> <span class="o">/</span> <span class="n">n</span>
    <span class="o">}</span>
    <span class="k">val</span> <span class="n">means</span> <span class="k">=</span> <span class="n">sums</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span> <span class="o">/</span> <span class="n">n</span><span class="o">)</span>

    <span class="o">(</span><span class="n">datum</span><span class="k">:</span> <span class="kt">Vector</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="o">{</span>
      <span class="k">val</span> <span class="n">normalizedArray</span> <span class="k">=</span> <span class="o">(</span><span class="n">datum</span><span class="o">.</span><span class="n">toArray</span><span class="o">,</span> <span class="n">means</span><span class="o">,</span> <span class="n">stdevs</span><span class="o">).</span><span class="n">zipped</span><span class="o">.</span><span class="n">map</span><span class="o">(</span>
        <span class="o">(</span><span class="n">value</span><span class="o">,</span> <span class="n">mean</span><span class="o">,</span> <span class="n">stdev</span><span class="o">)</span> <span class="k">=&gt;</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">stdev</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="o">)</span>  <span class="o">(</span><span class="n">value</span> <span class="o">-</span> <span class="n">mean</span><span class="o">)</span> <span class="k">else</span>  <span class="o">(</span><span class="n">value</span> <span class="o">-</span> <span class="n">mean</span><span class="o">)</span> <span class="o">/</span> <span class="n">stdev</span>
        <span class="o">)</span>
      <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="n">normalizedArray</span><span class="o">)</span>
    <span class="o">}</span>
<span class="o">}</span>

<span class="k">def</span> <span class="n">entropy</span><span class="o">(</span><span class="n">counts</span><span class="k">:</span> <span class="kt">Iterable</span><span class="o">[</span><span class="kt">Int</span><span class="o">])</span> <span class="k">=</span> <span class="o">{</span>
  <span class="k">val</span> <span class="n">values</span> <span class="k">=</span> <span class="n">counts</span><span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="k">_</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="o">)</span>
  <span class="k">val</span> <span class="n">n</span><span class="k">:</span> <span class="kt">Double</span> <span class="o">=</span> <span class="n">values</span><span class="o">.</span><span class="n">sum</span>
  <span class="n">values</span><span class="o">.</span><span class="n">map</span> <span class="o">{</span> <span class="n">v</span> <span class="k">=&gt;</span>
    <span class="k">val</span> <span class="n">p</span> <span class="k">=</span> <span class="n">v</span> <span class="o">/</span> <span class="n">n</span>
    <span class="o">-</span><span class="n">p</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="o">(</span><span class="n">p</span><span class="o">)</span>
    <span class="o">}.</span><span class="n">sum</span>
<span class="o">}</span>

<span class="k">def</span> <span class="n">buildNormalizationFunction</span><span class="o">(</span><span class="n">data</span><span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">Vector</span><span class="o">])</span><span class="k">:</span> <span class="o">(</span><span class="kt">Vector</span> <span class="o">=&gt;</span> <span class="kt">Vector</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span>
  <span class="k">val</span> <span class="n">dataAsArray</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">toArray</span><span class="o">)</span>
  <span class="k">val</span> <span class="n">numCols</span> <span class="k">=</span> <span class="n">dataAsArray</span><span class="o">.</span><span class="n">first</span><span class="o">().</span><span class="n">length</span>
  <span class="k">val</span> <span class="n">n</span> <span class="k">=</span> <span class="n">dataAsArray</span><span class="o">.</span><span class="n">count</span><span class="o">()</span>
  <span class="k">val</span> <span class="n">sums</span> <span class="k">=</span> <span class="n">dataAsArray</span><span class="o">.</span><span class="n">reduce</span><span class="o">(</span>
    <span class="o">(</span><span class="n">a</span><span class="o">,</span> <span class="n">b</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">zip</span><span class="o">(</span><span class="n">b</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="n">t</span> <span class="k">=&gt;</span> <span class="n">t</span><span class="o">.</span><span class="n">_1</span> <span class="o">+</span> <span class="n">t</span><span class="o">.</span><span class="n">_2</span><span class="o">))</span>
  <span class="k">val</span> <span class="n">sumSquares</span> <span class="k">=</span> <span class="n">dataAsArray</span><span class="o">.</span><span class="n">aggregate</span><span class="o">(</span>
    <span class="k">new</span> <span class="nc">Array</span><span class="o">[</span><span class="kt">Double</span><span class="o">](</span><span class="n">numCols</span><span class="o">)</span>
    <span class="o">)(</span>
      <span class="o">(</span><span class="n">a</span><span class="o">,</span> <span class="n">b</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">zip</span><span class="o">(</span><span class="n">b</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="n">t</span> <span class="k">=&gt;</span> <span class="n">t</span><span class="o">.</span><span class="n">_1</span> <span class="o">+</span> <span class="n">t</span><span class="o">.</span><span class="n">_2</span> <span class="o">*</span> <span class="n">t</span><span class="o">.</span><span class="n">_2</span><span class="o">),</span>
      <span class="o">(</span><span class="n">a</span><span class="o">,</span> <span class="n">b</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">zip</span><span class="o">(</span><span class="n">b</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="n">t</span> <span class="k">=&gt;</span> <span class="n">t</span><span class="o">.</span><span class="n">_1</span> <span class="o">+</span> <span class="n">t</span><span class="o">.</span><span class="n">_2</span><span class="o">)</span>
    <span class="o">)</span>
  <span class="k">val</span> <span class="n">stdevs</span> <span class="k">=</span> <span class="n">sumSquares</span><span class="o">.</span><span class="n">zip</span><span class="o">(</span><span class="n">sums</span><span class="o">).</span><span class="n">map</span> <span class="o">{</span>
    <span class="k">case</span> <span class="o">(</span><span class="n">sumSq</span><span class="o">,</span> <span class="n">sum</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="o">(</span><span class="n">n</span> <span class="o">*</span> <span class="n">sumSq</span> <span class="o">-</span> <span class="n">sum</span> <span class="o">*</span> <span class="n">sum</span><span class="o">)</span> <span class="o">/</span> <span class="n">n</span>
  <span class="o">}</span>
  <span class="k">val</span> <span class="n">means</span> <span class="k">=</span> <span class="n">sums</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span> <span class="o">/</span> <span class="n">n</span><span class="o">)</span>

  <span class="o">(</span><span class="n">datum</span><span class="k">:</span> <span class="kt">Vector</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">normalizedArray</span> <span class="k">=</span> <span class="o">(</span><span class="n">datum</span><span class="o">.</span><span class="n">toArray</span><span class="o">,</span> <span class="n">means</span><span class="o">,</span> <span class="n">stdevs</span><span class="o">).</span><span class="n">zipped</span><span class="o">.</span><span class="n">map</span><span class="o">(</span>
      <span class="o">(</span><span class="n">value</span><span class="o">,</span> <span class="n">mean</span><span class="o">,</span> <span class="n">stdev</span><span class="o">)</span> <span class="k">=&gt;</span>
      <span class="k">if</span> <span class="o">(</span><span class="n">stdev</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="o">)</span>  <span class="o">(</span><span class="n">value</span> <span class="o">-</span> <span class="n">mean</span><span class="o">)</span> <span class="k">else</span>  <span class="o">(</span><span class="n">value</span> <span class="o">-</span> <span class="n">mean</span><span class="o">)</span> <span class="o">/</span> <span class="n">stdev</span>
      <span class="o">)</span>
    <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="n">normalizedArray</span><span class="o">)</span>
  <span class="o">}</span>
<span class="o">}</span>

<span class="k">def</span> <span class="n">clusteringScore</span><span class="o">(</span><span class="n">normalizedLabelsAndData</span><span class="k">:</span> <span class="kt">RDD</span><span class="o">[(</span><span class="kt">String</span>,<span class="kt">Vector</span><span class="o">)],</span> <span class="n">k</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span>
  <span class="k">val</span> <span class="n">kmeans</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">KMeans</span><span class="o">()</span>
  <span class="n">kmeans</span><span class="o">.</span><span class="n">setK</span><span class="o">(</span><span class="n">k</span><span class="o">)</span>
  <span class="n">kmeans</span><span class="o">.</span><span class="n">setRuns</span><span class="o">(</span><span class="mi">10</span><span class="o">)</span>
  <span class="n">kmeans</span><span class="o">.</span><span class="n">setEpsilon</span><span class="o">(</span><span class="mf">1.0e-6</span><span class="o">)</span>

  <span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">run</span><span class="o">(</span><span class="n">normalizedLabelsAndData</span><span class="o">.</span><span class="n">values</span><span class="o">)</span>
  <span class="k">val</span> <span class="n">labelsAndClusters</span> <span class="k">=</span> <span class="n">normalizedLabelsAndData</span><span class="o">.</span><span class="n">mapValues</span><span class="o">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="o">)</span>
  <span class="k">val</span> <span class="n">clustersAndLabels</span> <span class="k">=</span> <span class="n">labelsAndClusters</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">swap</span><span class="o">)</span>
  <span class="k">val</span> <span class="n">labelsInCluster</span> <span class="k">=</span> <span class="n">clustersAndLabels</span><span class="o">.</span><span class="n">groupByKey</span><span class="o">().</span><span class="n">values</span>
  <span class="k">val</span> <span class="n">labelCounts</span> <span class="k">=</span> <span class="n">labelsInCluster</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="n">l</span> <span class="k">=&gt;</span> <span class="n">l</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">_2</span><span class="o">.</span><span class="n">size</span><span class="o">))</span>
  <span class="k">val</span> <span class="n">n</span> <span class="k">=</span> <span class="n">normalizedLabelsAndData</span><span class="o">.</span><span class="n">count</span><span class="o">()</span>

  <span class="n">labelCounts</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">m</span> <span class="k">=&gt;</span> <span class="n">m</span><span class="o">.</span><span class="n">sum</span> <span class="o">*</span> <span class="n">entropy</span><span class="o">(</span><span class="n">m</span><span class="o">)).</span><span class="n">sum</span> <span class="o">/</span> <span class="n">n</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">rawData</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="o">(</span><span class="s">&quot;/kdd/kddcup.data.corrected&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">parseFunction</span> <span class="k">=</span> <span class="n">buildCategoricalAndLabelFunction</span><span class="o">(</span><span class="n">rawData</span><span class="o">)</span>
<span class="k">val</span> <span class="n">labelsAndData</span> <span class="k">=</span> <span class="n">rawData</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">parseFunction</span><span class="o">)</span>
<span class="k">val</span> <span class="n">normalizedLabelsAndData</span> <span class="k">=</span>
    <span class="n">labelsAndData</span><span class="o">.</span><span class="n">mapValues</span><span class="o">(</span><span class="n">buildNormalizationFunction</span><span class="o">(</span><span class="n">labelsAndData</span><span class="o">.</span><span class="n">values</span><span class="o">)).</span><span class="n">cache</span><span class="o">()</span>

<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="o">(</span><span class="mi">80</span> <span class="n">to</span> <span class="mi">160</span> <span class="n">by</span> <span class="mi">10</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="n">k</span> <span class="k">=&gt;</span>
  <span class="o">(</span><span class="n">k</span><span class="o">,</span> <span class="n">clusteringScore</span><span class="o">(</span><span class="n">normalizedLabelsAndData</span><span class="o">,</span> <span class="n">k</span><span class="o">))).</span><span class="n">toList</span>
<span class="n">result</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>

<span class="n">normalizedLabelsAndData</span><span class="o">.</span><span class="n">unpersist</span><span class="o">()</span>
</code></pre></div>
<p>위 코드의 수행 결과는 다음과 같다. ***</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">(80,0.02779435579758084)
(90,0.05653844879893403)
(100,0.029429111090986747)
(110,0.022128545398091923)
(120,0.022724916386673424)
(130,0.02103069110661259)
(140,0.01920591910565662)
(150,0.019929832533142584)
(160,0.019637563306766435)
</code></pre></div>
<p>이로부터 \(k=140\)일때가 최적의 \(k\)임을 알 수 있다.</p>

<p><br>
<br></p>

<h2>Clustering in Action</h2>

<p>이제, 남은 과정은 네트워크 트래픽 중에서 비정상적인 트래픽을 감지해 내는 것이다.</p>

<p>이 장의 처음 부분에서 했던 것과 마찬가지로 현재 \(k=140\)으로 클러스터링을 진행하였을 때의 각 클러스터별 데이터 레이블의 상태를 확인해 볼 수 있다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">rawData</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="o">(</span><span class="s">&quot;/kdd/kddcup.data.corrected&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">parseFunction</span> <span class="k">=</span> <span class="n">buildCategoricalAndLabelFunction</span><span class="o">(</span><span class="n">rawData</span><span class="o">)</span>
<span class="k">val</span> <span class="n">labelsAndData</span> <span class="k">=</span> <span class="n">rawData</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">parseFunction</span><span class="o">)</span>
<span class="k">val</span> <span class="n">normalizedLabelsAndData</span> <span class="k">=</span>
    <span class="n">labelsAndData</span><span class="o">.</span><span class="n">mapValues</span><span class="o">(</span><span class="n">buildNormalizationFunction</span><span class="o">(</span><span class="n">labelsAndData</span><span class="o">.</span><span class="n">values</span><span class="o">))</span>
<span class="k">val</span> <span class="n">normalizedData</span> <span class="k">=</span> <span class="n">normalizedLabelsAndData</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">cache</span><span class="o">()</span>

<span class="k">val</span> <span class="n">kmeans</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">KMeans</span><span class="o">()</span>
<span class="n">kmeans</span><span class="o">.</span><span class="n">setK</span><span class="o">(</span><span class="mi">140</span><span class="o">)</span>
<span class="n">kmeans</span><span class="o">.</span><span class="n">setRuns</span><span class="o">(</span><span class="mi">10</span><span class="o">)</span>
<span class="n">kmeans</span><span class="o">.</span><span class="n">setEpsilon</span><span class="o">(</span><span class="mf">1.0e-6</span><span class="o">)</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">run</span><span class="o">(</span><span class="n">normalizedData</span><span class="o">)</span>
<span class="k">val</span> <span class="n">labelsAndClusters</span> <span class="k">=</span> <span class="n">normalizedLabelsAndData</span><span class="o">.</span><span class="n">mapValues</span><span class="o">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="o">)</span>
<span class="k">val</span> <span class="n">clustersAndLabelsCount</span> <span class="k">=</span> <span class="n">labelsAndClusters</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">swap</span><span class="o">).</span><span class="n">countByValue</span>

<span class="n">clustersAndLabelsCount</span><span class="o">.</span><span class="n">toSeq</span><span class="o">.</span><span class="n">sorted</span><span class="o">.</span><span class="n">foreach</span> <span class="o">{</span>
    <span class="k">case</span> <span class="o">((</span><span class="n">cluster</span><span class="o">,</span> <span class="n">label</span><span class="o">),</span> <span class="n">count</span><span class="o">)</span> <span class="k">=&gt;</span>
    <span class="n">println</span><span class="o">(</span><span class="n">f</span><span class="s">&quot;$cluster%1s$label%18s$count%8s&quot;</span><span class="o">)</span>
<span class="o">}</span>

<span class="n">normalizedData</span><span class="o">.</span><span class="n">unpersist</span><span class="o">()</span>
</code></pre></div>
<p>위 코드를 이용하면 다음과 같은 결과를 볼 수 있다. 처음 확인하였던 결과와는 다르게, 각 클러스터별로 최소 하나 이상의 레이블 데이터가 있으며, 한 레이블이 높은 비율을 차지하고 있다는 것을 알 수 있다.</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">0          neptune.  362825
0        portsweep.       9
1           normal.      13
1        portsweep.     645
2          neptune.     200
2        portsweep.       6
2            satan.       1
3          neptune.    1037
3        portsweep.      13
3            satan.       3
4             back.      43
4           normal.   63268
...
138           normal.    1005
139  buffer_overflow.       6
139        ftp_write.       4
139          ipsweep.      13
139         multihop.       3
139           normal.   35974
139        portsweep.       1
139          rootkit.       1
139      warezclient.     701
139      warezmaster.      18
</code></pre></div>
<p>이런 결과를 갖는 클러스터링 모델에서 비정상적인 트래픽을 찾아낼 것인데, 그 과정은 다음과 같다.</p>

<p>트레이닝한 데이터별로 각 그 데이터가 속하는 클러스터의 중심점과의 거리를 계산하고(이 과정은 앞서 진행하였다.), 그 길이들은 내림차순으로 정렬하여 100번째의 거리값을 Threshold로 정한다. 그리고 전체 데이터중 중심점과의 Threshold를 초과하는 것들을 비정상적인 데이터로 간주할 것이다. 그러기 위해선 데이터를 다시 normalize해야 한다.(앞선 과정에서 진행하였지만, 앞서 진행한 코드를 그대로 적용할 수 없어서 다시 계산한다.) 이어서 Threshold를 계산한 다음에 Threshold를 이용하여 각 데이터를 필터링한다.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">distances</span> <span class="k">=</span> <span class="n">normalizedData</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">datum</span> <span class="k">=&gt;</span> <span class="n">distToCentroid</span><span class="o">(</span><span class="n">datum</span><span class="o">,</span> <span class="n">model</span><span class="o">))</span>
<span class="k">val</span> <span class="n">threshold</span> <span class="k">=</span> <span class="n">distances</span><span class="o">.</span><span class="n">top</span><span class="o">(</span><span class="mi">100</span><span class="o">).</span><span class="n">last</span>
<span class="k">val</span> <span class="n">originalAndParsed</span> <span class="k">=</span> <span class="n">rawData</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">line</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">line</span><span class="o">,</span> <span class="n">parseFunction</span><span class="o">(</span><span class="n">line</span><span class="o">).</span><span class="n">_2</span><span class="o">))</span>

<span class="k">val</span> <span class="n">dataAsArray</span> <span class="k">=</span> <span class="n">originalAndParsed</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">line</span> <span class="k">=&gt;</span> <span class="n">line</span><span class="o">.</span><span class="n">_2</span><span class="o">.</span><span class="n">toArray</span><span class="o">)</span>
<span class="k">val</span> <span class="n">numCols</span> <span class="k">=</span> <span class="n">dataAsArray</span><span class="o">.</span><span class="n">first</span><span class="o">().</span><span class="n">length</span>
<span class="k">val</span> <span class="n">n</span> <span class="k">=</span> <span class="n">dataAsArray</span><span class="o">.</span><span class="n">count</span><span class="o">()</span>
<span class="k">val</span> <span class="n">sums</span> <span class="k">=</span> <span class="n">dataAsArray</span><span class="o">.</span><span class="n">reduce</span> <span class="o">{</span>
    <span class="o">(</span><span class="n">a</span><span class="o">,</span> <span class="n">b</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">zip</span><span class="o">(</span><span class="n">b</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="n">t</span> <span class="k">=&gt;</span> <span class="n">t</span><span class="o">.</span><span class="n">_1</span> <span class="o">+</span> <span class="n">t</span><span class="o">.</span><span class="n">_2</span><span class="o">)</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">sumSquares</span> <span class="k">=</span> <span class="n">dataAsArray</span><span class="o">.</span><span class="n">aggregate</span><span class="o">(</span>
    <span class="k">new</span> <span class="nc">Array</span><span class="o">[</span><span class="kt">Double</span><span class="o">](</span><span class="n">numCols</span><span class="o">)</span>
    <span class="o">)(</span>
        <span class="o">(</span><span class="n">a</span><span class="o">,</span> <span class="n">b</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">zip</span><span class="o">(</span><span class="n">b</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="n">t</span> <span class="k">=&gt;</span> <span class="n">t</span><span class="o">.</span><span class="n">_1</span> <span class="o">+</span> <span class="n">t</span><span class="o">.</span><span class="n">_2</span> <span class="o">*</span> <span class="n">t</span><span class="o">.</span><span class="n">_2</span><span class="o">),</span>
        <span class="o">(</span><span class="n">a</span><span class="o">,</span> <span class="n">b</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">zip</span><span class="o">(</span><span class="n">b</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="n">t</span> <span class="k">=&gt;</span> <span class="n">t</span><span class="o">.</span><span class="n">_1</span> <span class="o">+</span> <span class="n">t</span><span class="o">.</span><span class="n">_2</span><span class="o">)</span>
    <span class="o">)</span>   

<span class="k">val</span> <span class="n">stdevs</span> <span class="k">=</span> <span class="n">sumSquares</span><span class="o">.</span><span class="n">zip</span><span class="o">(</span><span class="n">sums</span><span class="o">).</span><span class="n">map</span> <span class="o">{</span>
    <span class="k">case</span> <span class="o">(</span><span class="n">sumSq</span><span class="o">,</span> <span class="n">sum</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="o">(</span><span class="n">n</span> <span class="o">*</span> <span class="n">sumSq</span> <span class="o">-</span> <span class="n">sum</span> <span class="o">*</span> <span class="n">sum</span><span class="o">)</span> <span class="o">/</span> <span class="n">n</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">means</span> <span class="k">=</span> <span class="n">sums</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span> <span class="o">/</span> <span class="n">n</span><span class="o">)</span>
<span class="k">def</span> <span class="n">normalize</span><span class="o">(</span><span class="n">datum</span><span class="k">:</span> <span class="kt">Vector</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">normalizedArray</span> <span class="k">=</span> <span class="o">(</span><span class="n">datum</span><span class="o">.</span><span class="n">toArray</span><span class="o">,</span> <span class="n">means</span><span class="o">,</span> <span class="n">stdevs</span><span class="o">).</span><span class="n">zipped</span><span class="o">.</span><span class="n">map</span> <span class="o">{</span>
    <span class="o">(</span><span class="n">value</span><span class="o">,</span> <span class="n">mean</span><span class="o">,</span> <span class="n">stdev</span><span class="o">)</span> <span class="k">=&gt;</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">stdev</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="o">)</span> <span class="o">(</span><span class="n">value</span> <span class="o">-</span> <span class="n">mean</span><span class="o">)</span> <span class="k">else</span> <span class="o">(</span><span class="n">value</span> <span class="o">-</span> <span class="n">mean</span><span class="o">)</span> <span class="o">/</span> <span class="n">stdev</span>
    <span class="o">}</span>
    <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="n">normalizedArray</span><span class="o">)</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">originalAndNormalized</span> <span class="k">=</span> <span class="n">originalAndParsed</span><span class="o">.</span><span class="n">mapValues</span><span class="o">(</span><span class="n">normalize</span><span class="o">)</span>
<span class="k">val</span> <span class="n">anormalies</span> <span class="k">=</span> <span class="n">originalAndNormalized</span><span class="o">.</span><span class="n">filter</span><span class="o">{</span>
  <span class="k">case</span> <span class="o">(</span><span class="n">original</span><span class="o">,</span> <span class="n">normalized</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">distToCentroid</span><span class="o">(</span><span class="n">normalized</span><span class="o">,</span> <span class="n">model</span><span class="o">)</span> <span class="o">&gt;</span> <span class="n">threshold</span>
<span class="o">}.</span><span class="n">keys</span>
<span class="n">anormalies</span><span class="o">.</span><span class="n">take</span><span class="o">(</span><span class="mi">10</span><span class="o">).</span><span class="n">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>
</code></pre></div>
<p>재미있게도 다음 결과가 제일 처음으로 나왔는데, 레이블은 정상적인 트래픽이라는 레이블이다. 하지만 이 정상적이라는 것은 보안에 영향을 미치는지에 대한 여부를 뜻하기 때문에 일반적인 네트워크 트래픽과 비교해 봤을때는 정상 트래픽과는 거리가 있다. 연결은 성공하였지만 그 이후로 아무것도 데이터가 전송되지 않은 것을 의미하는 S1 플래그이며, 짧은 순간 동안 30번 가량의 연결이 존재하였다. 이것으로부터 이 데이터는 악의적인 연결은 아니지만 충분히 정상적이지 않은 연결에 대한 것임을 알 수 있다.</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">0,tcp,telnet,S1,145,13236,0,0,0,0,0,1,31,1,2,38,0,0,0,0,0,0,1,1,1.00,1.00,0.00,0.00,1.00,0.00,0.00,29,10,0.28,0.10,0.03,0.20,0.07,0.20,0.00,0.00,normal.
</code></pre></div>
<p><br>
<br></p>

<h2><br></h2>

<p>* 이 과정부터 맥북에서 수행시켰을 때 7시간 이상이 걸려, Amazon EMR을 이용하여 계산하였다.</p>

<p>*<em>, *</em>* 이 결과는 책의 결과와 많이 다르다. 이것 때문에 책의 저자와 이메일을 주고받았는데, 책의 Spark 버전과 이 글을 쓸 때의 Spark 버전과의 차이가 있어서 인것으로 잠정 결론지었다.</p>

  </div><!-- /.entry-content -->
  
  <center><div><a href="/data%20analysis/2015/10/24/advanced-analytics-with-spark-ch5/" class="btn">Read More...</a></div></center>
  
</article><!-- /.hentry -->



<div class="pagination">
  <ul class="inline-list">
    
    

    
    
      <li><strong class="current-page">1</strong></li>
    

    
    

    
    
    

    
      
        
        
        
          
          
        
        <li><a href="/page2/">2</a></li>
      
    
      
        
        
        
          
          
        
        <li><a href="/page3/">3</a></li>
      
    
      
        
        
        
          
          
        
        <li><a href="/page4/">4</a></li>
      
    

    
    
      <li>…</li>
    

    
      <li><a href="/page5/">5</a></li>
    

    
    
      <li><a href="/page2/" class="btn">Next</a></li>
    
  </ul>
</div>

</div><!-- /#main -->

<div class="footer-wrapper">
  <footer role="contentinfo">
    <span>&copy; 2016 Hyunje Jo.</span>
  </footer>
</div><!-- /.footer-wrapper -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="/assets/js/scripts.min.js"></script>

<!-- Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-62281776-2', 'auto');
  ga('send', 'pageview');

</script>


<!-- Mathjax -->
<script type="text/javascript"
    src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


          

</body>
</html>